<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Shengtong Han" />


<title>Simulation study</title>

<script src="site_libs/header-attrs-2.25/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">rare-var-project</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://han16.github.io/rare-var-project/">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Simulation study</h1>
<h4 class="author">Shengtong Han</h4>

</div>


<!-- Add your analysis here -->
<div id="data-generation" class="section level2">
<h2>Data Generation</h2>
<p>Basically, there are two sequential levels when generating the data.
First under null hypothesis, generate total number of variants in cases
and controls, i.e., AF <span class="math inline">\(q_{ij}^{(0)} \sim
Beta(\alpha_0, \beta_0)\)</span>, <span
class="math inline">\(X_{1ij}+X_{0ij} \sim Pois (N1+N0,
q_{ij}^{(0)})\)</span>, filter out variants will null mutations, then
re-distribute all mutations in effective variants into cases and
controls depending on the risk status via conditional binomial
distribution.</p>
<ul>
<li>gene level: <span class="math inline">\(U_i\)</span> denote the risk
status of gene <span class="math inline">\(i\)</span>, <span
class="math inline">\(U_i \sim Ber(1, \delta)\)</span>. All genes share
the same risk probability <span
class="math inline">\(\delta\)</span>.</li>
<li>variant level:
<ul>
<li><p><span class="math inline">\(U_i=0\)</span>, all variants for gene
<span class="math inline">\(i\)</span> are non-causal, which is under
null hypothesis. Given the generated <span
class="math inline">\(X_{1ij}+X_{0ij}\)</span>, split into case and
controls by conditional binomial distribution, with <span
class="math inline">\(p=\frac{N1}{N1+N0}\)</span>.<br />
</p></li>
<li><p><span class="math inline">\(U_i=1\)</span>, gene <span
class="math inline">\(i\)</span> is a causal gene, the variant <span
class="math inline">\((i,j)\)</span> whose risk status is denoted by
<span class="math inline">\(Z_{ij}\)</span> is generated as <span
class="math inline">\(Z_{ij} \sim Ber(1, \pi(\eta))\)</span>, <span
class="math inline">\(\pi(\eta)\)</span> is a function linking
annotations to the probability of being causal.</p>
<pre><code>1.   $Z_{ij}=0$ (which is under null),  given the generated $X_{1ij}+X_{0ij}$, split into case and controls by conditional binomial distribution, with $p=\frac{N1}{N1+N0}$. 

2.  $Z_{ij}=1$ (which is under alternative), AF $q_{ij}^{(1)} \sim Beta(\alpha, \beta)$, $\gamma_{ij} \sim Gamma(\bar{\gamma}*\sigma, \sigma)$,  $X_{1ij}+X_{0ij} \sim Pois(N1+N0, q_{ij}^{(1)})$, split into case and control by conditional binomial distribution with $p=\frac{N1*\gamma_{ij}}{N1*\gamma_{ij}+N0}$. </code></pre></li>
</ul></li>
</ul>
<p>Filtering step: filter variants that have null variant counts in both
cases and controls.</p>
<p>Notations:</p>
<ul>
<li>N1, N0 are sample sizes in cases and controls</li>
<li><span class="math inline">\(q_{ij}\)</span> is allele frequency for
variant <span class="math inline">\((i,j)\)</span></li>
<li><span class="math inline">\(\bar{\gamma}\)</span> relative risk</li>
</ul>
<p><span class="math inline">\(\pi(\eta)\)</span> is the link function
between annotations and prior probability and the interest is in
estimating <span class="math inline">\(\eta\)</span>.</p>
</div>
<div id="disjoint-group-priors" class="section level2">
<h2>Disjoint group priors</h2>
<div id="comparison-between-mirage-vs-and-other-methods"
class="section level3">
<h3>Comparison between MIRAGE-VS and other methods</h3>
<p>We simulated 100 variants in one category. <span
class="math inline">\(N1=N0=1000, 3000, 5000\)</span>, <span
class="math inline">\(\eta=0.1, 0.2, 0.3, 0.4\)</span>, <span
class="math inline">\(\bar{\gamma}=5\)</span>, <span
class="math inline">\(\alpha=\alpha_0=0.1\)</span>, <span
class="math inline">\(\beta=2000, \beta_0=1000\)</span>. We independetly
run Monte Carlo 100 times and calculate the true positive rate for
MIRAGE-VS, burden test and SKATO. Note here there is no gene
information. MIRAGE-VS basically estimates the proportion of risk
variants <span class="math inline">\(\hat{\eta}\)</span>, and performs
the likelihood ratio test to get p value.</p>
<pre><code>## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
## ℹ Please use `linewidth` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
## generated.</code></pre>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<div id="sensitivity-analysis-of-bargamma" class="section level4">
<h4>Sensitivity analysis of <span
class="math inline">\(\bar{\gamma}\)</span></h4>
<p>We simulated 100 variants in one category. <span
class="math inline">\(\eta= 0.4\)</span>, true <span
class="math inline">\(\bar{\gamma}=5\)</span>, and we vary <span
class="math inline">\(\bar{\gamma}=3,4,5,6\)</span> and <span
class="math inline">\(N1=N0=1000, 3000, 5000\)</span>,, <span
class="math inline">\(\alpha=\alpha_0=0.1\)</span>, <span
class="math inline">\(\beta=2000, \beta_0=1000\)</span>. We independetly
run Monte Carlo 1000 times and calculate the true positive rate for
MIRAGE-VS, burden test and SKATO. Note here there is no gene
information. MIRAGE-VS basically estimates the proportion of risk
variants <span class="math inline">\(\hat{\eta}\)</span>, and performs
the likelihood ratio test to get p value.</p>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="type-one-error" class="section level4">
<h4>Type one error</h4>
<p>To investigate the type one error, we simulated 1000 independent data
sets, with varying sample size <span class="math inline">\(N1=N0=1000,
3000, 5000\)</span>, 100 variants in one group; no risk variants, i.e.,
<span class="math inline">\(\eta=0\)</span> and other parameters are
pretty the same as before <span class="math inline">\(\alpha_0=0.1,
\beta_0=1000,\alpha= 0.1, \beta=2000,\bar{\gamma}=5,\sigma= 1\)</span>.
The basic idea is to see the proportion of significant test under
null.</p>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Burden test: use fisher exact test MIRAGE: first estimate parameter
<span class="math inline">\(\eta\)</span>, then do likelihood ratio
test</p>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>This is to test how sensitive is the effect of mis-specified <span
class="math inline">\(\bar{\gamma}\)</span> on type one error.</p>
<p>The same parameter settings. The only diffrence is that <span
class="math inline">\(\bar{\gamma}=5\)</span> when generating the data
and different mis-specified <span
class="math inline">\(\bar{\gamma}\)</span> (on x axis) is used to make
inference. N1=N0=3000.</p>
</div>
</div>
<div id="all-genes-are-risk-genes-fix-delta1-only-estimate-eta"
class="section level3">
<h3>All genes are risk genes, fix <span
class="math inline">\(\delta=1\)</span>, only estimate <span
class="math inline">\(\eta\)</span></h3>
<ul>
<li>parameter estimate: (I) relative risk effect, <span
class="math inline">\(\bar{\gamma}\)</span> on estimating <span
class="math inline">\(\eta\)</span></li>
</ul>
<p>Since variant groups are assumed to be independent, it suffices to
demonstrate the parameter estimate only for one risk variant group.</p>
<p>Parameter settings: N1=N0=3000, <span
class="math inline">\(\alpha=\alpha_0=0.1\)</span>, <span
class="math inline">\(\beta=2000, \beta_0=1000\)</span>. 100 genes, each
having 1000 variants with <span
class="math inline">\(\eta_i=0.1\)</span> risk variants, but the actural
<span class="math inline">\(\eta_i\)</span> is varying for each
generated data set because of the filtering. <span
class="math inline">\(\bar{\gamma}=2,3,4,5\)</span> and with each <span
class="math inline">\(\bar{\gamma}\)</span>, perform 100 independent
runs.</p>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<ul>
<li>Parameter estimate (II): sample size effect on estimating <span
class="math inline">\(\eta\)</span></li>
</ul>
<p>Parameter settings: N1=N0=1000, 3000, 5000, <span
class="math inline">\(\alpha=\alpha_0=0.1\)</span>, <span
class="math inline">\(\beta=2000, \beta_0=1000\)</span>. 100 genes, each
having 1000 variants with <span
class="math inline">\(\eta_i=0.1\)</span> risk variants, but the actural
<span class="math inline">\(\eta_i\)</span> is varying for each
generated data set because of the filtering. <span
class="math inline">\(\bar{\gamma}=5\)</span>. For each fixed sample
size, perform 100 independent runs.</p>
<ul>
<li>power comparison with other methods</li>
</ul>
<p>For every simulated risk gene, three different methods are used to
test the power of detecting risk genes. Significance level of 0.05 is
used as cutoff. Burnden test looks at the variants in cases and controls
and performs the enrichment analysis for every gene. SKATO tests the
significance of effect size and generate p value without covariates.
MIRAGE-LRT first estimates the parameter <span
class="math inline">\(\eta\)</span>, then does a likelihood ratio test
and returns p value by <span class="math inline">\(\chi^2_k\)</span>
(<span class="math inline">\(k\)</span> is the number of unknown
parameters <span class="math inline">\(\eta\)</span>).</p>
<p><strong>Case 1: every risk gene only has one risk variant group with
the proportion of <span class="math inline">\(\eta\)</span> and fixed
<span class="math inline">\(\bar{\gamma}\)</span></strong></p>
<p>Parameter settings: N1=N0=3000 <span
class="math inline">\(\alpha=\alpha_0=0.1\)</span>, <span
class="math inline">\(\beta=2000, \beta_0=1000\)</span>. 100 genes, each
having 1000 variants with <span class="math inline">\(\eta=0.1, 0.2,
0.3\)</span> risk variants, but the actural <span
class="math inline">\(\eta\)</span> is varying for each generated data
set because of the filtering. <span
class="math inline">\(\bar{\gamma}=5\)</span>. For every <span
class="math inline">\(\eta\)</span>, perform 100 independent runs.</p>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p><strong>Case 2: every risk gene has multiple risk variant groups with
varying proportion of <span class="math inline">\(\eta\)</span> and
fixed <span class="math inline">\(\bar{\gamma}\)</span></strong></p>
<p>Parameter settings: N1=N0=3000 <span
class="math inline">\(\alpha=\alpha_0=0.1\)</span>, <span
class="math inline">\(\beta=2000, \beta_0=1000\)</span>. 100 genes, each
having 1000 variants in three different groups, the first group has 30%
variant, the second has 40% and the rest 30% are in the third group. In
each group of every gene, the proportion of risk genes <span
class="math inline">\(\eta\)</span> is varying at 0.01, 0.05, 0.1
respectively. <span class="math inline">\(\bar{\gamma}=2, 3,4,
5\)</span>. For every <span class="math inline">\(\bar{\gamma}\)</span>,
perform 100 independent runs.</p>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p><strong>Case 3: every risk gene has multiple risk variant groups with
varying proportion of <span class="math inline">\(\eta\)</span> and
varying <span class="math inline">\(\bar{\gamma}\)</span></strong></p>
<p>Parameter settings: N1=N0=3000 <span
class="math inline">\(\alpha=\alpha_0=0.1\)</span>, <span
class="math inline">\(\beta=2000, \beta_0=1000\)</span>. 100 genes, each
having 1000 variants in three different groups, the first group has 30%
variants, the second has 40% and the rest 30% are in the third group. In
each variant group of every gene, the proportion of risk variants <span
class="math inline">\(\eta\)</span> is varying at 0.01, 0.05, 0.1 and
every risk category has its own <span
class="math inline">\(\bar{\gamma}=5, 3,1\)</span> respectively. The
basic idea is that the rarer the varinat is, the more effect size it
tends to have. Perform 100 independent runs.</p>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
</div>
<div
id="mixture-of-risk-genes-and-non-risk-genes-0delta1-estimate-both-eta-delta"
class="section level3">
<h3>Mixture of risk genes and non-risk genes <span
class="math inline">\(0&lt;\delta&lt;1\)</span>, estimate both <span
class="math inline">\(\eta, \delta\)</span></h3>
<p>Since the simulated data is a mixture of risk genes and non-risk
genes, drawing ROC curve is one way to test the power of discriminating
risk genes of different methods. For MIRAGE, Bayes factor of every gene
was calculated and used to plot ROC, called MIRAGE-BF.</p>
<div id="power-comparison" class="section level4">
<h4>Power comparison</h4>
<p><strong>case 1: one risk gene has only one risk variant category with
fixed <span class="math inline">\(\bar{\gamma}\)</span></strong></p>
<p>Parameter settings: N1=N0=3000 <span
class="math inline">\(\alpha=\alpha_0=0.1\)</span>, <span
class="math inline">\(\beta=2000, \beta_0=1000\)</span>. 100 genes, each
having 1000 variants with <span class="math inline">\(\eta=0.03, 0.07,
0.1, 0.2\)</span> risk variants, but the actural <span
class="math inline">\(\eta\)</span> is varying for each generated data
set because of the filtering. <span
class="math inline">\(\delta=0.5\)</span>, i.e. half genes are risk
genes and the rest half are nonrisk genes. <span
class="math inline">\(\bar{\gamma}=5\)</span>.</p>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p><strong>case2: one risk gene has multiple risk variant categories
with group specific <span
class="math inline">\(\bar{\gamma}\)</span></strong></p>
<p>Parameter settings: N1=N0=3000 <span
class="math inline">\(\alpha=\alpha_0=0.1\)</span>, <span
class="math inline">\(\beta=2000, \beta_0=1000\)</span>, <span
class="math inline">\(\delta=0.5\)</span>. 100 genes, each having 1000
variants in three different groups, the first group has 30% variants,
the second has 40% and the rest 30% are in the third group. In each
variant group of every gene, the proportion of risk variants <span
class="math inline">\(\eta\)</span> is varying at 0.01, 0.05, 0.1 and
every risk category has its own <span
class="math inline">\(\bar{\gamma}=5, 3,1\)</span> respectively. The
basic idea is that the rarer the varinat is, the more effect size it
tends to have.</p>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Parameter settings: N1=N0=3000 <span
class="math inline">\(\alpha=\alpha_0=0.1\)</span>, <span
class="math inline">\(\beta=2000, \beta_0=1000\)</span>, <span
class="math inline">\(\delta=0.1, 0.2, 0.3, 0.4\)</span>. 1000 genes,
each having 100 variants in three different groups, the first group has
60% variants, the second has 30% and the rest 10% are in the third
group. In each variant group of every gene, the proportion of risk
variants <span class="math inline">\(\eta\)</span> is varying at 0.05,
0.2, 0.5 and every risk category has its own <span
class="math inline">\(\bar{\gamma}\)</span> respectively. The basic idea
is that the rarer the varinat is, the more effect size it tends to
have.</p>
<p><strong>burden test: for every gene, use all variants in cases and
control</strong></p>
<p><span class="math inline">\(\bar{\gamma}=1, 3,5\)</span></p>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p><strong>burden-adj: for every gene, compute p values for 3 variant
categories, adjust p values by bonferroni correction and take the
minimum</strong></p>
<p><span class="math inline">\(\bar{\gamma}=3,3,5\)</span>. burden-comb:
use Fisher method to combine p values from 3 independent tests.</p>
<ul>
<li><p>burden test: use fisher exact test in R on total counts of
transmitted and un-transmitted alleles</p></li>
<li><p>SKAT-O test: use R package-SKAT with method “SKATO” chosen.<br />
</p></li>
<li><p>ASUM: use ASUM function in R package AssotesteR, with 100
permutations</p></li>
<li><p>CMC: use CMC function in R package AssotesteR, with 100
permutations, and <code>maf=10^(-4)*c(0.05, 0.2, 0.5)</code>.</p></li>
<li><p>ACAT p value: within each of 3 variant groups, run ACAT on p
value of every single variant by burden test (collapse variant if its
MAC&lt;10, as ACAT paper suggested) to obtain group level p value, then
use ACAT to combine group level p value to get gene level p
values</p></li>
</ul>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>Comparisons among three burden tests</p>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<pre class="r"><code>rm(&quot;Ui&quot;, &quot;mirage_pvalue&quot;, &quot;mirage_BF&quot;, &quot;fisher_pvalue&quot;, &quot;skato_pvalue&quot;, &quot;cmc_pvalue&quot;, &quot;asum_pvalue&quot;, &quot;acat.pvalue&quot;, &quot;fisher.separate.pvalue&quot;)
load(&quot;../output/Var_specific_bargamma_MixedGene_MixtureVariant/7methods_delta0.02_gammamean335_5rep1.RData&quot;)
AUC_summary_0.02=matrix(nrow=10, ncol=6)
colnames(AUC_summary_0.02)=c(&quot;ACAT&quot;, &quot;ASUM&quot;, &quot;Burden&quot;, &quot;CMC&quot;, &quot;MIRAGE&quot;, &quot;SKAT-O&quot;)
#for (i in 1:10)
{
  i=2
Ui=Gene.Risk.Status[[i]]
mirage_pvalue=MIRAGE.pvalue[[i]]
mirage_BF=MIRAGE.BF[[i]]
fisher_pvalue=Fisher.pvalue[[i]]
skato_pvalue=SKATO.pvalue[[i]]
cmc_pvalue=CMC.pvalue[[i]]
asum_pvalue=ASUM.pvalue[[i]]
fisher.separate.pvalue=Fisher.separate.pvalue[[i]]
acat.pvalue=ACAT.pvalue[[i]]
fisher.adj.pvalue=numeric()
fisher.combine.pvalue=numeric()
for (ii in 1:nrow(fisher.separate.pvalue))
{
  fisher.adj.pvalue[ii]=min(p.adjust(fisher.separate.pvalue[ii,], method = &quot;bonferroni&quot;, n = length(fisher.separate.pvalue[ii,])))
  fisher.combine.pvalue[ii]=pchisq(-sum(log(fisher.separate.pvalue[ii,])), df=6, ncp = 0, lower.tail = TRUE)
}  
  # fisher.adj.pvalue[i]=min(fisher.separate.pvalue[i,])

num_run=length(mirage_pvalue)


method=rep(c(&quot;Burden(0.657)&quot;, &quot;SKAT-O(0.657)&quot;, &quot;MIRAGE(0.849)&quot;, &quot;CMC(0.715)&quot;, &quot;ASUM(0.544)&quot;, &quot;ACAT(0.702)&quot;), each=num_run) # AUC is from round(calc_auc(p1.basic)$AUC, 2) 

roc_single_run=data.frame(D=Ui, m=c(fisher_pvalue,skato_pvalue, -mirage_BF, cmc_pvalue, asum_pvalue, acat.pvalue), method=method)

p1.basic=ggplot(roc_single_run, aes(d = D, m = m, color=method), size=2) + 
  geom_roc(increasing=F, n.cuts=0)+
  style_roc(theme = theme_grey)
p1_delta0.02=p1.basic+
 # annotate(&quot;text&quot;, x =rep(0.7, 8), y = c(0.02,0.08, 0.14, 0.2, 0.25, 0.3, 0.35, 0.4), 
#           label = paste(c(&quot;ASUM:AUC&quot;, &quot;Burden_adj:AUC&quot;, &quot;Burden:AUC=&quot;, &quot;Burden_comb:AUC&quot;, &quot;CMC:AUC&quot;, &quot;MIRAGE-BF:AUC=&quot;, &quot;MIRAGE-LRT:AUC=&quot;, &quot;SKATO:AUC=&quot;), round(calc_auc(p1.basic)$AUC, 2)), size=2)+
  ggtitle(expression(paste(delta, &quot;=0.02&quot;)))+
  theme_classic()+
theme(plot.title = element_text(hjust = 0.5, size=10))+  #center the title 
 theme(axis.text.x= element_text(size=8))+  # custmorize the axis tick size 
theme(axis.text.y= element_text(size=10))+
  theme(axis.text = element_text(size = 1))+
  geom_abline(intercept = 0, slope =1, col=&quot;black&quot;)+  # add a diagnal line 
  theme(legend.title=element_blank())+   # nol legend title 
  theme(legend.justification=c(1,0), legend.position=c(1,0))+
  theme(legend.text = element_text(size = 11)) # adjust legend text size 
#p1_delta0.01
#calc_auc(p1.basic)$AUC
AUC_summary_0.02[i,]=calc_auc(p1.basic)$AUC
}

############################################################################################################
################################ delta=0.1
rm(&quot;Ui&quot;, &quot;mirage_pvalue&quot;, &quot;mirage_BF&quot;, &quot;fisher_pvalue&quot;, &quot;skato_pvalue&quot;, &quot;cmc_pvalue&quot;, &quot;asum_pvalue&quot;, &quot;acat.pvalue&quot;, &quot;fisher.separate.pvalue&quot;)
load(&quot;../output/Var_specific_bargamma_MixedGene_MixtureVariant/7methods_delta0.1_gammamean335_5rep.RData&quot;)
AUC_summary_0.1=matrix(nrow=5, ncol=6)
colnames(AUC_summary_0.1)=c(&quot;ACAT&quot;, &quot;ASUM&quot;, &quot;Burden&quot;, &quot;CMC&quot;, &quot;MIRAGE&quot;, &quot;SKAT-O&quot;)
#for (i in 1:5)
{
  i=1
Ui=Gene.Risk.Status[[i]]
mirage_pvalue=MIRAGE.pvalue[[i]]
mirage_BF=MIRAGE.BF[[i]]
fisher_pvalue=Fisher.pvalue[[i]]
skato_pvalue=SKATO.pvalue[[i]]
cmc_pvalue=CMC.pvalue[[i]]
asum_pvalue=ASUM.pvalue[[i]]
fisher.separate.pvalue=Fisher.separate.pvalue[[i]]
acat.pvalue=ACAT.pvalue[[i]]
fisher.adj.pvalue=numeric()
fisher.combine.pvalue=numeric()
for (ii in 1:nrow(fisher.separate.pvalue))
{
  fisher.adj.pvalue[ii]=min(p.adjust(fisher.separate.pvalue[ii,], method = &quot;bonferroni&quot;, n = length(fisher.separate.pvalue[ii,])))
  fisher.combine.pvalue[ii]=pchisq(-sum(log(fisher.separate.pvalue[ii,])), df=6, ncp = 0, lower.tail = TRUE)
}  
  # fisher.adj.pvalue[i]=min(fisher.separate.pvalue[i,])

num_run=length(mirage_pvalue)


method=rep(c( &quot;Burden(0.682)&quot;, &quot;SKAT-O(0.751)&quot;, &quot;MIRAGE(0.859)&quot;, &quot;CMC(0.784)&quot;, &quot;ASUM(0.634)&quot;, &quot;ACAT(0.638)&quot;), each=num_run)

roc_single_run=data.frame(D=Ui, m=c(fisher_pvalue,skato_pvalue, -mirage_BF, cmc_pvalue, asum_pvalue, acat.pvalue), method=method)
p2.basic=ggplot(roc_single_run, aes(d = D, m = m, color=method), size=2) + 
  geom_roc(increasing=F, n.cuts=0)+
  style_roc(theme = theme_grey)
#pdf(&quot;../../Figure/power_comparison_different_methods.pdf&quot;)
p2_delta0.1=p2.basic+
#  annotate(&quot;text&quot;, x =rep(0.7, 8), y = c(0.02,0.08, 0.14, 0.2, 0.25, 0.3, 0.34, 0.4), 
#           label = paste(c(&quot;ASUM:AUC&quot;, &quot;Burden_adj:AUC&quot;,  &quot;Burden:AUC=&quot;, &quot;Burden_comb:AUC&quot;,&quot;CMC:AUC&quot;, &quot;MIRAGE-BF:AUC=&quot;, &quot;MIRAGE-LRT:AUC=&quot;, &quot;SKATO:AUC=&quot;), round(calc_auc(p2.basic)$AUC, 2)), size=2)+
  ggtitle(expression(paste(delta, &quot;=0.1&quot;)))+
  theme_classic()+
theme(plot.title = element_text(hjust = 0.5, size=10))+  #center the title 
 theme(axis.text.x= element_text(size=8))+  # custmorize the axis tick size 
theme(axis.text.y= element_text(size=10))+
  theme(axis.text = element_text(size = 1))+
geom_abline(intercept = 0, slope =1, col=&quot;black&quot;)+  # add a diagnal line 
  theme(legend.title=element_blank())+   # nol legend title 
  theme(legend.justification=c(1,0), legend.position=c(1,0))+
  theme(legend.text = element_text(size = 11))+ # adjust legend text size 
  theme(axis.title.y = element_blank())  # remove labels on y axis 

AUC_summary_0.1[i,]=calc_auc(p2.basic)$AUC
}

#p2_delta0.05
#grid.arrange(p1, p2, top=grid.text(&quot;ROC curves&quot;), bottom=grid.text(expression(paste(alpha, &quot;=0.1,&quot;, alpha[0], &quot;=0.1,&quot;, beta, &quot;=2000,&quot;, beta[0], &quot;=1000&quot;))), nrow=1)
#dev.off()
#grid.arrange(p1_delta0.01, p2_delta0.05, nrow=1)

#pdf(&quot;C:/Users/hans/OneDrive - Marquette University/RareVariant/Fig3-power_comparison_MIRAGE-gene_2023_0417.pdf&quot;)
#pdf(&quot;C:\\Shengtong\\Research\\rare-var\\RareVariant\\2023_0413_Figure_for_paper\\Fig3-power_comparison_MIRAGE-gene_2023_0421.pdf&quot;)
grid.arrange(p1_delta0.02, p2_delta0.1, nrow=1) </code></pre>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<ul>
<li>use threshold <code>MAC&lt;10</code> for variant collapsing for
ACAT</li>
</ul>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-28-1.png" width="672" />
* use threshold <code>MAC&lt;5</code> for variant collapsing for
ACAT</p>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<ul>
<li>no collapsing for ACAT</li>
</ul>
<p><strong>Parameter estimate</strong></p>
<p><span class="math inline">\(\beta_1=0.05,\beta_2=0.2, \beta_3=0.5,
\delta=0.1\)</span></p>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
</div>
</div>
<div id="type-i-error" class="section level3">
<h3>type I error</h3>
<div id="only-variant-level-no-gene-level" class="section level4">
<h4>Only variant level, no gene level</h4>
<p>To investigate the type one error, we simulated 100 independent data
sets, each with <span class="math inline">\(N1=N0=3000\)</span>, 100
variants in one group; no risk variants, i.e., <span
class="math inline">\(\eta=0\)</span> and other parameters are pretty
the same as before <span class="math inline">\(\alpha_0=0.1,
\beta_0=1000,\alpha= 0.1, \beta=2000,\bar{\gamma}=4,\sigma=
1\)</span>.</p>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p>Burden test: use fisher exact test MIRAGE: first estimate parameter
<span class="math inline">\(\eta\)</span>, then do likelihood ratio
test</p>
<p>To investigate the type one error, we simulated one independent data
set, with <span class="math inline">\(N1=N0=3000\)</span>, 1000 genes
are all non-risk genes. Every gene has 100 variants in three non-risk
variant groups; no risk variant groups i.e., <span
class="math inline">\(\eta=0\)</span> and other parameters are pretty
the same as before <span class="math inline">\(\alpha_0=0.1,
\beta_0=1000,\alpha= 0.1, \beta=2000,\bar{\gamma}=3,4,5,\sigma=
1\)</span>.</p>
<pre><code>## Warning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.
## ℹ Please use `after_stat(count)` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
## generated.</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-32-2.png" width="672" /></p>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-32-3.png" width="672" /></p>
</div>
</div>
<div id="bayesian-fdr-control" class="section level3">
<h3>Bayesian FDR control</h3>
<div id="bayesian-fdr-vs-actual-fdr" class="section level4">
<h4>Bayesian FDR vs actual FDR</h4>
<p>Simulated one data set, <span class="math inline">\(N1=N0=1000, 3000,
5000\)</span>, 10% of 1000 genes are risk genes. Every gene has 100
variants in three variant groups with <span
class="math inline">\(\eta_1=0.05, \eta_2=0.2, \eta_3=0.5\)</span> and
<span class="math inline">\(\bar{\gamma}=3,3,5\)</span> respectively and
the proportion of variants are 60%, 30% and 10%. Other parameters are
pretty the same as before <span class="math inline">\(\alpha_0=0.1,
\beta_0=1000,\alpha= 0.1, \beta=2000,\sigma= 1\)</span>.</p>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
</div>
<div id="robustness-of-bayesian-fdr-for-bargamma"
class="section level4">
<h4>Robustness of Bayesian FDR for <span
class="math inline">\(\bar{\gamma}\)</span></h4>
<p>Simulated one data set, <span
class="math inline">\(N1=N0=3000\)</span>, 10% of 1000 genes are risk
genes. Every gene has 100 variants in three variant groups with <span
class="math inline">\(\eta_1=0.05, \eta_2=0.2, \eta_3=0.5\)</span> and
the proportion of variants are 30%, 40% and 30%. Each data set has one
fixed <span class="math inline">\(\bar{\gamma}\)</span> and it is varied
at <span class="math inline">\(\bar{\gamma}=3,4,5,6\)</span>. Other
parameters are pretty the same as before <span
class="math inline">\(\alpha_0=0.1, \beta_0=1000,\alpha= 0.1,
\beta=2000,\sigma= 1\)</span>.</p>
<p>Repeat the simulation 20 times. When Bayesian FDR=0.05, what is the
distribution of actual FDR.</p>
<pre class="r"><code>##################### true gamma.bar=3 ##########
gene.prior=0.1 # use true value
gene.fdr=list()
num.run=20  # there are 20 replicates 
bayesian.fdr=0.05
actual.fdr.range=matrix(nrow=4, ncol=num.run)
for (i in 3:6)
{
  #i=3
 ############ compute posterior probability for every gene ##########
 rm(&quot;all.delta.est&quot;, &quot;all.BF.gene&quot;, &quot;all.mirage.pvalue&quot;, &quot;all.skat.pvalue&quot;, &quot;all.fisher.pvalue&quot;, &quot;all.Ui&quot;)
 load(paste(&quot;../output/BayesianFDR/Mixed_Gene_Gammamean3_&quot;, &quot;useGammabar&quot;, i, &quot;.delta0.1_replicate100.RData&quot;, sep=&quot;&quot;)) 

 actual.fdr.range.single.run=numeric()
 for (run in 1:num.run)
 { #run=1
 Bayes.factor=tibble(BF=all.BF.gene[run,])
 gene.post=Bayes.factor %&gt;% mutate(post.prob=gene.prior*BF/(1-gene.prior+gene.prior*BF))
 gene.post=as_tibble(cbind(gene.post, RiskStatus=all.Ui[run,]))

 ################ calculate Bayesian FDR for every post prob cutoff ###########
tau=seq(0, 0.999, by=0.001)
num.pred=NULL
false.disc=NULL
FDR=NULL
for (ii in 1:length(tau))
{
num.pred[ii]=sum(ifelse(gene.post$post.prob&gt;tau[ii], 1, 0))
false.disc[ii]=sum((1-gene.post$post.prob)*ifelse(gene.post$post.prob&gt;tau[ii], 1, 0))
FDR[ii]=false.disc[ii]/num.pred[ii]
}
tau.fdr=tibble(tau=tau, bar.fdr=FDR)%&gt;%drop_na()  # drop rows with NA

############### calculate actual FDR #################################
bayes.fdr=seq(0, 0.5, length=100)
actual.fdr=numeric()
tau.select=numeric()
for (ii in 1:length(bayes.fdr))
{
  tau.select[ii]=max(tau.fdr %&gt;% filter(bar.fdr&gt;bayes.fdr[ii] &amp; bar.fdr&lt;bayes.fdr[ii]+0.1 ) %&gt;%  pull(tau))
  No.Disc=gene.post %&gt;% filter(post.prob&gt;tau.select[ii]) %&gt;% tally() %&gt;% pull()
  TP=gene.post %&gt;% filter(post.prob&gt;tau.select[ii]) %&gt;% filter(RiskStatus==1) %&gt;% tally() %&gt;% pull()
  # pull is used to convert tibble to a vector 
  actual.fdr[ii]=1-TP/No.Disc
} 
bayes.actual.fdr=tibble(Bayes.FDR=bayes.fdr, Actual.FDR=actual.fdr) %&gt;% mutate(Gamma.bar.use=i)
#gene.fdr[[i]]=list( gene.post=gene.post, bayes.actual.fdr=bayes.actual.fdr)

actual.fdr.range.single.run[run]=bayes.actual.fdr %&gt;% filter(Bayes.FDR&lt;bayesian.fdr-0.0001) %&gt;% summarize(Actual.FDR=max(Actual.FDR)) %&gt;% pull() # calculate the actual FDR when Bayesian.FDR=0.1
 } # end of run
 
 actual.fdr.range[i-2,]=actual.fdr.range.single.run
} # end of i



fdr.mean=rowMeans(actual.fdr.range)
fdr.sd=c(sd(actual.fdr.range[1,]), sd(actual.fdr.range[2,]), sd(actual.fdr.range[3,]), sd(actual.fdr.range[4,]))
max.ylab=max(fdr.mean+fdr.sd)

bar.gamma=3:6
actual.fdr.summary=data.frame(mean=fdr.mean, sd=fdr.sd, bar.gamma=bar.gamma)
p1=ggplot(actual.fdr.summary, aes(x=bar.gamma, y=mean, group=1)) + 
   geom_point() +
  geom_pointrange(aes(ymin=mean-sd, ymax=mean+sd))+
  ggtitle(expression(paste(&quot;True &quot;, bar(gamma), &quot;=3&quot;)))+
  theme_classic()+
  theme(plot.title = element_text(hjust = 0.5, size=10))+  #center the title 
  xlab(expression(paste(bar(gamma))))+
  ylab(&quot;False Discovery Proportion&quot;)+ylim(c(-0.01, max.ylab))+
  guides(fill=guide_legend(title=NULL))+
  #ylim(0.05,0.15)+
   geom_hline(yintercept=bayesian.fdr,linetype=&quot;dashed&quot;, color = &quot;red&quot;)+
  theme(axis.title.y=element_text(size=8)) # adjust text size for y labels

#combine.bayes.actual.fdr=bind_rows(gene.fdr[[3]]$bayes.actual.fdr,gene.fdr[[4]]$bayes.actual.fdr,gene.fdr[[5]]$bayes.actual.fdr,gene.fdr[[6]]$bayes.actual.fdr)
#combine.bayes.actual.fdr$Gamma.bar.use&lt;-combine.bayes.actual.fdr$Gamma.bar.use %&gt;% recode(&quot;3&quot;=&quot;3&quot;, &quot;4&quot;=&quot;4&quot;, &quot;5&quot;=&quot;5&quot;, &quot;6&quot;=&quot;6&quot;)
#null.pvalue.combine$Method=null.pvalue.combine$Method %&gt;% recode(MIRAGE.pvalue=&quot;MIRAGE_VS&quot;, Fisher.pvalue=&quot;Burden&quot;, SKATO.pvalue=&quot;SKATO&quot;)
#g1=ggplot(combine.bayes.actual.fdr, aes(x=Bayes.FDR, y=Actual.FDR, color=Gamma.bar.use))+
#  geom_abline(intercept =0, slope =1, 
#                 linetype=&quot;solid&quot;, size=1.5, col=&quot;black&quot;)+
#  geom_point()+
#  ggtitle(expression(paste(&quot;True &quot;, bar(gamma), &quot;=3&quot;)))+
#  theme(plot.title = element_text(hjust = 0.5, size=10))  #center the title 
#################################################################################################################
#################################################################################################################
##################### true gamma.bar=4 ##########
gene.prior=0.1 # use true value
gene.fdr=list()
actual.fdr.range=matrix(nrow=4, ncol=num.run)
for (i in 3:6)
{
  #i=3
 ############ compute posterior probability for every gene ##########
 rm(&quot;all.delta.est&quot;, &quot;all.BF.gene&quot;, &quot;all.mirage.pvalue&quot;, &quot;all.skat.pvalue&quot;, &quot;all.fisher.pvalue&quot;, &quot;all.Ui&quot;)
 load(paste(&quot;../output/BayesianFDR/Mixed_Gene_Gammamean4_&quot;, &quot;useGammabar&quot;, i, &quot;.delta0.1_replicate100.RData&quot;, sep=&quot;&quot;)) 

 actual.fdr.range.single.run=numeric()
 for (run in 1:num.run)
 { #run=1
 Bayes.factor=tibble(BF=all.BF.gene[run,])
 gene.post=Bayes.factor %&gt;% mutate(post.prob=gene.prior*BF/(1-gene.prior+gene.prior*BF))
 gene.post=as_tibble(cbind(gene.post, RiskStatus=all.Ui[run,]))

 ################ calculate Bayesian FDR for every post prob cutoff ###########
tau=seq(0, 0.999, by=0.001)
num.pred=NULL
false.disc=NULL
FDR=NULL
for (ii in 1:length(tau))
{
num.pred[ii]=sum(ifelse(gene.post$post.prob&gt;tau[ii], 1, 0))
false.disc[ii]=sum((1-gene.post$post.prob)*ifelse(gene.post$post.prob&gt;tau[ii], 1, 0))
FDR[ii]=false.disc[ii]/num.pred[ii]
}
tau.fdr=tibble(tau=tau, bar.fdr=FDR)%&gt;%drop_na()  # drop rows with NA

############### calculate actual FDR #################################
bayes.fdr=seq(0, 0.5, length=100)
actual.fdr=numeric()
tau.select=numeric()
for (ii in 1:length(bayes.fdr))
{
  tau.select[ii]=max(tau.fdr %&gt;% filter(bar.fdr&gt;bayes.fdr[ii] &amp; bar.fdr&lt;bayes.fdr[ii]+0.1 ) %&gt;%  pull(tau))
  No.Disc=gene.post %&gt;% filter(post.prob&gt;tau.select[ii]) %&gt;% tally() %&gt;% pull()
  TP=gene.post %&gt;% filter(post.prob&gt;tau.select[ii]) %&gt;% filter(RiskStatus==1) %&gt;% tally() %&gt;% pull()
  # pull is used to convert tibble to a vector 
  actual.fdr[ii]=1-TP/No.Disc
} 
bayes.actual.fdr=tibble(Bayes.FDR=bayes.fdr, Actual.FDR=actual.fdr) %&gt;% mutate(Gamma.bar.use=i)
#gene.fdr[[i]]=list( gene.post=gene.post, bayes.actual.fdr=bayes.actual.fdr)

actual.fdr.range.single.run[run]=bayes.actual.fdr %&gt;% filter(Bayes.FDR&lt;bayesian.fdr-0.0001) %&gt;% summarize(Actual.FDR=max(Actual.FDR)) %&gt;% pull() # calculate the actual FDR when Bayesian.FDR=0.1
 } # end of run
 
 actual.fdr.range[i-2,]=actual.fdr.range.single.run
} # end of i



fdr.mean=rowMeans(actual.fdr.range)
fdr.sd=c(sd(actual.fdr.range[1,]), sd(actual.fdr.range[2,]), sd(actual.fdr.range[3,]), sd(actual.fdr.range[4,]))

bar.gamma=3:6
actual.fdr.summary=data.frame(mean=fdr.mean, sd=fdr.sd, bar.gamma=bar.gamma)
p2=ggplot(actual.fdr.summary, aes(x=bar.gamma, y=mean, group=1)) + 
   geom_point() +
  geom_pointrange(aes(ymin=mean-sd, ymax=mean+sd))+
  ggtitle(expression(paste(&quot;True &quot;, bar(gamma), &quot;=4&quot;)))+
  theme_classic()+
  theme(plot.title = element_text(hjust = 0.5, size=10))+  #center the title 
  xlab(expression(paste(bar(gamma))))+
  ylab(&quot;&quot;)+ylim(c(0, max.ylab))+  
  guides(fill=guide_legend(title=NULL))+
  #ylim(0.05,0.15)+
   geom_hline(yintercept=bayesian.fdr,linetype=&quot;dashed&quot;, color = &quot;red&quot;)

###############################################################################################################
###############################################################################################################
##################### true gamma.bar=5, use gamma.bar=3,4,5,6 ##########
gene.prior=0.1 # use true value
gene.fdr=list()
actual.fdr.range=matrix(nrow=4, ncol=num.run)
for (i in 3:6)
{
  #i=3
 ############ compute posterior probability for every gene ##########
 rm(&quot;all.delta.est&quot;, &quot;all.BF.gene&quot;, &quot;all.mirage.pvalue&quot;, &quot;all.skat.pvalue&quot;, &quot;all.fisher.pvalue&quot;, &quot;all.Ui&quot;)
 load(paste(&quot;../output/BayesianFDR/Mixed_Gene_Gammamean5_&quot;, &quot;useGammabar&quot;, i, &quot;.delta0.1_replicate100.RData&quot;, sep=&quot;&quot;)) 

 actual.fdr.range.single.run=numeric()
 for (run in 1:num.run)
 { #run=1
 Bayes.factor=tibble(BF=all.BF.gene[run,])
 gene.post=Bayes.factor %&gt;% mutate(post.prob=gene.prior*BF/(1-gene.prior+gene.prior*BF))
 gene.post=as_tibble(cbind(gene.post, RiskStatus=all.Ui[run,]))

 ################ calculate Bayesian FDR for every post prob cutoff ###########
tau=seq(0, 0.999, by=0.001)
num.pred=NULL
false.disc=NULL
FDR=NULL
for (ii in 1:length(tau))
{
num.pred[ii]=sum(ifelse(gene.post$post.prob&gt;tau[ii], 1, 0))
false.disc[ii]=sum((1-gene.post$post.prob)*ifelse(gene.post$post.prob&gt;tau[ii], 1, 0))
FDR[ii]=false.disc[ii]/num.pred[ii]
}
tau.fdr=tibble(tau=tau, bar.fdr=FDR)%&gt;%drop_na()  # drop rows with NA

############### calculate actual FDR #################################
bayes.fdr=seq(0, 0.5, length=100)
actual.fdr=numeric()
tau.select=numeric()
for (ii in 1:length(bayes.fdr))
{
  tau.select[ii]=max(tau.fdr %&gt;% filter(bar.fdr&gt;bayes.fdr[ii] &amp; bar.fdr&lt;bayes.fdr[ii]+0.1 ) %&gt;%  pull(tau))
  No.Disc=gene.post %&gt;% filter(post.prob&gt;tau.select[ii]) %&gt;% tally() %&gt;% pull()
  TP=gene.post %&gt;% filter(post.prob&gt;tau.select[ii]) %&gt;% filter(RiskStatus==1) %&gt;% tally() %&gt;% pull()
  # pull is used to convert tibble to a vector 
  actual.fdr[ii]=1-TP/No.Disc
} 
bayes.actual.fdr=tibble(Bayes.FDR=bayes.fdr, Actual.FDR=actual.fdr) %&gt;% mutate(Gamma.bar.use=i)
#gene.fdr[[i]]=list( gene.post=gene.post, bayes.actual.fdr=bayes.actual.fdr)

actual.fdr.range.single.run[run]=bayes.actual.fdr %&gt;% filter(Bayes.FDR&lt;bayesian.fdr-0.0001) %&gt;% summarize(Actual.FDR=max(Actual.FDR)) %&gt;% pull() # calculate the actual FDR when Bayesian.FDR=0.1
 } # end of run
 
 actual.fdr.range[i-2,]=actual.fdr.range.single.run
} # end of i



fdr.mean=rowMeans(actual.fdr.range)
fdr.sd=c(sd(actual.fdr.range[1,]), sd(actual.fdr.range[2,]), sd(actual.fdr.range[3,]), sd(actual.fdr.range[4,]))

bar.gamma=3:6
actual.fdr.summary=data.frame(mean=fdr.mean, sd=fdr.sd, bar.gamma=bar.gamma)
p3=ggplot(actual.fdr.summary, aes(x=bar.gamma, y=mean, group=1)) + 
   geom_point() +
  geom_pointrange(aes(ymin=mean-sd, ymax=mean+sd))+
  ggtitle(expression(paste(&quot;True &quot;, bar(gamma), &quot;=5&quot;)))+
  theme_classic()+
  theme(plot.title = element_text(hjust = 0.5, size=10))+  #center the title 
  xlab(expression(paste(bar(gamma))))+
  ylab(&quot;False Discovery Proportion&quot;)+ylim(c(0, max.ylab))+  
  guides(fill=guide_legend(title=NULL))+
  #ylim(0.05,0.15)+
   geom_hline(yintercept=bayesian.fdr,linetype=&quot;dashed&quot;, color = &quot;red&quot;)+
  theme(axis.title.y=element_text(size=8)) # adjust text size for y labels


###############################################################################################################
###############################################################################################################
##################### true gamma.bar=6, use gamma.bar=3,4,5,6 ##########

##################################################################
gene.prior=0.1 # use true value
gene.fdr=list()
bayesian.fdr=0.05
actual.fdr.range=matrix(nrow=4, ncol=num.run)
for (i in 3:6)
{
  #i=3
 ############ compute posterior probability for every gene ##########
 rm(&quot;all.delta.est&quot;, &quot;all.BF.gene&quot;, &quot;all.mirage.pvalue&quot;, &quot;all.skat.pvalue&quot;, &quot;all.fisher.pvalue&quot;, &quot;all.Ui&quot;)
 load(paste(&quot;../output/BayesianFDR/Mixed_Gene_Gammamean6_&quot;, &quot;useGammabar&quot;, i, &quot;.delta0.1_replicate100.RData&quot;, sep=&quot;&quot;)) 

 actual.fdr.range.single.run=numeric()
 for (run in 1:num.run)
 { #run=1
 Bayes.factor=tibble(BF=all.BF.gene[run,])
 gene.post=Bayes.factor %&gt;% mutate(post.prob=gene.prior*BF/(1-gene.prior+gene.prior*BF))
 gene.post=as_tibble(cbind(gene.post, RiskStatus=all.Ui[run,]))

 ################ calculate Bayesian FDR for every post prob cutoff ###########
tau=seq(0, 0.999, by=0.001)
num.pred=NULL
false.disc=NULL
FDR=NULL
for (ii in 1:length(tau))
{
num.pred[ii]=sum(ifelse(gene.post$post.prob&gt;tau[ii], 1, 0))
false.disc[ii]=sum((1-gene.post$post.prob)*ifelse(gene.post$post.prob&gt;tau[ii], 1, 0))
FDR[ii]=false.disc[ii]/num.pred[ii]
}
tau.fdr=tibble(tau=tau, bar.fdr=FDR)%&gt;%drop_na()  # drop rows with NA

############### calculate actual FDR #################################
bayes.fdr=seq(0, 0.5, length=100)
actual.fdr=numeric()
tau.select=numeric()
for (ii in 1:length(bayes.fdr))
{
  tau.select[ii]=max(tau.fdr %&gt;% filter(bar.fdr&gt;bayes.fdr[ii] &amp; bar.fdr&lt;bayes.fdr[ii]+0.1 ) %&gt;%  pull(tau))
  No.Disc=gene.post %&gt;% filter(post.prob&gt;tau.select[ii]) %&gt;% tally() %&gt;% pull()
  TP=gene.post %&gt;% filter(post.prob&gt;tau.select[ii]) %&gt;% filter(RiskStatus==1) %&gt;% tally() %&gt;% pull()
  # pull is used to convert tibble to a vector 
  actual.fdr[ii]=1-TP/No.Disc
} 
bayes.actual.fdr=tibble(Bayes.FDR=bayes.fdr, Actual.FDR=actual.fdr) %&gt;% mutate(Gamma.bar.use=i)
#gene.fdr[[i]]=list( gene.post=gene.post, bayes.actual.fdr=bayes.actual.fdr)

actual.fdr.range.single.run[run]=bayes.actual.fdr %&gt;% filter(Bayes.FDR&lt;bayesian.fdr-0.0001) %&gt;% summarize(Actual.FDR=max(Actual.FDR)) %&gt;% pull() # calculate the actual FDR when Bayesian.FDR=0.1
 } # end of run
 
 actual.fdr.range[i-2,]=actual.fdr.range.single.run
} # end of i



fdr.mean=rowMeans(actual.fdr.range)
fdr.sd=c(sd(actual.fdr.range[1,]), sd(actual.fdr.range[2,]), sd(actual.fdr.range[3,]), sd(actual.fdr.range[4,]))

bar.gamma=3:6
actual.fdr.summary=data.frame(mean=fdr.mean, sd=fdr.sd, bar.gamma=bar.gamma)
p4=ggplot(actual.fdr.summary, aes(x=bar.gamma, y=mean, group=1)) + 
   geom_point() +
  geom_pointrange(aes(ymin=mean-sd, ymax=mean+sd))+
  #geom_pointrange(aes(ymin=c(min(actual.fdr.range[1,]),min(actual.fdr.range[2,]), min(actual.fdr.range[3,]), min(actual.fdr.range[4,])), ymax=c(max(actual.fdr.range[1,]),max(actual.fdr.range[2,]), max(actual.fdr.range[3,]), max(actual.fdr.range[4,]))))+
  ggtitle(expression(paste(&quot;True &quot;, bar(gamma), &quot;=6&quot;)))+
  theme_classic()+
  theme(plot.title = element_text(hjust = 0.5, size=10))+  #center the title 
  xlab(expression(paste(bar(gamma))))+
  ylab(&quot;&quot;)+ylim(c(0, max.ylab))+  
  guides(fill=guide_legend(title=NULL))+
  #ylim(0.05,0.15)+
   geom_hline(yintercept=bayesian.fdr,linetype=&quot;dashed&quot;, color = &quot;red&quot;)+
  theme(axis.title.y=element_text(size=8)) # adjust text size for y labels



#pdf(&quot;C:/Users/hans/OneDrive - Marquette University/RareVariant/Fig-MIRAGE_gene_Bayes_FDR_misspecified_gammabar.pdf&quot;)
#pdf(&quot;C:/Shengtong/Research/rare-var/RareVariant/2023_0413_Figure_for_paper/Fig-MIRAGE_gene_Bayes_FDR_misspecified_gammabar3456.pdf&quot;)
#grid.arrange( p3, nrow=1)
grid.arrange(p1, p2, p3, p4, nrow=2)</code></pre>
<p><img src="simulation-study_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<pre class="r"><code>#dev.off()</code></pre>
</div>
</div>
</div>
<div id="logistic-priors" class="section level2">
<h2>Logistic priors</h2>
<div id="case-1-one-annotation-feature" class="section level3">
<h3>Case 1: One annotation feature</h3>
<div id="paramster-settings-1" class="section level4">
<h4>Paramster settings 1 :</h4>
<ul>
<li><span class="math inline">\(\delta=1\)</span></li>
<li><span class="math inline">\(N1=N0=5000\)</span></li>
<li>number of genes <span class="math inline">\(I=1000\)</span>, number
of variants per gene <span class="math inline">\(m=200\)</span> before
filtering.</li>
<li><span class="math inline">\(\alpha=\alpha_0=0.1\)</span>, <span
class="math inline">\(\beta_0=1000, \beta=2000\)</span>.</li>
<li><span class="math inline">\(\beta_{true}=0.5\)</span>, <span
class="math inline">\(\bar{\gamma}=10\)</span></li>
<li>80% elements of of Ajk are 1</li>
</ul>
<p>This is the simplest case in that every variant has one annotation
feature if any.</p>
</div>
<div id="likelihood-function" class="section level4">
<h4>likelihood function:</h4>
<p>If the feature has one dimension, the objective likelihood function
would be simple to be optimized using common R packages. The log
likelihood as a function of <span class="math inline">\(\beta\)</span>
(true <span class="math inline">\(\beta=0.5\)</span>)is as</p>
<p><img src="figure/loglikelihood.png" alt="loglikelihood" />.</p>
<p>This plot tells us the likelihood only has one mode in one dimension
case. It looks like <span class="math inline">\(\beta\)</span> is
overestimated by R package-BFGS. With the fixed randomly generated data,
run BFGS 50 times with random initials. The mean of <span
class="math inline">\(\hat{\beta}_{MLE}=0.7631\)</span> and
SD=2.344796e-05.</p>
</div>
<div
id="effect-of-sparsity-of-a_jk-k-is-the-number-of-features-here-k1-on-mle-of-beta"
class="section level4">
<h4>Effect of Sparsity of <span class="math inline">\(A_{jk}\)</span>
(<span class="math inline">\(k\)</span> is the number of features, here
<span class="math inline">\(k=1\)</span>) on MLE of <span
class="math inline">\(\beta\)</span></h4>
<p>Set <span class="math inline">\(\beta_{true}=0.5\)</span>, vary the
sparsity of <span class="math inline">\(A_{jk}\)</span>, i.e., the ratio
of 0’s in <span class="math inline">\(A_{jk}\)</span>. Define sparsity
rate as the ratio of 0’s in each feature category.</p>
<table style="width:100%;">
<caption>MLE at different sparsity rate <span
class="math inline">\(\beta_{true}=0.5\)</span></caption>
<colgroup>
<col width="16%" />
<col width="8%" />
<col width="10%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
</colgroup>
<thead>
<tr class="header">
<th>Sparsity rate</th>
<th>90%</th>
<th>80%</th>
<th>70%</th>
<th>60%</th>
<th>50%</th>
<th>40%</th>
<th>30%</th>
<th>20%</th>
<th>10%</th>
<th>0</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\hat{\beta}_{MLE}\)</span></td>
<td>0.3802</td>
<td>0.4499</td>
<td>0.5845</td>
<td>0.5420</td>
<td>0.5829</td>
<td>0.64444</td>
<td>0.6817</td>
<td>0.7608</td>
<td>0.7941</td>
<td>0.8896</td>
</tr>
</tbody>
</table>
<p>When All entries of <span class="math inline">\(A_{jk}\)</span> are
zero, <span class="math inline">\(\tau_j=\frac{1}{2}\)</span>,
regardless of whatever values of <span
class="math inline">\(\beta\)</span> and the likelihood function is a
constant of <span class="math inline">\(\beta\)</span>. Thus <span
class="math inline">\(\widehat{\beta}\)</span> can be anywhere.</p>
<p>Set <span class="math inline">\(\beta_{true}=0.2\)</span>.</p>
<table>
<caption>MLE at different sparsity rate with <span
class="math inline">\(\beta_{true}=0.2\)</span>.</caption>
<colgroup>
<col width="14%" />
<col width="8%" />
<col width="8%" />
<col width="9%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th>Sparsity rate</th>
<th>95%</th>
<th>90%</th>
<th>85%</th>
<th>80%</th>
<th>75%</th>
<th>70%</th>
<th>65%</th>
<th>60%</th>
<th>55%</th>
<th>50%</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\hat{\beta}_{MLE}\)</span></td>
<td>0.3075</td>
<td>0.2259</td>
<td>0.3481</td>
<td>0.3944</td>
<td>0.3677</td>
<td>0.4167</td>
<td>0.3956</td>
<td>0.4331</td>
<td>0.4565</td>
<td>0.4091</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div id="important-note" class="section level4">
<h4>Important Note:</h4>
<p>There are two variables affecting estimate of <span
class="math inline">\(\beta\)</span>, sparsity of <span
class="math inline">\(A_{jk}\)</span> and <span
class="math inline">\(\beta_{true}\)</span>. (1) <span
class="math inline">\(\beta\)</span> cannot be set too large, say &gt;10
because it controls the probability of a variant of being causal.
Consider an extreme case where all variants are truly causal risk
variants. The likelihood of the data is close to the product of Bayes
factor of every variant, free of <span
class="math inline">\(\beta\)</span> value. Any large enough <span
class="math inline">\(\beta\)</span> will give the same likelihood. (2)
Sparsity of <span class="math inline">\(A_{jk}\)</span> will certainly
influences the estimate of <span class="math inline">\(\beta\)</span>.
The less sparsity, the more information will be used, the more accurate
the estimate will be. (3) AF cannot be too large because for common
variants with large odds ratio (large <span
class="math inline">\(\bar{\gamma}\)</span>), Bayes factor will become
overflow of being Inf.</p>
</div>
<div id="parameter-setting-2-increasing-sample-size"
class="section level4">
<h4>Parameter setting 2-increasing sample size</h4>
<ul>
<li><span class="math inline">\(\delta=1\)</span></li>
<li><span class="math inline">\(\beta_{true}=2\)</span>, <span
class="math inline">\(\bar{\gamma}=10\)</span></li>
<li>all entries of <span class="math inline">\(A_{jk}\)</span> are
1</li>
<li><span class="math inline">\(\alpha=\alpha_0=0.1\)</span>, <span
class="math inline">\(\beta=1000, \beta_0=2000\)</span></li>
</ul>
<table>
<caption>MLE averaging across 10 replicates with different sample
size</caption>
<colgroup>
<col width="12%" />
<col width="10%" />
<col width="12%" />
<col width="64%" />
</colgroup>
<thead>
<tr class="header">
<th>N1=N0</th>
<th>10,000</th>
<th>50,000</th>
<th>100,000</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\widehat{\beta}_{MLE}\)</span> by
Optim</td>
<td>2.7810 (0.0362)</td>
<td>2.4413 (0.0161)</td>
<td>2.3420</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\widehat{\beta}_{MLE}\)</span> by
GLM</td>
<td>2.0016 (0.0126)</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>To use GLM, <span class="math inline">\(Z_{ij}\)</span> is treated as
response (but in practice, <span class="math inline">\(Z_{ij}\)</span>
is unknown) and each column of <span
class="math inline">\(A_{jk}\)</span> is a predictor, but without
intercept.</p>
<p>Use function GLM to estimate <span
class="math inline">\(\beta\)</span>.</p>
</div>
</div>
<div id="case-2-two-annotation-features" class="section level3">
<h3>Case 2: Two Annotation features</h3>
<p><span class="math inline">\(K=2\)</span>. Set <span
class="math inline">\(\beta_1=0.05, \beta_2=2\)</span>. Other parameters
are</p>
<ul>
<li><span class="math inline">\(\delta=1\)</span></li>
<li><span class="math inline">\(\bar{\gamma}=10\)</span></li>
<li><span class="math inline">\(\alpha=\alpha_0=0.1\)</span>, <span
class="math inline">\(\beta=1000, \beta_0=2000\)</span></li>
</ul>
<p>When there are more than 2 groups, <span
class="math inline">\(A_{ij}\)</span> must be designed carefully such
that all columns (all annotations) have as little overlap as possible.
Otherwise, the method have difficulty in distinguishing between them,
leading to poor estimate. In simulations below, these two factures have
no overlap.</p>
<table>
<caption>MLE averaging across 10 replicates with different sample
size</caption>
<colgroup>
<col width="12%" />
<col width="10%" />
<col width="12%" />
<col width="64%" />
</colgroup>
<thead>
<tr class="header">
<th>N1=N0</th>
<th>10,000</th>
<th>50,000</th>
<th>80,000</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\widehat{\beta_1}_{MLE}\)</span> by
Optim</td>
<td>0.3472 (0.0239)</td>
<td>0.2287 (0.0252)</td>
<td>0.2371 (0.0193)</td>
</tr>
<tr class="even">
<td><span class="math inline">\(\widehat{\beta_2}_{MLE}\)</span> by
Optim</td>
<td>2.7807 (0.0919)</td>
<td>2.4239 (0.0211)</td>
<td>2.3636 (0.0243)</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\widehat{\beta_1}_{MLE}\)</span> by
GLM</td>
<td>0.0517 (0.0159)</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\widehat{\beta_2}_{MLE}\)</span> by
GLM</td>
<td>1.9952 (0.0177)</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div id="case-3-many-annotation-features" class="section level3">
<h3>Case 3: Many annotation features</h3>
</div>
</div>
<div id="session-information" class="section level2">
<h2>Session information</h2>
<!-- Insert the session information into the document -->
</div>

<hr>
<p>
    This <a href="http://rmarkdown.rstudio.com">R Markdown</a> site was created with <a href="https://github.com/jdblischak/workflowr">workflowr</a>
</p>
<hr>

<!-- To enable disqus, uncomment the section below and provide your disqus_shortname -->

<!-- disqus
  <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'rmarkdown'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
