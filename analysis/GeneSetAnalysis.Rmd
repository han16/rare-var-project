---
title: "Gene Set Analysis"
author: "Shengtong Han"
date: YYYY-MM-DD
output: html_document
---

<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results='asis'}
```

<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
```{r code-version, echo=FALSE, results='asis'}
```

```{r load packages, results='hide', include=FALSE}
library(RSQLite)
library(dplyr)
library(knitr)
```

```{r defined function, echo=F, results='hide'}
test.func=function(evid, Data, N1, N0) # given evid, and sample size, perform the burden analysis
{
evid.data=Data[Data$ID %in% evid,]
count=c(sum(evid.data$No.case), sum(evid.data$No.contr))
Time=c(N1, N0)
pois.test=poisson.test(count, Time, r=1, alternative="greater")
return(result=list(odds.ratio=pois.test$estimate, p.value=pois.test$p.value, rate.case=count[1]/N1, rate.contr=count[2]/N0))
}
```

<!-- Add your analysis here -->

```{r read into data, echo=F, results='hide', cache=T}
All.Anno.Data=read.table("D:\\ResearchWork\\StatisticalGenetics\\Rare-variant-project\\AnnotatedTrans.txt", header=T)
```

```{r set paramters and modifying the data, echo=T, results='hide'}
N1=4315; N0=4315
All.Anno.Data[All.Anno.Data =="."] <- NA
All.Anno.Data$ExacAF[is.na(All.Anno.Data$ExacAF)]=0 # set AF of NA to zero 
Anno.Data=All.Anno.Data[which(All.Anno.Data$ExacAF<0.05 & All.Anno.Data$Annotation!="synonymous SNV"),] # use AF cutoff and exclude synonumous SNV
var.data=data.frame(ID=Anno.Data$ID, No.case=Anno.Data$No.case, No.contr=Anno.Data$No.contr)
LoF.def=c("stopgain", "frameshift substitution", "splicing", "stoploss")
LoF.var=as.character(Anno.Data$ID[which(Anno.Data$Annotation %in% LoF.def==T)]) 
```



## Simple burden test 

```{r burdern analysis-gene level, results='hide', echo=F}
GeneDB=src_sqlite(path="D:\\ResearchWork\\StatisticalGenetics\\Rare-variant-project\\gene.list.db", create=F)
gene_cate1=data.frame(collect(tbl(GeneDB, "SFARI_HighConf")))
gene_cate2=data.frame(collect(tbl(GeneDB, "SFARI_StrongCand")))
gene_cate3=data.frame(collect(tbl(GeneDB, "SFARI_cate3_gene")))
gene_cate4=data.frame(collect(tbl(GeneDB, "SFARI_cate4_gene")))
gene_cate5=data.frame(collect(tbl(GeneDB, "SFARI_cate5_gene")))
gene_cate6=data.frame(collect(tbl(GeneDB, "SFARI_cate6_gene")))
gene_cateS=data.frame(collect(tbl(GeneDB, "SFARI_cateS_gene")))
IDGene=data.frame(collect(tbl(GeneDB, "Pinto14AJHG_IDgene")))
TADAGene=data.frame(collect(tbl(GeneDB, "TADAGenelist")))
Qlessthan5percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.05]
Qlessthan20percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.2]
Qlessthan30percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.3]
Qlessthan40percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.4]
Qlessthan50percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.5]
Qlargerthan90percentgene=TADAGene$TadaName[TADAGene$qvalue.combined>0.9]
purcell.genelist=data.frame(collect(tbl(GeneDB, "Purcell2014_genelist"))) ## PSD gene, SCZdenovo gene 
ASD.gene=data.frame(collect(tbl(GeneDB, "AutismKB_gene")))
constraint.gene=data.frame(collect(tbl(GeneDB, "Samocha_2014NG_constraintgene")))$gene
RVIS.Allgene=data.frame(collect(tbl(GeneDB, "RVIS_gene")))
RVIS.gene=RVIS.Allgene$GeneID[RVIS.Allgene$RVIS.percentile<5] # top 5% gene 
haploinsuff.gene=data.frame(collect(tbl(GeneDB, "Petrovski_plosgen_haploinsuff_gene")))
gene.set=c("ID gene","High", "Mod", "PSD", "FMRP", "AutismKB", "constraint gene", "RVIS", "Haploinsuff gene", "SCZ gene", "Olfac.gene")
gene.fea=c("cate1", "cate2", "cate3", "cate4", "cate5", "cate6", "cateS", "TADAq<5%", "TADAq<20%", "TADAq<30%", "TADAq<40%", "TADAq<50%", "TADAq>90%", gene.set); max.gene=length(gene.fea)
gene.summy=matrix(nrow=max.gene+1, ncol=4)
gene.evid=list(); var.index=1
gene.evid[[1]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate1$GeneID )])
gene.evid[[2]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate2$GeneID )])
gene.evid[[3]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate3$GeneID )])
gene.evid[[4]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate4$GeneID )])
gene.evid[[5]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate5$GeneID )])
gene.evid[[6]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate6$GeneID )])
gene.evid[[7]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cateS$GeneID )])
gene.evid[[8]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan5percentgene )])
gene.evid[[9]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan20percentgene )])
gene.evid[[10]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan30percentgene )])
gene.evid[[11]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan40percentgene)])
gene.evid[[12]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan50percentgene )])
gene.evid[[13]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlargerthan90percentgene )])
gene.evid[[14]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% IDGene$GeneID )])
high.conf=union(union(gene_cate1$GeneID, gene_cate2$GeneID),Qlessthan5percentgene)
mod.conf=setdiff(union(union(gene_cate3$GeneID, gene_cateS$GeneID), Qlessthan30percentgene),Qlessthan5percentgene)
gene.evid[[15]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% high.conf)])
gene.evid[[16]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% mod.conf )])
psd.gene=purcell.genelist$Gene_symbol[purcell.genelist$PSD=="Y"]
FMRP.gene=purcell.genelist$Gene_symbol[purcell.genelist$FMRP.target=="Y"]
gene.evid[[17]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% psd.gene )])
gene.evid[[18]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% FMRP.gene )])
gene.evid[[19]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% ASD.gene$GeneID )])
gene.evid[[20]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% constraint.gene )])
gene.evid[[21]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% RVIS.gene )])
gene.evid[[22]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% haploinsuff.gene$GeneID )])
gene.evid[[23]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% purcell.genelist$Gene_symbol )])
olfac.gene=data.frame(collect(tbl(GeneDB, "Olfac_gene")))
gene.evid[[24]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% olfac.gene$GeneID )])
sczgene=as.character(read.table("D:\\ResearchWork\\StatisticalGenetics\\NumericAnalysis\\RealData\\SCZData\\GeneList\\SCZ.67gene.q0.3.txt", header=T)[[1]])
gene.evid[[25]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% sczgene )])

colnames(gene.summy)=c("OR", "p.value", "rate.ca", "rate.co")
rownames(gene.summy)=c(gene.fea, "67SCZriskgene")
LoF.summy=gene.summy
colnames(LoF.summy)=c("OR", "p.value", "No.ca", "No.co")
for (gene in 1:(max.gene+1))
{
  cat(gene, "is running", "\n")
  pois.test=test.func(gene.evid[[gene]], var.data, N1, N0)
  gene.summy[gene,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
  
  LoF.test=test.func(intersect(gene.evid[[gene]], LoF.var), var.data, N1, N0)
  LoF.summy[gene,]=c(LoF.test$odds.ratio, LoF.test$p.value, LoF.test$rate.case*N1, LoF.test$rate.contr*N0)
}

```
* Two sample one side ("greater") test
* high confidence gene: TADA q<0.05, [SFARI][sfari] cate1&2
* Moder confi: 0.3>TADA q>0.05 SFARI cat3 & S
* ID gene: 252 genes from AJHG [paper][paper] 
* 842 [FMRP][fmrp] gene
* 171 [AutismKB][autismkb] genes 
* 1003 [constraint][constraint] genes 
* [RVIS][rvis] gene
* [Haploinsufficient][haploinsufficient] genes 
* [Schizophrenia][schizophrenia], SCZ gene
* 861 [Olfactory][olfactory] gene 
* 67SCZ genes are from SCZ genes with cutoff 0.3. 
* de novo gene: TADA_SNV_CNV_combined_Feb7, look at column qvalue.combined, the smaller q value, the more likely to be risk gene 
* Constraint gene set: use Exac Constraint data ConstraintMat.RDS, look at the last column lof.Z, the smaller value the less constraint
* ASD prior list: ASD_Priors, look at the column-post, the larger, the more likely to be risk. 



[paper]:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4067558/
[sfari]:https://sfari.org/
[fmrp]:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3232425/
[autismkb]:http://autismkb.cbi.pku.edu.cn/
[constraint]:http://www.nature.com/ng/journal/v46/n9/abs/ng.3050.html?foxtrotcallback=true
[rvis]:http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1003709
[haploinsufficient]:http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1003709
[schizophrenia]:https://www.ncbi.nlm.nih.gov/pubmed/24463508
[olfactory]:http://www.genenames.org/genefamilies/OR






```{r gene level, echo=F}
kable(gene.summy, caption="Burden analysis of gene set")
kable(LoF.summy, caption="Burden analysis of LoF in different gene sets")
```





## Variant partitions
A gene usually has many variants such as missense, LoF, etc which contribute to the disease at different degree of deleteriousness. So we partition variants from all genes into different variant categories based on their annotation priors. 

### Eight variant groups 



Category | AF |fixed $\beta$
---------|--------------------------|-------------------------------
C1:LoF|   $0.01 \leq AF < 0.05$  |      $\beta_1= 0.5$  
C2:LoF|  $AF < 0.01$       |   $\beta_2=0.9$  
C3:Damaging| $0.01 \leq AF < 0.05$ |  $\beta_3= 0.1$ 
C4:Damaging|  $0.001 \leq  AF < 0.01$ |    $\beta_4= 0.2$ 
C5:Damaging|  $AF < 0.001$ |  $\beta_5=  0.4$ 
C6:Non-Damaging| $0.01 \leq  AF < 0.05$ |    $\beta_6= 0.05$ 
C7:Non-Damaging| $0.001 \leq AF < 0.01$ |  $\beta_7=  0.1$  
C8:Non-Damaging|  $AF < 0.001$ | $\beta_8=0.2$ 
Table: Fixed parameters for eight variant categories. 



* Damaging (probably damaging):Polyphen2.HDIV.score >=0.957


## Constraint (top 5%-1003) gene set 

Constraint gene set is from [this paper].

[this paper]: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4222185/



### Cons: Simple burden analysis

```{r, echo=F, results='hide'}
gene.set=as.character(read.csv("D:\\ResearchWork\\StatisticalGenetics\\Rare-variant-project\\rare-var-project\\data\\GeneSet\\Samocha_2014NG_contraintgene.csv", header=T)$gene)
cand.data=Anno.Data[which(Anno.Data$Gene %in% gene.set),]
par.evid=list()
par.evid[[1]]=which(cand.data$Annotation %in% LoF.def==T & cand.data$ExacAF<0.05 & cand.data$ExacAF>=0.01)
par.evid[[2]]=which(cand.data$Annotation %in% LoF.def==T &  cand.data$ExacAF<0.01)
par.evid[[3]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))>=0.957 & cand.data$ExacAF>=0.01 & cand.data$ExacAF<0.05)
par.evid[[4]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))>=0.957 & cand.data$ExacAF>=0.001 & cand.data$ExacAF<0.01)
par.evid[[5]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))>=0.957 & cand.data$ExacAF<0.001)
par.evid[[6]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))<0.957 & cand.data$ExacAF>=0.01 & cand.data$ExacAF<0.05)
par.evid[[7]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))<0.957 & cand.data$ExacAF>=0.001 & cand.data$ExacAF<0.01)
par.evid[[8]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))<0.957 & cand.data$ExacAF<0.001)
burden.summy=matrix(nrow=length(par.evid), ncol=4)
for (i in 1:length(par.evid))
{
  cat(i, "is running", "\n")
  pois.test=test.func(as.character(cand.data$ID[par.evid[[i]]]), var.data, N1, N0)
  burden.summy[i,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case*N1, pois.test$rate.contr*N0)
  }

```

The burden of 8 categories is 
```{r, echo=T}
colnames(burden.summy)=c("OR", "p.value", "No.ca", "No.co")
kable(burden.summy, caption="The burden of eight categories")
```


* The first catogry only has one common variant with 298/272. 


### Cons: Estimate $\beta_i$, common fixed $\delta$


Annotation category  | $\delta=0.1$ (test.stat) | $\delta=0.2$ (test.stat)
---------------------|---------------|-------------------
LoF,   $0.01 \leq AF < 0.05$  |      $\beta_1=0$ (0) | 0 (0)
LoF,  $AF < 0.01$ |         $\beta_2=0.54$ (0.63) | 0.39 (0.76)  
Damaging, $0.01 \leq AF < 0.05$ |   $\beta_3=0$ (0)| 0 (0)
Damaging,  $0.001 \leq  AF < 0.01$ |    $\beta_4=0$ (0) | 0 (0)
Damaging,  $AF < 0.001$ |  $\beta_5=0.23$ (5.42)| 0.15 (5.71)
Non-Damaging, $0.01 \leq  AF < 0.05$ |    $\beta_6=0$ (0) | 0 (0)
Non-Damaging, $0.001 \leq AF < 0.01$ |  $\beta_7=0$ (0) | 0 (0)
Non-Damaging,  $AF < 0.001$ | $\beta_8=0.24$ (3.11) | 0.16 (3.49)
Table: Parameter estimates of 1003 constraint genes by EM with eight partitions with fixed $\delta$. 



#### LoF category 

```{r, echo=T}
beta.est=c(0.49419653, 0.31677155, 0.22161936, 0.16934539, 0.13697687, 0.11502861, 0.09918004, 0.08717663, 0.07778499, 0.07022805)
delta=seq(0.1, 1, by=0.1)
plot(beta.est, xaxt='n', ylab=expression(paste(hat(beta))), main="Parameter estimate for LoF category", type="o", xlab=expression(paste(delta)))
axis.label=c("0.1", "0.2", "0.3", "0.4", "0.5", "0.6", "0.7", "0.8", "0.9", "1")
axis(1,at=1:10,labels=axis.label)
test.stat=c(0.6105703, 0.7301446, 0.7621092, 0.7772918, 0.7866515, 0.7931309, 0.7979188, 0.8016140, 0.8045560, 0.8069559, cex.axis=0.8)

```

### Cons: Fixed $\beta_i$


With fixed parameter in every variant group, calculate the BF of every gene which is the product of BF of every variant in this gene. Below are top 20 genes with large BF.   


Gene | BF | C1 | C2 | C3 | C4 | C5 | C6 | C7 | C8 | Rank | p-val
-----|----|----|----|----|----|----|----|----|----|------|------------------
CYFIP1 | 12.44 | - | - | - | 0.81 | 13.53 | - | 0.90 |  1.26 | 18200 | 0.0015
ABCA2 | 11.96 | - | - | - | - |  1.18 | - | - | 10.13 | 18210 | 0.0016
CACNA1D | 11.26 | - | - | - | - |  9.46 | 0.97 | 0.91 |  1.35 | 186 | 0.0018
FBN1 |  6.94 | - | - | - | 0.83 |  5.83 | 0.95 | 0.89 |  1.71 | 1324 | 0.0041
CIT |  6.68 | - | 1.63 | - | 5.90 |  0.45 | 0.95 | 0.70 |  2.31 | 13225 | 0.0044
PLXNB1 |  5.78 | - | - | - | - |  3.45 | - | - |  1.68 | 364 | 0.0057
CREBBP |  5.51 | - | - | - | - |  2.22 | - | 1.47 |  1.70 | 1232 | 0.0062
GTF3C4 |  5.50 | - | - | - | - |  4.85 | - | 0.92 |  1.23 | 15612 | 0.0063
MYH10 |  5.25 | - | - | - | - |  4.45 | - | 0.79 |  1.50 | 48 | 0.0068
DNM3 |  4.91 | - | 1.63 | - | - |  2.02 | - | 1.27 |  1.18 | 16092 | 0.0076
CHD8 |  4.79 | - | - | - | 0.77 |  6.66 | 0.97 | - |  0.96 | 2 | 0.008
TP63 |  4.05 | - | - | - | 0.81 |  2.66 | - | 0.92 |  2.05 | 15512 | 0.0108
DOCK4 |  3.91 | - | - | - | - |  4.47 | 0.90 | 0.90 |  1.07 | 18342 | 0.0116
CNOT1 |  3.73 | - | - | 0.91 | - |  3.25 | 1.06 | - |  1.19 | 8577 | 0.0128
HIRA |  3.04 | - | - | - | - |  2.37 | 1.06 | - |  1.21 | 17444 | 0.0192
ITSN1 |  2.94 | - | - | - | 0.91 |  3.23 | - | - |  1.00 | 1479 | 0.0205
HDLBP |  2.91 | - | - | - | - |  1.08 | - | 4.11 |  0.65 | 480 | 0.0210
BAZ1A |  2.89 | - | - | - | - |  2.79 | 1.02 | 0.85 |  1.20 | 1392 | 0.0212
SLC4A8 |  2.81 | - | - | - | - |  1.90 | - | - |  1.48 | 16562 | 0.0225
VPRBP |  2.79 | - | - | - | - |  3.80 | - | - |  0.73 | 1393 | 0.0230
Table: Bayes factor partition of top 20 genes from 1003 constraint genes. Rank: Rank by DNM; p-val: empirical p values by perturbating case control labels with null distribution of all constraint genes. ``-" means no variants in the category.


In top 1000 denovo genes, 5 are found in top 20 genes and 81 in all 1003 genes. Fisher exact test (5/20 vs 81/1003) gives OR=3.7857 and p value=0.0211.




ASD gene priors  for 1003 constraint genes. (1) Enrichment with top 1000 genes: 11/20 vs 261/1003, OR=3.4696, pvalue=0.008017; (2) enrichment with top 2000 genes: 12/20 vs 419/1003, OR=2.0892, p value=0.1135.


### Cons: Estimate $\beta_i$, gene specific $\delta_i$



#### (1) LoF only 

The burden is 622/583. $\widehat{\beta}=0.74$ and test statistic is 2.99. 


#### (2) Eight categories 


Annotation category  | $\widehat{\beta}$ | test.stat
---------------------|---------------|-------------------
LoF,   $0.01 \leq AF < 0.05$  |     0 | 0 
LoF,  $AF < 0.01$ |       0.81 | 2.98  
Damaging, $0.01 \leq AF < 0.05$ |   0| 0 
Damaging,  $0.001 \leq  AF < 0.01$ |  0 | 0 
Damaging,  $AF < 0.001$ | 0.12| 6.88
Non-Damaging, $0.01 \leq  AF < 0.05$ |  0 | 0 
Non-Damaging, $0.001 \leq AF < 0.01$ |  0 | 0 
Non-Damaging,  $AF < 0.001$ | 0.09 | 0
Table: Parameter estimates of 1003 constraint genes by EM with eight partitions with gene specific  $\delta$.


In top 1000 denovo genes, 6 are found in top 20 genes and 102 in all 1003 genes. Fisher exact test (6/20 vs 102/1003) gives OR=2.95, pvalue=0.0311.

ASD gene priors for 1003 constraint genes. (1) Enrichment with top 1000 genes: 10/20 vs 331/1003, OR=1.5146, pvalue=0.2896. 

## TADA gene (q<5%)

Only 46 genes with TADA q values less than 5%. 

### TADA: Estimate $\beta$, fixed $\delta=1$

#### Only LoF variants  

In the simple burden analysis (see Table above), LoF variants is 55/27. With $\delta=1$, $\widehat{\beta}=0.5692$, and test statistic is 12.0211. 

### TADA: Estimate $\beta_i$, gene specific $\delta_i$

Use 1-FDR of every gene as priors to estimate $\beta_i$. 


```{r, results="hide", echo=F, eval=F}
Bayesian.FDR <- function(BF, pi0, alpha=0.05) {
  # convert BFs to PPA (posterior probability of alternative model)
  # [BF]: a sorted vector of BFs (in decreasing order)
  # [pi0]: the prior probability that the null model is true
  # [alpha]: the FDR target
  # [Return]: the q-value of each BF, and the number of findings with q below alpha. 
  pi <- 1-pi0
  q <- pi*BF/(1-pi+pi*BF) # PPA
  q0 <- 1 - q # posterior probability of null model
  
  # the FDR at each PPA cutoff
  n <- length(BF)
  FDR <- numeric(n)
  for (i in 1:n) FDR[i] <- sum(q0[1:i]) / i 
  
  # the cutoff
  t <- 1
  while (t <= length(q0) & mean(q0[1:t]) <= alpha) { t <- t+1 }
  return (list(FDR=FDR, ND=t))
}
```

####  Only LoF category 

$\widehat{\beta}=0.63$, test statistics is 10.07. 

## RVIS gene (quantile score <50)

There are 8437 genes. 


### RVIS:Estimate $\beta_i$, gene specific $\delta_i$ 

Annotation category  | $\widehat{\beta}$ | test.stat
---------------------|---------------|-------------------
LoF,   $0.01 \leq AF < 0.05$  |     0 | 0 
LoF,  $AF < 0.01$ |       0.17 | 6.06  
Damaging, $0.01 \leq AF < 0.05$ |   0| 0 
Damaging,  $0.001 \leq  AF < 0.01$ |  0 | 0 
Damaging,  $AF < 0.001$ | 0.06| 13.55
Non-Damaging, $0.01 \leq  AF < 0.05$ |  0 | 0 
Non-Damaging, $0.001 \leq AF < 0.01$ |  0 | 0 
Non-Damaging,  $AF < 0.001$ | 0.08 | 11.34
Table: Parameter estimates of 8437 RVIS genes by EM with eight partitions with gene specific  $\delta_i$.




## Whole genome 

consider all 15624 genes in ASD data. 

### Whole: Estimate $\beta_i$, gene specific $\delta_i$

Annotation category  | $\widehat{\beta}$ | test.stat
---------------------|---------------|-------------------
LoF,   $0.01 \leq AF < 0.05$  |     0 | 0 
LoF,  $AF < 0.01$ |       0.08 | 3.94  
Damaging, $0.01 \leq AF < 0.05$ |   0| 0 
Damaging,  $0.001 \leq  AF < 0.01$ |  0 | 0 
Damaging,  $AF < 0.001$ | 0.06| 23.85
Non-Damaging, $0.01 \leq  AF < 0.05$ |  0 | 0 
Non-Damaging, $0.001 \leq AF < 0.01$ |  0 | 0 
Non-Damaging,  $AF < 0.001$ | 0.06 | 11.42
Table: Parameter estimates of 15624 genes by EM with eight partitions with gene specific  $\delta_i$.




## Session information

<!-- Insert the session information into the document -->
```{r session-info}
```
