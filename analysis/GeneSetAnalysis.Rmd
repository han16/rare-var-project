---
title: "Gene Set Analysis"
author: "Shengtong Han"
date: YYYY-MM-DD
output: html_document
---



```{r load packages, results='hide', include=FALSE}
library(RSQLite)
library(dplyr)
library(knitr)
library(kableExtra)
library(ggplot2)
library(tidyverse)
library(viridis)
```

```{r defined function, echo=F, results='hide'}
test.func=function(evid, Data, N1, N0) # given evid, and sample size, perform the burden analysis
{
evid.data=Data[Data$ID %in% evid,]
count=c(sum(evid.data$No.case), sum(evid.data$No.contr))
Time=c(N1, N0)
pois.test=poisson.test(count, Time, r=1, alternative="greater")
return(result=list(odds.ratio=pois.test$estimate, p.value=pois.test$p.value, rate.case=count[1]/N1, rate.contr=count[2]/N0))
}
```

```{r, echo=F}
loadRData <- function(fileName){
#loads an RData file, and returns it
    load(fileName)
    get(ls()[ls() != "fileName"])
}
```

```{r, echo=F}
eight.partition=function(cand.data) # given gene data and annotations, do variant partitions
{
  par.evid=list()
  LoF.def=c("stopgain", "frameshift substitution", "splicing", "stoploss")
  par.evid[[1]]=which(cand.data$Annotation %in% LoF.def==T & cand.data$ExacAF<0.05 & cand.data$ExacAF>=0.01 )
  par.evid[[2]]=which(cand.data$Annotation %in% LoF.def==T &  cand.data$ExacAF<0.01)

  par.evid[[3]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))>=0.957 & cand.data$ExacAF>=0.01 & cand.data$ExacAF<0.05)
  par.evid[[4]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))>=0.957 & cand.data$ExacAF>=0.001 & cand.data$ExacAF<0.01)
  par.evid[[5]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))>=0.957 &  cand.data$ExacAF<0.001)

  par.evid[[6]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))<0.957 & cand.data$ExacAF>=0.01 & cand.data$ExacAF<0.05)
  par.evid[[7]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))<0.957 & cand.data$ExacAF>=0.001 & cand.data$ExacAF<0.01)
  par.evid[[8]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))<0.957 & cand.data$ExacAF<0.001)

  group.index=rep(NA, nrow(cand.data))
  for (i in 1:length(par.evid))
    group.index[par.evid[[i]]]=i
  gene.data=data.frame(ID=cand.data$ID, Gene=cand.data$Gene, No.case=cand.data$No.case, No.contr=cand.data$No.contr, group.index=group.index)
  gene.data=gene.data[complete.cases(gene.data),]
  return(gene.data)
}
```

<!-- Add your analysis here -->

```{r read into data, echo=F, results='hide', cache=T}
All.Anno.Data=as_tibble(read.table("../../AnnotatedTrans.txt", header=T))
```

```{r set paramters and modifying the data, echo=T, results='hide'}
N1=4315; N0=4315
All.Anno.Data[All.Anno.Data =="."] <- NA
All.Anno.Data$ExacAF[is.na(All.Anno.Data$ExacAF)]=0 # set AF of NA to zero 
Anno.Data=All.Anno.Data[which(All.Anno.Data$ExacAF<0.05 & All.Anno.Data$Annotation!="synonymous SNV"),] # use AF cutoff and exclude synonumous SNV
var.data=as_tibble(data.frame(ID=Anno.Data$ID, No.case=Anno.Data$No.case, No.contr=Anno.Data$No.contr))
LoF.def=c("stopgain", "frameshift substitution", "splicing", "stoploss")
LoF.var=as.character(Anno.Data$ID[which(Anno.Data$Annotation %in% LoF.def==T)]) 
```



## Simple burden test 

```{r burdern analysis-gene level, results='hide', echo=F}
GeneDB=src_sqlite(path="..\\..\\gene.list.db", create=F)
gene_cate1=data.frame(collect(tbl(GeneDB, "SFARI_HighConf")))
gene_cate2=data.frame(collect(tbl(GeneDB, "SFARI_StrongCand")))
gene_cate3=data.frame(collect(tbl(GeneDB, "SFARI_cate3_gene")))
gene_cate4=data.frame(collect(tbl(GeneDB, "SFARI_cate4_gene")))
gene_cate5=data.frame(collect(tbl(GeneDB, "SFARI_cate5_gene")))
gene_cate6=data.frame(collect(tbl(GeneDB, "SFARI_cate6_gene")))
gene_cateS=data.frame(collect(tbl(GeneDB, "SFARI_cateS_gene")))
IDGene=data.frame(collect(tbl(GeneDB, "Pinto14AJHG_IDgene")))
TADAGene=data.frame(collect(tbl(GeneDB, "TADAGenelist")))
Qlessthan5percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.05]
Qlessthan20percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.2]
Qlessthan30percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.3]
Qlessthan40percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.4]
Qlessthan50percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.5]
Qlargerthan90percentgene=TADAGene$TadaName[TADAGene$qvalue.combined>0.9]
purcell.genelist=data.frame(collect(tbl(GeneDB, "Purcell2014_genelist"))) ## PSD gene, SCZdenovo gene 
ASD.gene=data.frame(collect(tbl(GeneDB, "AutismKB_gene")))
constraint.gene=data.frame(collect(tbl(GeneDB, "Samocha_2014NG_constraintgene")))$gene
RVIS.Allgene=data.frame(collect(tbl(GeneDB, "RVIS_gene")))
RVIS.gene=RVIS.Allgene$GeneID[RVIS.Allgene$RVIS.percentile<5] # top 5% gene 
haploinsuff.gene=data.frame(collect(tbl(GeneDB, "Petrovski_plosgen_haploinsuff_gene")))
gene.set=c("ID gene","High conf", "Mod conf", "PSD", "FMRP", "AutismKB", "constraint gene", "RVIS", "Haploinsuff gene", "SCZ gene", "Olfac.gene")
gene.fea=c("cate1", "cate2", "cate3", "cate4", "cate5", "cate6", "cateS", "TADAq<5%", "TADAq<20%", "TADAq<30%", "TADAq<40%", "TADAq<50%", "TADAq>90%", gene.set); max.gene=length(gene.fea)
gene.summy=matrix(nrow=max.gene+1, ncol=4)
gene.evid=list(); var.index=1
gene.evid[[1]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate1$GeneID )])
gene.evid[[2]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate2$GeneID )])
gene.evid[[3]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate3$GeneID )])
gene.evid[[4]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate4$GeneID )])
gene.evid[[5]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate5$GeneID )])
gene.evid[[6]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate6$GeneID )])
gene.evid[[7]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cateS$GeneID )])
gene.evid[[8]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan5percentgene )])
gene.evid[[9]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan20percentgene )])
gene.evid[[10]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan30percentgene )])
gene.evid[[11]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan40percentgene)])
gene.evid[[12]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan50percentgene )])
gene.evid[[13]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlargerthan90percentgene )])
gene.evid[[14]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% IDGene$GeneID )])
high.conf=union(union(gene_cate1$GeneID, gene_cate2$GeneID),Qlessthan5percentgene)
mod.conf=setdiff(union(union(gene_cate3$GeneID, gene_cateS$GeneID), Qlessthan30percentgene),Qlessthan5percentgene)
gene.evid[[15]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% high.conf)])
gene.evid[[16]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% mod.conf )])
psd.gene=purcell.genelist$Gene_symbol[purcell.genelist$PSD=="Y"]
FMRP.gene=purcell.genelist$Gene_symbol[purcell.genelist$FMRP.target=="Y"]
gene.evid[[17]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% psd.gene )])
gene.evid[[18]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% FMRP.gene )])
gene.evid[[19]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% ASD.gene$GeneID )])
gene.evid[[20]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% constraint.gene )])
gene.evid[[21]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% RVIS.gene )])
gene.evid[[22]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% haploinsuff.gene$GeneID )])
gene.evid[[23]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% purcell.genelist$Gene_symbol )])
olfac.gene=data.frame(collect(tbl(GeneDB, "Olfac_gene")))
gene.evid[[24]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% olfac.gene$GeneID )])
#sczgene=as.character(read.table("D:\\ResearchWork\\StatisticalGenetics\\NumericAnalysis\\RealData\\SCZData\\GeneList\\SCZ.67gene.q0.3.txt", header=T)[[1]])
#gene.evid[[25]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% sczgene )])

colnames(gene.summy)=c("OR", "p.value", "rate.ca", "rate.co")
rownames(gene.summy)=c(gene.fea, "67SCZriskgene")
LoF.summy=gene.summy
colnames(LoF.summy)=c("OR", "p.value", "No.ca", "No.co")
for (gene in 1:(max.gene))
{
  cat(gene, "is running", "\n")
  pois.test=test.func(gene.evid[[gene]], var.data, N1, N0)
  gene.summy[gene,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
  
  LoF.test=test.func(intersect(gene.evid[[gene]], LoF.var), var.data, N1, N0)
  LoF.summy[gene,]=c(LoF.test$odds.ratio, LoF.test$p.value, LoF.test$rate.case*N1, LoF.test$rate.contr*N0)
}

```
* Two sample one side ("greater") test
* high confidence gene: TADA q<0.05, [SFARI][sfari] cate1&2
* Moder confi: 0.3>TADA q>0.05 SFARI cat3 & S
* ID gene: 252 genes from AJHG [paper][paper] 
* 842 [FMRP][fmrp] gene
* 171 [AutismKB][autismkb] genes 
* 1003 [constraint][constraint] genes 
* [RVIS][rvis] gene
* [Haploinsufficient][haploinsufficient] genes 
* [Schizophrenia][schizophrenia], SCZ gene
* 861 [Olfactory][olfactory] gene 
* 67SCZ genes are from SCZ genes with cutoff 0.3. 
* de novo gene: TADA_SNV_CNV_combined_Feb7, look at column qvalue.combined, the smaller q value, the more likely to be risk gene 
* Constraint gene set: use Exac Constraint data ConstraintMat.RDS, look at the last column lof.Z, the smaller value the less constraint
* ASD prior list: ASD_Priors, look at the column-post, the larger, the more likely to be risk. 



[paper]:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4067558/
[sfari]:https://sfari.org/
[fmrp]:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3232425/
[autismkb]:http://autismkb.cbi.pku.edu.cn/
[constraint]:http://www.nature.com/ng/journal/v46/n9/abs/ng.3050.html?foxtrotcallback=true
[rvis]:http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1003709
[haploinsufficient]:http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1003709
[schizophrenia]:https://www.ncbi.nlm.nih.gov/pubmed/24463508
[olfactory]:http://www.genenames.org/genefamilies/OR






```{r gene level, echo=F}
kable(gene.summy, caption="Burden analysis of gene set", "html")%>%
kable_styling() %>%
scroll_box(height = "200px")

kable(LoF.summy, caption="Burden analysis of LoF in different gene sets", "html")%>%
kable_styling() %>%
scroll_box(height = "200px")
```

```{r, echo=F, eval=F}
#pdf("D:\\ResearchWork\\StatisticalGenetics\\Latex\\Paper\\PLoS\\Figure\\burden_geneset.pdf")
barcenters=barplot(gene.summy[1:22,1], xlab="OR", pch=19, xlim=c(0, max(gene.summy[1:22,1])+0.5), ylab="", yaxt='n', main="", col="blue", horiz=T, width=0.85)
lines(-log(gene.summy[1:22,2], base=10), barcenters, pch=16, col=2, type="p")
abline(v=1, col="blue", lty=4)
abline(v=-log(0.05, base=10), col=2, lty=4)
axis.labels <-row.names(gene.summy[1:22,])
axis(2, las=2, at=seq(1,length(axis.labels)), labels=axis.labels, cex.axis=0.5)
legend(1.32, 21, c("OR", "-log(p.val)"), col=c("blue",2), pch=c(15,16), cex=0.8)
#dev.off()
```



```{r, echo=F}
Gene=row.names(gene.summy)[1:22]
OR=gene.summy[1:22,1]; pval=gene.summy[1:22,2]
result.summary=tibble(Gene=Gene, OR=OR, pval=pval)
# pdf("../../Figure/burden_geneset.pdf")
  ggplot(result.summary, aes(x=Gene, y=OR, fill=Gene))+
  geom_bar(stat="identity")+
  ylab("")+xlab("Gene")+ ggtitle("Burden analysis for gene sets")+
   geom_point(mapping=aes(x=Gene, y=-log(pval, base=10), size=-log(pval, base=10), fill=Gene), alpha=0.8)+ 
    coord_flip()+
    scale_color_viridis(discrete=T)+
    geom_hline(yintercept=1,linetype="dashed")+
  geom_hline(yintercept=-log(0.05, base=10), linetype="dashed", color = "red")+
    #theme(legend.position = "none")+  # no legend at all 
    guides(fill = FALSE)+
  theme(plot.title = element_text(hjust = 0.5, size=10)) #center the title 
  
#dev.off()
```
  



## Variant partitions
A gene usually has many variants such as missense, LoF, etc which contribute to the disease at different degree of deleteriousness. So we partition variants from all genes into different variant categories based on their annotation priors. 

### Eight variant groups 



Category | AF |fixed $\eta$
---------|--------------------------|-------------------------------
C1:LoF|   $0.01 \leq AF < 0.05$  |      $\eta_1= 0.5$  
C2:LoF|  $AF < 0.01$       |   $\eta_2=0.9$  
C3:Damaging| $0.01 \leq AF < 0.05$ |  $\eta_3= 0.1$ 
C4:Damaging|  $0.001 \leq  AF < 0.01$ |    $\eta_4= 0.2$ 
C5:Damaging|  $AF < 0.001$ |  $\eta_5=  0.4$ 
C6:Non-Damaging| $0.01 \leq  AF < 0.05$ |    $\eta_6= 0.05$ 
C7:Non-Damaging| $0.001 \leq AF < 0.01$ |  $\eta_7=  0.1$  
C8:Non-Damaging|  $AF < 0.001$ | $\eta_8=0.2$ 
Table: Fixed parameters for eight variant categories. 



* Damaging (probably damaging):Polyphen2.HDIV.score >=0.957


## Constraint (top 5%~1003) gene set 

Constraint gene set is from [this paper].

[this paper]: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4222185/



### Cons: Simple burden analysis

```{r, echo=F, results='hide'}
gene.set=as.character(read.csv("../data/GeneSet/Samocha_2014NG_contraintgene.csv", header=T)$gene)
cand.data=as_tibble(Anno.Data[which(Anno.Data$Gene %in% gene.set),])
par.evid=list()
par.evid[[1]]=cand.data %>% filter(Annotation%in%LoF.def)%>% filter(between(ExacAF, 0.01, 0.05))
par.evid[[2]]=cand.data %>% filter(Annotation%in%LoF.def) %>% filter(between(ExacAF, 0, 0.01))
par.evid[[3]]=cand.data %>% filter(Annotation %in% LoF.def==F) %>% filter(between(as.numeric(as.character(Polyphen2.HDIV.score)), 0.957, 1)) %>% filter(between(ExacAF, 0.01, 0.05))
par.evid[[4]]=cand.data %>% filter(Annotation %in% LoF.def==F) %>% filter(between(as.numeric(as.character(Polyphen2.HDIV.score)), 0.957, 1)) %>% filter(between(ExacAF, 0.001, 0.01))
par.evid[[5]]=cand.data %>% filter(Annotation %in% LoF.def==F) %>% filter(between(as.numeric(as.character(Polyphen2.HDIV.score)), 0.957, 1)) %>% filter(between(ExacAF, 0, 0.001))
par.evid[[6]]=cand.data %>% filter(Annotation %in% LoF.def==F) %>% filter(between(as.numeric(as.character(Polyphen2.HDIV.score)), 0, 0.957)) %>% filter(between(ExacAF, 0.01, 0.05))
par.evid[[7]]=cand.data %>% filter(Annotation %in% LoF.def==F) %>% filter(between(as.numeric(as.character(Polyphen2.HDIV.score)), 0, 0.957)) %>% filter(between(ExacAF, 0.001, 0.01))
par.evid[[8]]=cand.data %>% filter(Annotation %in% LoF.def==F) %>% filter(between(as.numeric(as.character(Polyphen2.HDIV.score)), 0, 0.957)) %>% filter(between(ExacAF, 0, 0.001))

burden.summy=matrix(nrow=length(par.evid), ncol=4)
for (i in 1:length(par.evid))
{
  cat(i, "is running", "\n")
  pois.test=test.func(par.evid[[i]]$ID, var.data, N1, N0)
  burden.summy[i,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case*N1, pois.test$rate.contr*N0)
  }

```

```{r, echo=F}
unique.gene=unique(cand.data$Gene)
var.count=numeric()
for (i in 1:length(unique.gene))
{
  single.gene=cand.data[which(cand.data$Gene==unique.gene[i]),]
  var.count[i]=sum(single.gene$No.case)+sum(single.gene$No.contr)
}
```

```{r, echo=F, warning=F}
gene.var.count=data.frame(Gene=unique.gene, var.count=var.count)
ggplot(gene.var.count, aes(x=var.count))+ 
  geom_histogram()+
  geom_vline(aes(xintercept=mean(var.count)),
            color="blue", linetype="dashed", size=1)+
  xlab("#.variant")+
  ylab("#.gene")+
  ggtitle("Histogram of variants in top constraint genes")+
  theme(plot.title = element_text(hjust = 0.5, size=10)) #center the title 

```



The burden of 8 categories is 
```{r, echo=F}
colnames(burden.summy)=c("OR", "p.value", "No.ca", "No.co")
kable(burden.summy, caption="The burden of eight categories", "html")%>%
kable_styling() %>%
scroll_box(height = "200px")
```

```{r, echo=F, eval=F}
#pdf("D:\\ResearchWork\\StatisticalGenetics\\Latex\\Paper\\PLoS\\Figure\\burden_constgene.pdf")
barcenters=barplot(burden.summy[,1], xlab="OR", pch=19, xlim=c(0, 1.7), ylab="", yaxt='n', main="", col="blue", horiz=T, width=0.9)
lines(-log(burden.summy[,2], base=10), barcenters, pch=16, col=2, type="p")
abline(v=1, col="blue", lty=4)
abline(v=-log(0.05, base=10), col=2, lty=4)
axis.labels <-seq(1,8)
axis(2, las=2, at=seq(1,length(axis.labels)), labels=axis.labels, cex.axis=1)
legend(1.32, 8, c("OR", "-log(p.val)"), col=c("blue",2), pch=c(15,16), cex=1)
#dev.off()
```

```{r, echo=F}
Cate=c("1", "2", "3", "4", "5", "6", "7", "8")
OR=burden.summy[,1]; pval=burden.summy[,2]
result.summary=tibble(Cate=Cate, OR=OR, pval=pval)
result.summary$Cate=result.summary$Cate %>% recode("1"="LoF; 1%<AF<5%", "2"="LoF; AF<1%", "3" = "Damaging; 1%<AF<5%","4"= "Damaging; 0.1%<FA<1%", "5" ="Damaging; AF<0.1%", "6" ="Non-damaging; 1%<AF<5%", "7" ="Non-damaging; 0.1%<AF<1%", "8" ="Non-damaging; AF<0.1%")

 #pdf("C:\\Users\\han24\\OneDrive - UWM\\rare-var\\Figure\\Supp\\Fig-burden_variant_group_of_constgene.pdf")
  ggplot(result.summary, aes(x=Cate, y=OR, fill=Cate))+
  geom_bar(stat="identity")+
  ylab("")+xlab("")+ ggtitle("")+
   geom_point(aes(x=Cate, y=-log(pval, base=10), size=-log(pval, base=10)))+ 
    coord_flip()+
    geom_hline(yintercept=1,linetype="dashed")+
  geom_hline(yintercept=-log(0.05, base=10), linetype="dashed", color = "red")+
    #scale_color_viridis(discrete=T)+
    guides(fill = FALSE)+
  theme(plot.title = element_text(hjust = 0.5, size=10))+ #center the title
    theme(axis.text.y = element_text(angle = 0, hjust = 1,size=7))+
    labs(size=expression(paste("-log"[10], "(p value)")))+ # the argument in labs could be size, color, fill depends on which character the legend demonstrate!!!!!!!!
    theme(legend.text = element_text(size = 7))+ # change legend text size 
    theme(legend.title=element_text(size=10))#+
    #theme(legend.position="bottom")
#dev.off()
```


* The first catogry only has one common variant with 298/272. 

### Cons: Estimate all parameters, $\delta, \eta$


#### Parameter estimate 



```{r, echo=F}
#pdf("C:/Users/han24/OneDrive - UWM/rare-var/Figure/Supp/Fig-MIRAGE-para_est_ASD_topconstgene_var_group.pdf")
cate.index=1:8
para.est=tibble(cate.index=cate.index, eta.est=c(0, 0.41, 0, 0, 0.16, 0, 0, 0.17))
para.est$cate.index=para.est$cate.index %>% recode("1"="LoF; 1%<AF<5%", "2"="LoF; AF<1%", "3" = "Damaging; 1%<AF<5%","4"= "Damaging; 0.1%<FA<1%", "5" ="Damaging; AF<0.1%", "6" ="Non-damaging; 1%<AF<5%", "7" ="Non-damaging; 0.1%<AF<1%", "8" ="Non-damaging; AF<0.1%")
#para.est$cate.index=as.factor(para.est$cate.index)
ggplot(para.est, aes(x=cate.index, y=eta.est, fill=cate.index)) + 
   geom_bar(stat="identity")+
  theme_classic()+
 # coord_flip()+
 # theme(legend.title=element_blank())+
  theme(legend.position = "none")+
  xlab("")+
  ylab(expression(paste(hat(eta))))+
  theme(plot.title = element_text(hjust = 0.5, size=7))+  #center the title+
theme(axis.text.x = element_text(angle = 45, vjust = 0.5, size=7))
#dev.off()
```


$\hat{\delta}=0.18$. 


#### Top genes overlapping with SFARI genes 


```{r, echo=F}
BF_para_all_est=loadRData("../output/para.est.constraint.gene.estimate.delta.RData")
Bayes_factor=as_tibble(BF_para_all_est)

sort_BF=Bayes_factor %>% arrange(desc(BF))
top10genes=as.character(sort_BF$Gene[1:10])
all.const.gene=as.character(sort_BF$Gene)
SFARI.gene=read.csv("../data/GeneSet/SFARI-Gene_genes_06-20-2019release_07-15-2019export.csv", header=T)
## Top 10 genes 
top10genes
######################

strong.ASD.gene=c(as.character(SFARI.gene[which(SFARI.gene$gene.score==1), ]$gene.symbol), as.character(SFARI.gene[which(SFARI.gene$gene.score==2), ]$gene.symbol), as.character(SFARI.gene[which(SFARI.gene$gene.score==3), ]$gene.symbol))  # define strong ASD gene with score 1,2,3
overlap1=length(intersect(top10genes, strong.ASD.gene))
overlap2=length(intersect(all.const.gene, strong.ASD.gene))
fisher.test(matrix(c(overlap1, overlap2, 10, 1003), nrow=2))


##########################
strong.ASD.gene=c(as.character(SFARI.gene[which(SFARI.gene$gene.score==1), ]$gene.symbol), as.character(SFARI.gene[which(SFARI.gene$gene.score==2), ]$gene.symbol))  # define strong ASD gene with score 1,2,3
overlap1=length(intersect(top10genes, strong.ASD.gene))
overlap2=length(intersect(all.const.gene, strong.ASD.gene))
fisher.test(matrix(c(overlap1, overlap2, 10, 1003), nrow=2))


```

strong ASD gene score 1,2,3 : enrichemnt is 8/10 vs 76/1003 gives OR 10.5058 and p value $1.98\times 10^{-5}$

strong ASD gene score 1,2: enrichemnt is 4/10 vs 31/1003 gives OR 12.8417 and p value $8.24\times 10^{-4}$

#### Bayesian FDR 

Below are top risk genes with highest Bayes factor and enrichment with de novo rank. 

```{r, echo=F}
BF_para_all_est=loadRData("../output/para.est.constraint.gene.estimate.delta.RData")
denovo.gene=read.table("..\\..\\GeneSet\\TADA_SNV_CNV_combined\\TADA_SNV_CNV_combined_Feb7.txt", header=T)
rank.denovo.gene=denovo.gene[order(denovo.gene$qvalue.combined),]
top1000.denovo.gene=rank.denovo.gene$RefSeqName[1:1000]
top.const.overlap.withdenovo=length(intersect(top1000.denovo.gene, BF_para_all_est$Gene))

Bayes_factor=as_tibble(BF_para_all_est)
sort_BF=Bayes_factor %>% arrange(desc(BF))
#sort_BF %>% print(n=20)

#################### non-overlapping 
num.top.gene=seq(20,100, by=20)
enrichment=matrix(nrow=length(num.top.gene), ncol=3)
colnames(enrichment)=c("OR", "pvalue", "num.top.gene")
for (i in 1:length(num.top.gene))
{ #i=2
  if (i==1)
   topgene=as.character(sort_BF$Gene)[1:num.top.gene[i]]
  if (i>1)
    topgene=as.character(sort_BF$Gene)[num.top.gene[i-1]:num.top.gene[i]]  # non-overlapping gene sets 
  
  overlap=length(intersect(topgene, top1000.denovo.gene))
  enrichment.test=fisher.test(matrix(c(overlap, top.const.overlap.withdenovo, 20, 1003), nrow=2))
enrichment[i,]=c(enrichment.test$estimate, enrichment.test$p.value, num.top.gene[i])  
}

enrichment.result=as_tibble(enrichment)
enrichment.result$pvalue=round(enrichment.result$pvalue,4)
#enrichment.result$num.top.gene=enrichment.result$num.top.gene %>% recode("20"="Top 20", "40"="Top 40", "60" = "Top 60","80"= "Top 80", "100" ="Top 100", "120"="Top 120")
#enrichemnt.test$num.top.gene=factor(enrichment.result$num.top.gene, levels=c("20", " 40", " 60", " 80", " 100", "120"))

#pdf("C:/Users/han24/OneDrive - UWM/rare-var/Figure/Main/Fig-overlap.with.denovo.gene.pdf")
ggplot(enrichment.result, aes(x=num.top.gene, y=OR)) + 
   geom_bar(stat="identity", fill="blue")+
  theme_classic()+
 # coord_flip()+
 # theme(legend.title=element_blank())+
  theme(legend.position = "none")+
  xlab("")+
  ylab("OR")+
  theme(plot.title = element_text(hjust = 0.5, size=7))+  #center the title+
theme(axis.text.x = element_text(angle =0, vjust = 0.5, size=7))+
  scale_x_continuous("", labels = as.character(num.top.gene), breaks = num.top.gene)+ # list all x labels
  geom_text(aes(label=pvalue), position=position_dodge(width=0.9), vjust=-0.25)
#dev.off()

################ overlapping 

num.top.gene=seq(20,100, by=20)
enrichment=matrix(nrow=length(num.top.gene), ncol=3)
colnames(enrichment)=c("OR", "pvalue", "num.top.gene")
for (i in 1:length(num.top.gene))
{ #i=2
   topgene=as.character(sort_BF$Gene)[1:num.top.gene[i]]
  
  overlap=length(intersect(topgene, top1000.denovo.gene))
  enrichment.test=fisher.test(matrix(c(overlap, top.const.overlap.withdenovo, num.top.gene[i], 1003), nrow=2))
enrichment[i,]=c(enrichment.test$estimate, enrichment.test$p.value, num.top.gene[i])  
}

enrichment.result=as_tibble(enrichment)
enrichment.result$pvalue=round(enrichment.result$pvalue,4)
#enrichment.result$num.top.gene=enrichment.result$num.top.gene %>% recode("20"="Top 20", "40"="Top 40", "60" = "Top 60","80"= "Top 80", "100" ="Top 100", "120"="Top 120")
#enrichemnt.test$num.top.gene=factor(enrichment.result$num.top.gene, levels=c("20", " 40", " 60", " 80", " 100", "120"))

#pdf("C:/Users/han24/OneDrive - UWM/rare-var/Figure/Main/Fig-overlap.with.denovo.gene.pdf")
ggplot(enrichment.result, aes(x=num.top.gene, y=OR)) + 
   geom_bar(stat="identity", fill="blue")+
  theme_classic()+
 # coord_flip()+
 # theme(legend.title=element_blank())+
  theme(legend.position = "none")+
  xlab("")+
  ylab("OR")+
  theme(plot.title = element_text(hjust = 0.5, size=7))+  #center the title+
theme(axis.text.x = element_text(angle =0, vjust = 0.5, size=7))+
  scale_x_continuous("", labels = as.character(num.top.gene), breaks = num.top.gene)+ # list all x labels
  geom_text(aes(label=pvalue), position=position_dodge(width=0.9), vjust=-0.25)
```

** Enrichment of top MIRAGE genes with Strong ASD gene, plausible ASD gene and DNM candidate genes 
Strong ASD gene: SFARI score 1,2
plausible ASD gene: SFARI score 3
DNM candidate genes: top 1000 DNM genes


```{r, echo=F}
############# MIRAGE gene 
BF_para_all_est=loadRData("../output/para.est.constraint.gene.estimate.delta.RData")
Bayes_factor=as_tibble(BF_para_all_est)
sort_BF=Bayes_factor %>% arrange(desc(BF))
top10genes=as.character(sort_BF$Gene[1:10])
top20genes=as.character(sort_BF$Gene[1:20])
all.const.gene=as.character(sort_BF$Gene)

################## SFARI gene 
SFARI.gene=read.csv("../data/GeneSet/SFARI-Gene_genes_06-20-2019release_07-15-2019export.csv", header=T)
plausible.ASD.gene=as.character(SFARI.gene[which(SFARI.gene$gene.score==3), ]$gene.symbol)  # define strong ASD gene with score 1,2,3
strong.ASD.gene=c(as.character(SFARI.gene[which(SFARI.gene$gene.score==1), ]$gene.symbol), as.character(SFARI.gene[which(SFARI.gene$gene.score==2), ]$gene.symbol))  # define strong ASD gene with score 1,2,3

################## de novo gene 
denovo.gene=read.table("..\\..\\GeneSet\\TADA_SNV_CNV_combined\\TADA_SNV_CNV_combined_Feb7.txt", header=T)
rank.denovo.gene=denovo.gene[order(denovo.gene$qvalue.combined),]
top1000.denovo.gene=rank.denovo.gene$RefSeqName[1:1000]

top10mirage.percent=c(length(intersect(top10genes, strong.ASD.gene)), length(intersect(top10genes, plausible.ASD.gene)), length(intersect(top10genes, top1000.denovo.gene)))/10
top20mirage.percent=c(length(intersect(top20genes, strong.ASD.gene)), length(intersect(top20genes, plausible.ASD.gene)), length(intersect(top20genes, top1000.denovo.gene)))/20
const.gene.percent=c(length(intersect(all.const.gene, strong.ASD.gene)), length(intersect(all.const.gene, plausible.ASD.gene)), length(intersect(all.const.gene, top1000.denovo.gene)))/1003
top10mirage.enrichment=tibble(class=c("Top10 MIRAGE Gene", "All 1003 Constraint Gene"), Strong.ASD=c(top10mirage.percent[1], const.gene.percent[1]), Plausible.ASD=c(top10mirage.percent[2], const.gene.percent[2]), DNM=c(top10mirage.percent[3], const.gene.percent[3]))
top10mirage.enrichment.tidy=top10mirage.enrichment %>% gather( group, percent,2:4)
######## Top 10 mirage genes 
ggplot(top10mirage.enrichment.tidy, aes(group, percent)) + 
  geom_bar(aes(fill = class), stat = "identity", position = "dodge")+
  xlab("")+
  theme_classic()+
   theme(legend.title = element_blank())+
   theme(legend.position="bottom")
########### top 20 mirage genes 
top20mirage.enrichment=tibble(class=c("Top20 MIRAGE Gene", "All 1003 Constraint Gene"), Strong.ASD=c(top20mirage.percent[1], const.gene.percent[1]), Plausible.ASD=c(top20mirage.percent[2], const.gene.percent[2]), DNM=c(top20mirage.percent[3], const.gene.percent[3]))
top20mirage.enrichment.tidy=top20mirage.enrichment %>% gather( group, percent,2:4)

ggplot(top20mirage.enrichment.tidy, aes(group, percent)) + 
  geom_bar(aes(fill = class), stat = "identity", position = "dodge")+
  xlab("")+
  theme_classic()+
   theme(legend.title = element_blank())+
   theme(legend.position="bottom")


```





```{r, echo=F, eval=F}
denovo.gene=read.table("..\\..\\GeneSet\\TADA_SNV_CNV_combined\\TADA_SNV_CNV_combined_Feb7.txt", header=T)
rank.denovo.gene=denovo.gene[order(denovo.gene$qvalue.combined),]
top1000.denovo.gene=as.character(rank.denovo.gene$RefSeqName[1:1000])
top20.const.gene=as.character(rank.BF.const.gene.common.delta$Gene[1:20])
all.const.gene=as.character(rank.BF.const.gene.common.delta$Gene)
```



This is the how FDR varies as the posterior probability cutoff $\tau$ changes with $\hat{\delta}=0.18$ as prior. 


```{r, echo=F}
prior_cons=0.18
cons_post=Bayes_factor %>% mutate(post_prob=prior_cons*BF/(1-prior_cons+prior_cons*BF))

tau=seq(0, 0.999, by=0.001)
num_pred=NULL
false_disc=NULL
FDR=NULL
for (i in 1:length(tau))
{
num_pred[i]=sum(ifelse(cons_post$post_prob>tau[i], 1, 0))
false_disc[i]=sum((1-cons_post$post_prob)*ifelse(cons_post$post_prob>tau[i], 1, 0))
FDR[i]=false_disc[i]/num_pred[i]
}
tau_fdr=tibble(tau=tau, fdr=FDR)%>%drop_na()  # drop rows with NA

ggplot(tau_fdr)+
  geom_point(aes(x=tau, y=fdr))+
  xlab(expression(paste(tau)))+ylab("FDR")
```

```{r, echo=F}
const.gene.BF=loadRData("../output/const.gene.BF.MIRAGE.RData")
const.gene.pvalue=loadRData("../output/const.gene.pvalue.other.methods.RData")
gene.index.to.test=c(1,  21,  41, 136, 196, 220, 332, 409, 469, 473, 489, 514, 561, 624, 694, 696, 699, 714, 762, 777)
const.gene.pvalue$ASUM.pvalue[gene.index.to.test]=c(0.00234, 0.00064, 0.00000, 0.00000, 0.00000, 0.00000, 0.01122, 0.00000, 0.00000, 0.00000, 0.00000, 0.00419, 0.00000, 0.00000, 0.00000, 0.00222, 0.00000, 0.00000, 0.00000, 0.00000) # set 10,000 permutations to update p value
const.gene.pvalue.adj=const.gene.pvalue%>%mutate("SKATO.pvalue.adj"=p.adjust(SKATO.pvalue, method="BH"))%>%
  mutate("CMC.pvalue.adj"=p.adjust(CMC.pvalue, method="BH"))%>%
  mutate("ASUM.pvalue.adj"=p.adjust(ASUM.pvalue, method="BH"))%>%
  mutate("Fisher.pvalue.adj"=p.adjust(Fisher.pvalue, method="BH"))%>%
  mutate("Fisher.adj.pvalue.adj"=p.adjust(Fisher.adj.pvalue, method="BH"))
const.gene.BF.pvalue.combine=full_join(const.gene.BF, const.gene.pvalue.adj, by="Gene")
const.gene.BF.pvalue.combine %>% filter(ASUM.pvalue.adj==0)%>%select(SKATO.pvalue.adj:Fisher.adj.pvalue.adj)
```

```{r, echo=T}
MIRAGE_gene=const.gene.BF.pvalue.combine %>% filter(post_prob>0.72)%>%select(Gene, BF, post_prob)
MIRAGE_gene%>%arrange(desc(post_prob))  # FDR<0.2

const.gene.BF.pvalue.combine %>% filter(post_prob>0.52)%>%select(Gene, BF, post_prob) %>% arrange(desc(post_prob)) # FDR<0.3


const.gene.BF.pvalue.combine %>% filter(post_prob>0.4)%>%select(Gene, BF, post_prob) %>% arrange(desc(post_prob))

ASUM_gene=const.gene.BF.pvalue.combine %>% filter(ASUM.pvalue.adj<0.05) %>% select(Gene,BF, post_prob, ASUM.pvalue.adj)
ASUM_gene %>% arrange(ASUM.pvalue.adj) %>% print(n=20)
right_join(as_tibble(const.gene.BF), ASUM_gene, by="Gene")%>% select(-post_prob.y, -BF.y)%>%arrange(desc(post_prob.x)) 
left_join(as_tibble(MIRAGE_gene), ASUM_gene, by="Gene")%>% select(-post_prob.y, -BF.y)%>%arrange(desc(post_prob.x))%>% print(n=29) ## ASUM: does not work for genes with one variant, resutling in NA 
```



FDR has the minimum of 0.14 


method    | FDR<0.2  | FDR<0.3  |
---------|--------|--------------
MIRAGE  | 3 | 9
SKATO   | 0  | 0 
CMC  | 0 | 0 
ASUM | 20 |20 
Burden | 0 | 0 
Burden.adj | 0 | 0 
Table: Number of genes identified by different methods at different FDR levels. 



method    | FDR<0.2  | FDR<0.3  |
---------|--------|--------------
MIRAGE  | 3 | 9
SKATO   | 0  | 0 
CMC  | 0 | 0 
Burden | 0 | 0 
Burden.adj | 0 | 0 
Table: Number of genes identified by different methods at different FDR levels. 



#### highlight genes


```{r, echo=F}
Gene_CYFIP1=Anno.Data[which(Anno.Data$Gene=="CYFIP1"),]
Gene_CYFIP1_par=eight.partition(Gene_CYFIP1)
Gene_CYFIP1_merge=Gene_CYFIP1_par %>% gather(status, No.var, 3:4) 
Gene_CYFIP1_merge$group.index=Gene_CYFIP1_merge$group.index %>% recode("1"="1", "2"="2", "3"="3", "4"="4", "5"="5", "6"="6", "7"="7", "8"="8")
Gene_CYFIP1_merge$status=Gene_CYFIP1_merge$status %>% recode(No.case="Case", No.contr="Control")
Gene_CYFIP1_merge=Gene_CYFIP1_merge[which(Gene_CYFIP1_merge$No.var<40),]
```

```{r, echo=F}
ggplot(as_tibble(Gene_CYFIP1_merge), aes(x=ID, y=No.var, color=status, shape=group.index))+
  geom_point()+
  ggtitle("CYFIP1")+
  theme_classic()+
  xlab("Coordinate")+ylab("#.var")+
  geom_hline(yintercept=0, linetype="solid", color = "black")+
  theme(plot.title = element_text(hjust = 0.5, size=10))+
  theme(axis.text.x = element_text(angle = 60, hjust = 1, size=6))
```


### Cons: Estimate $\eta_i$


Annotation category  | fix $\delta=0.1$ (test.stat) | fix $\delta=0.2$ (test.stat) | estimate $\hat{\delta}=0.18 (9.93)$
---------------------|---------------|-------------------|----------
LoF,   $0.01 \leq AF < 0.05$  |      $\eta_1=0$ (0) | 0 (0) | 0 (0)
LoF,  $AF < 0.01$ |         $\eta_2=0.54$ (0.63) | 0.39 (0.76)  | 0.41 (0.75) 
Damaging, $0.01 \leq AF < 0.05$ |   $\eta_3=0$ (0)| 0 (0) |0 (0)
Damaging,  $0.001 \leq  AF < 0.01$ |    $\eta_4=0$ (0) | 0 (0) | 0 (0)
Damaging,  $AF < 0.001$ |  $\eta_5=0.23$ (5.42)| 0.15 (5.71) | 0.16 (5.72)
Non-Damaging, $0.01 \leq  AF < 0.05$ |    $\eta_6=0$ (0) | 0 (0) |0 (0)
Non-Damaging, $0.001 \leq AF < 0.01$ |  $\eta_7=0$ (0) | 0 (0) | 0 (0)
Non-Damaging,  $AF < 0.001$ | $\eta_8=0.24$ (3.11) | 0.16 (3.49) | 0.17 (3.46)
Table: Parameter estimates of 1003 constraint genes by EM with eight partitions. 



```{r, echo=T}
para.est=c(0, 0.54, 0, 0, 0.23, 0, 0, 0.24)
x=1:8
plot(x, para.est, type="p", ylim=c(0,1), cex.lab=0.7, ylab=expression(paste(hat(beta))), pch=16, xlab="Variant Category", main="Parameter estimate of constraint genes with fixed delta=0.1")
```


```{r, echo=F}
BF.const.gene.common.delta=read.csv("..\\output\\BF.constraint.gene.ASD.commmondelta0.1.csv", header=T)
rank.BF.const.gene.common.delta=BF.const.gene.common.delta[order(BF.const.gene.common.delta$BF, decreasing=T),]
row.names(BF.const.gene.common.delta)=NULL
```

```{r, echo=F}
library(gridExtra)
#pdf("..\\..\\Figure\\top20gene.pdf")
top20gene=as.character(rank.BF.const.gene.common.delta$Gene)[1:20]
top20gene.BF=as.numeric(rank.BF.const.gene.common.delta$BF)[1:20]
BF.data=data.frame(Gene=top20gene, BF=top20gene.BF)
p1=ggplot(data=BF.data, aes(x=Gene, y=BF)) +
  geom_bar(stat="identity", fill="steelblue")+coord_flip()

no.case=numeric(); no.contr=numeric()
for (i in 1:length(top20gene))
{
  no.case[i]=sum(Anno.Data[which(Anno.Data$Gene==top20gene[i]),]$No.case)
  no.contr[i]=sum(Anno.Data[which(Anno.Data$Gene==top20gene[i]),]$No.contr)
  
}
Gene=top20gene
rate.case=no.case/N1
rate.contr=no.contr/N0
group=c(rep("case", length(Gene)), rep("control", length(Gene)))
rate.data=data.frame(group=group, Gene=rep(Gene,2), rate=c(rate.case, rate.contr))
p2=ggplot(data=rate.data, aes(x=Gene, y=rate, fill=group)) +
  geom_bar(stat="identity", position=position_dodge())+
  xlab("")+coord_flip()

grid.arrange(p1, p2, nrow = 1)
#dev.off()
```

```{r, echo=T}
kable(cbind(rank.BF.const.gene.common.delta[1:20,1:2], no.case, no.contr), row.names=NA, caption =("Top 20 genes of constraint genes with fixed delta"), "html")%>%
kable_styling() %>%
scroll_box(height = "200px")


```




#### enrichment with de novo genes 

```{r, echo=F, eval=F}
denovo.gene=read.table("D:\\ResearchWork\\StatisticalGenetics\\NumericAnalysis\\RealData\\GeneSet\\TADA_SNV_CNV_combined\\TADA_SNV_CNV_combined_Feb7.txt", header=T)
rank.denovo.gene=denovo.gene[order(denovo.gene$qvalue.combined),]
top1000.denovo.gene=as.character(rank.denovo.gene$RefSeqName[1:1000])
top20.const.gene=as.character(rank.BF.const.gene.common.delta$Gene[1:20])
all.const.gene=as.character(rank.BF.const.gene.common.delta$Gene)
```
In top 1000 denovo genes, there are 9 in top 20 constarint genes and 87 in 1003 constraint genes. By Fisher exact test (9/20 vs 87/1003), OR=5.17 and p value of $4.10 \times 10^{-4}$.  



#### LoF category 

```{r, echo=T}
beta.est=c(0.49419653, 0.31677155, 0.22161936, 0.16934539, 0.13697687, 0.11502861, 0.09918004, 0.08717663, 0.07778499, 0.07022805)
delta=seq(0.1, 1, by=0.1)
plot(beta.est, xaxt='n', ylab=expression(paste(hat(beta))), main="Parameter estimate for LoF category", type="o", xlab=expression(paste(delta)))
axis.label=c("0.1", "0.2", "0.3", "0.4", "0.5", "0.6", "0.7", "0.8", "0.9", "1")
axis(1,at=1:10,labels=axis.label)
test.stat=c(0.6105703, 0.7301446, 0.7621092, 0.7772918, 0.7866515, 0.7931309, 0.7979188, 0.8016140, 0.8045560, 0.8069559, cex.axis=0.8)

```

### Cons: Fixed $\eta_i$


With fixed parameter in every variant group, calculate the BF of every gene which is the product of BF of every variant in this gene. Below are top 20 genes with large BF.   


Gene | BF | C1 | C2 | C3 | C4 | C5 | C6 | C7 | C8 | Rank | p-val
-----|----|----|----|----|----|----|----|----|----|------|------------------
CYFIP1 | 12.44 | - | - | - | 0.81 | 13.53 | - | 0.90 |  1.26 | 18200 | 0.0015
ABCA2 | 11.96 | - | - | - | - |  1.18 | - | - | 10.13 | 18210 | 0.0016
CACNA1D | 11.26 | - | - | - | - |  9.46 | 0.97 | 0.91 |  1.35 | 186 | 0.0018
FBN1 |  6.94 | - | - | - | 0.83 |  5.83 | 0.95 | 0.89 |  1.71 | 1324 | 0.0041
CIT |  6.68 | - | 1.63 | - | 5.90 |  0.45 | 0.95 | 0.70 |  2.31 | 13225 | 0.0044
PLXNB1 |  5.78 | - | - | - | - |  3.45 | - | - |  1.68 | 364 | 0.0057
CREBBP |  5.51 | - | - | - | - |  2.22 | - | 1.47 |  1.70 | 1232 | 0.0062
GTF3C4 |  5.50 | - | - | - | - |  4.85 | - | 0.92 |  1.23 | 15612 | 0.0063
MYH10 |  5.25 | - | - | - | - |  4.45 | - | 0.79 |  1.50 | 48 | 0.0068
DNM3 |  4.91 | - | 1.63 | - | - |  2.02 | - | 1.27 |  1.18 | 16092 | 0.0076
CHD8 |  4.79 | - | - | - | 0.77 |  6.66 | 0.97 | - |  0.96 | 2 | 0.008
TP63 |  4.05 | - | - | - | 0.81 |  2.66 | - | 0.92 |  2.05 | 15512 | 0.0108
DOCK4 |  3.91 | - | - | - | - |  4.47 | 0.90 | 0.90 |  1.07 | 18342 | 0.0116
CNOT1 |  3.73 | - | - | 0.91 | - |  3.25 | 1.06 | - |  1.19 | 8577 | 0.0128
HIRA |  3.04 | - | - | - | - |  2.37 | 1.06 | - |  1.21 | 17444 | 0.0192
ITSN1 |  2.94 | - | - | - | 0.91 |  3.23 | - | - |  1.00 | 1479 | 0.0205
HDLBP |  2.91 | - | - | - | - |  1.08 | - | 4.11 |  0.65 | 480 | 0.0210
BAZ1A |  2.89 | - | - | - | - |  2.79 | 1.02 | 0.85 |  1.20 | 1392 | 0.0212
SLC4A8 |  2.81 | - | - | - | - |  1.90 | - | - |  1.48 | 16562 | 0.0225
VPRBP |  2.79 | - | - | - | - |  3.80 | - | - |  0.73 | 1393 | 0.0230
Table: Bayes factor partition of top 20 genes from 1003 constraint genes. Rank: Rank by DNM; p-val: empirical p values by perturbating case control labels with null distribution of all constraint genes. ``-" means no variants in the category.


In top 1000 denovo genes, 5 are found in top 20 genes and 81 in all 1003 genes. Fisher exact test (5/20 vs 81/1003) gives OR=3.7857 and p value=0.0211.




ASD gene priors  for 1003 constraint genes. (1) Enrichment with top 1000 genes: 11/20 vs 261/1003, OR=3.4696, pvalue=0.008017; (2) enrichment with top 2000 genes: 12/20 vs 419/1003, OR=2.0892, p value=0.1135.


### Cons: Estimate $\eta_i$, gene specific $\delta_i$



#### (1) LoF only 

The burden is 622/583. $\widehat{\beta}=0.74$ and test statistic is 2.99. 


#### (2) Eight categories 


Annotation category  | $\widehat{\eta}$ | test.stat
---------------------|---------------|-------------------
LoF,   $0.01 \leq AF < 0.05$  |     0 | 0 
LoF,  $AF < 0.01$ |       0.81 | 2.98  
Damaging, $0.01 \leq AF < 0.05$ |   0| 0 
Damaging,  $0.001 \leq  AF < 0.01$ |  0 | 0 
Damaging,  $AF < 0.001$ | 0.12| 6.88
Non-Damaging, $0.01 \leq  AF < 0.05$ |  0 | 0 
Non-Damaging, $0.001 \leq AF < 0.01$ |  0 | 0 
Non-Damaging,  $AF < 0.001$ | 0.09 | 0
Table: Parameter estimates of 1003 constraint genes by EM with eight partitions with gene specific  $\delta$.


```{r, echo=F}
BF.const.gene.specific.delta=read.csv("..\\output\\BF.constraint.gene.ASD.specificdelta.csv", header=T)
rank.BF.const.gene.specific.delta=BF.const.gene.specific.delta[order(BF.const.gene.specific.delta$BF, decreasing=T),]
```

```{r, echo=T}
kable(rank.BF.const.gene.specific.delta[1:20,1:2], row.names=NA, caption =("Top 20 genes of constraint genes with gene specific delta"), "html")%>%
kable_styling() %>%
scroll_box(height = "200px")
```

In top 1000 denovo genes, 6 are found in top 20 genes and 102 in all 1003 genes. Fisher exact test (6/20 vs 102/1003) gives OR=2.95, pvalue=0.0311.

ASD gene priors for 1003 constraint genes. (1) Enrichment with top 1000 genes: 10/20 vs 331/1003, OR=1.5146, pvalue=0.2896. 

```{r, echo=F}
library(plotrix)
para.est=read.csv("../../para.est.1003.constraint.gene.csv", header=T)
para.summ=matrix(nrow=8, ncol=3)
for (i in 1:8)
  { 
   para.summ[i,1]=mean(para.est[,(i+1)])
   para.summ[i,2]=quantile(para.est[,(i+1)], prob=0.025)
   para.summ[i,3]=quantile(para.est[,(i+1)], prob=0.975)
}
x=1:8
plot(para.summ[,1], type="p", ylim=c(0,1), cex.lab=0.7, ylab=expression(paste(hat(beta))), pch=16, xlab="Variant Category", main="Parameter estimate of constraint genes")
#plotCI(x, para.summ[,1], ui=para.summ[,3], li=para.summ[,2], sfrac=0.005, ylim=c(0,1), pch=16, cex=0.5, ylab=expression(paste(hat(beta))),xlab="Variant Category", main="Parameter estimate of constraint genes")
```


```{r, echo=T}
para.est=c(0, 0.54, 0, 0, 0.23, 0, 0, 0.24)
x=1:8
plot(x, para.est, type="p", ylim=c(0,1), cex.lab=0.7, ylab=expression(paste(hat(beta))), pch=15, col="black", xlab="Variant Category", main="Parameter estimates of constraint genes")
points(x, para.summ[,1], type="p", ylim=c(0,1), cex.lab=0.7, ylab=expression(paste(hat(beta))), pch=16,col="red")
legend(6, 0.8, c(expression(paste("common ", delta, "=0.1")), expression(paste("gene specific ", delta[i]))), col=c("black", "red"), pch=c(15,16))
abline(h=0, lty=2)
```



```{r, echo=F}
#pdf("D:\\ResearchWork\\StatisticalGenetics\\Latex\\Paper\\PLoS\\Figure\\paraestconsgene.pdf")
para.est.sum=matrix(nrow=3, ncol=8)
para.est.sum[1,]=para.est
para.est.sum[2,]=para.summ[,1]
para.est.sum[3,]=c(0, 0.41, 0, 0, 0.16, 0, 0, 0.17)
colnames(para.est.sum)=seq(1,8)
barplot(para.est.sum, beside=T, col=c("darkblue", "red", "green"), legend=c(expression(paste("fixed common", delta, "=0.1")), expression(paste("gene specific ", delta[i])), expression(paste(hat(delta), "=0.18"))), ylim=c(0,1), ylab=expression(paste(hat(eta))), cex.lab=0.7) 
#dev.off()
```


```{r, echo=F}
all.est=c(para.est.sum[1,], para.est.sum[2,])
cate=1:8
para=rep(c("common delta", "specific delta"), each=8)
para.est.combine=data.frame(cate=cate, para=para, est=all.est)

#pdf("../../Figure/paraestconsgene.pdf")
ggplot(data=para.est.combine, aes(x=cate, y=all.est, fill=para)) +
geom_bar(stat="identity", position=position_dodge())+
  xlab("variant category")+ylab(expression(paste(hat(beta))))+
  scale_x_continuous("variant category", labels = as.character(cate), breaks = cate)
#dev.off()
```

Replace "damaging" with "consensus damaging"


Annotation category  | $\widehat{\eta}$ | test.stat
---------------------|---------------|-------------------
LoF,   $0.01 \leq AF < 0.05$  |     0 | 0 
LoF,  $AF < 0.01$ |       0.7318 | 2.99  
Consensus Damaging, $0.01 \leq AF < 0.05$ |   0| 0 
Consensus Damaging,  $0.001 \leq  AF < 0.01$ |  0 | 0 
Consensus Damaging,  $AF < 0.001$ | 0.1310| 10.06
Non-Consensus Damaging, $0.01 \leq  AF < 0.05$ |  0 | 0 
Non-Consensus Damaging, $0.001 \leq AF < 0.01$ |  0 | 0 
Non-Consensus Damaging,  $AF < 0.001$ | 0.0737 | 0
Table: Parameter estimates of 1003 constraint genes by EM with eight partitions with gene specific  $\delta$.

### QQ plot of p values by different methods 

```{r, echo=F}
plotQQ.unif <- function(p.obs) {
  obs <- (p.obs)
  theo <- (ppoints(length(obs)))
  qqplot(-log(theo, base=10), -log(obs, base=10), xlab=expression(paste("Theoretical ",-log[10], "(p-values)")), ylab=expression(paste("Observed ", -log[10], "(p-values)")), main="A")
  abline(0,1,col='red')
}

```





```{r, echo=F}
pvalues.othermethod=loadRData("../output/const.gene.pvalue.other.methods.RData")
SKATO.pvalue=pvalues.othermethod$SKATO.pvalue
CMC.pvalue=pvalues.othermethod$CMC.pvalue
ASUM.pvalue=pvalues.othermethod$ASUM.pvalue
Burden.pvalue=pvalues.othermethod$Fisher.pvalue

#######################   John storey's q value 
library(qvalue)
qobj.burden=qvalue(Burden.pvalue)
localFDR.burden <- qobj.burden$lfdr
min(localFDR.burden, na.rm=T)

qobj.SKATO=qvalue(SKATO.pvalue)
localFDR.SKATO <- qobj.SKATO$lfdr
min(localFDR.SKATO, na.rm=T)
#######################


#png("C:/Users/han24/OneDrive - UWM/rare-var/Figure/Supp/Fig-pvalue_QQplot_othermethod_ASD_topconstgene.png")
par(mfrow=c(1,2))
theo <- (ppoints(length(Burden.pvalue)))
  qqplot(-log(theo, base=10), -log(Burden.pvalue, base=10), xlab=expression(paste("Theoretical ",-log[10], "(p-values)")), ylab=expression(paste("Observed ", -log[10], "(p-values)")), main="Burden", frame=F, cex.lab=0.8, pch=16)
  abline(0,1,col='red')

theo <- (ppoints(length(SKATO.pvalue)))
  qqplot(-log(theo, base=10), -log(SKATO.pvalue, base=10), xlab=expression(paste("Theoretical ",-log[10], "(p-values)")), ylab="", main="SKATO", frame=F, cex.lab=0.8, pch=16)
  abline(0,1,col='red')
#dev.off()    

```






This is for LoF and damaging variants only. 


```{r, echo=F}
pvalues.othermethod=loadRData("../output/const.gene.pvalue.other.methods.LoFandDamagingVariant.RData")
SKATO.pvalue=pvalues.othermethod$SKATO.pvalue
CMC.pvalue=pvalues.othermethod$CMC.pvalue
ASUM.pvalue=pvalues.othermethod$ASUM.pvalue
Burden.pvalue=pvalues.othermethod$Fisher.pvalue
#pdf("C:/Users/han24/OneDrive - UWM/rare-var/Figure/Supp/Fig-pvalue_QQplot_othermethod_ASD_topconstgene.pdf")
par(mfrow=c(1,2))
theo <- (ppoints(length(Burden.pvalue)))
  qqplot(-log(theo, base=10), -log(Burden.pvalue, base=10), xlab=expression(paste("Theoretical ",-log[10], "(p-values)")), ylab=expression(paste("Observed ", -log[10], "(p-values)")), main="Burden", frame=F, cex.lab=0.8, pch=16)
  abline(0,1,col='red')

theo <- (ppoints(length(SKATO.pvalue)))
  qqplot(-log(theo, base=10), -log(SKATO.pvalue, base=10), xlab=expression(paste("Theoretical ",-log[10], "(p-values)")), ylab="", main="SKATO", frame=F, cex.lab=0.8, pch=16)
  abline(0,1,col='red')
#dev.off()    

```


### Empirical distribution of BF by permutations

permutate the variant count in cases and controls for every gene 100 times, calculate Bayes factor by MIRAGE and get their empirical p value by comparing original BF and 100 permutated BF. The null distribution of BF is  pooling BF's of all genes through permutations together. 

```{r, echo=F}
BF.permutation=loadRData("../output/const.gene.BF.by.100permutations.RData")
null.BF.all.gene=NA
for (i in 1:length(BF.permutation))
  null.BF.all.gene=c(null.BF.all.gene, BF.permutation[[i]]$BF)
null.BF.all.gene=null.BF.all.gene[-1]
const.gene.BF=loadRData("../output/const.gene.BF.MIRAGE.RData")
empirical.pvalue=numeric()
for (i in 1:nrow(const.gene.BF))
  empirical.pvalue[i]=1-sum(const.gene.BF[i,]$BF>null.BF.all.gene)/length(null.BF.all.gene) # empirical p value
const.gene.BF.postprob.empirical.pvalue=const.gene.BF %>% add_column(empirical.pvalue=empirical.pvalue)
const.gene.BF.postprob.empirical.pvalue %>% arrange(empirical.pvalue)
```

Histogram of empirical p values by permutations

```{r, echo=F}
ggplot(as_tibble(empirical.pvalue),aes(x=value))+
  geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#FF6666")+
  xlab("p value")+
  theme_classic()
```


```{r, echo=F}

theo <- (ppoints(length(empirical.pvalue)))
  qqplot(-log(theo, base=10), -log(empirical.pvalue, base=10), xlab=expression(paste("Theoretical ",-log[10], "(p-values)")), ylab=expression(paste("Observed ", -log[10], "(p-values)")), main="Empirical p value of Bayes factor by permutation", frame=F, cex.lab=0.8, pch=16)
  abline(0,1,col='red')

```


## Constraint genes 

There are 17,416 genes. 

### Con: Estimate $\beta_i$, gene specific $\delta_i$

#### Non-nested gene sets 

With their constraint scores, focus on top 10% genes, top 10-20% genes, top 20-30% genes, top 30-40% genes, top 40-50% genes. 


```{r, echo=T}
beta=matrix(nrow=5, ncol=8)
rownames(beta)=c("<10%", "10-20%", "20-30%", "30-40%", "40-50%")
beta[1,]=c(0, 0.6195,  0, 0.0025,  0.0427, 0,  0,  0.0855)
beta[2,]=c(0, 0.0073,  0, 0,   0.0316, 0, 0,  0.0588)
beta[3,]=c(0,  0.0179, 0,   0,   0.0284,0,  0.0294,  0.0390)
beta[4,]=c(0,  0.0883,  0, 0,   0.0245,0,  0,   0.0017)
beta[5,]=c(0,  0.2706,  0, 0,   0.0038,0,   0.0187,  0.0006)
plot(beta[,1], ylim=c(0,1),cex=0.1, type="o", xaxt="n", xlab="Score quantile ", pch=16, ylab=expression(paste(hat(beta))), cex.lab=0.75, main="Parameter estimates of top five non-nested constraint gene sets",)
axis(side=1, at=1:5, labels=rownames(beta),cex.axis=0.8)
for (i in 2:8)
 lines(beta[,i], type="o", col=i, pch=16)
betas=c(expression(paste(hat(beta)[1])),expression(paste(hat(beta)[2])), expression(paste(hat(beta)[3])),expression(paste(hat(beta)[4])), 
expression(paste(hat(beta)[5])),expression(paste(hat(beta)[6])), expression(paste(hat(beta)[7])),expression(paste(hat(beta)[8])))
#legend(2, 1, c(paste("beta", seq(1,8), sep="")), col=seq(1,8), lty=rep(1,8))
legend(4, 1, betas, col=seq(1,8), lty=rep(1,8), ncol=2)





```



Replace "Damaging" with "Consensus damaging"


```{r, echo=T}
beta=matrix(nrow=5, ncol=8)
rownames(beta)=c("top10%", "top10-20%", "top20-30%", "top30-40%", "top40-50%")
beta[1,]=c(0, 0.6275,  0, 0,  0.0454, 0,  0,  0.0848)
beta[2,]=c(0, 0.0326,  0, 0,   0.0667, 0, 0,  0.0071)
beta[3,]=c(0,  0.0379, 0,   0,   0.0365,0,  0.0509,  0.0034)
beta[4,]=c(0,  0.1009,  0, 0,   0.0020,0,  0,   0.0008)
beta[5,]=c(0,  0.2652,  0, 0,   0.0350,0,   0.0080,  0.0004)
plot(beta[,1], ylim=c(0,1), type="o", xaxt="n", xlab="", ylab=expression(paste(hat(beta))), main="Parameter estimate of five non-nested gene sets")
axis(side=1, at=1:5, labels=rownames(beta),cex.axis=0.7)
for (i in 2:8)
 lines(beta[,i], type="o", col=i)
legend(4, 1, c(paste("beta", seq(1,8), sep="")), col=seq(1,8), lty=rep(1,8))

```

constraint level | C5: Consensus Damaging,  $AF < 0.001$| C8: Non-Consensus Damaging,  $AF < 0.001$
---------------------|---------------|-------------------
top 10%  |     34,028/33,508=1.0155 | 30,922/30,736=1.0061 
top 10-20% | 17,184/16,925=1.0153 | 15,738/15,894=0.9902
top 20-30% | 12,371/12,588=0.9828 | 12,035/12,216=0.9852
top 30-40% | 11,972/12,038=0.9945 | 10,652/10,605=1.0044
top 40-50% | 11,055/11,147=0.9917 | 9,548/9,903=0.9642
Table: Number of variants in C5 and C8 at different constrait level. 





## TADA gene (q<5%)

Only 46 genes with TADA q values less than 5%. 

### TADA: Estimate $\beta$, fixed $\delta=1$

#### Only LoF variants  

In the simple burden analysis (see Table above), LoF variants is 55/27. With $\delta=1$, $\widehat{\beta}=0.5692$, and test statistic is 12.0211. 

### TADA: Estimate $\beta_i$, gene specific $\delta_i$

Use 1-FDR of every gene as priors to estimate $\beta_i$. 


```{r, results="hide", echo=F, eval=F}
Bayesian.FDR <- function(BF, pi0, alpha=0.05) {
  # convert BFs to PPA (posterior probability of alternative model)
  # [BF]: a sorted vector of BFs (in decreasing order)
  # [pi0]: the prior probability that the null model is true
  # [alpha]: the FDR target
  # [Return]: the q-value of each BF, and the number of findings with q below alpha. 
  pi <- 1-pi0
  q <- pi*BF/(1-pi+pi*BF) # PPA
  q0 <- 1 - q # posterior probability of null model
  
  # the FDR at each PPA cutoff
  n <- length(BF)
  FDR <- numeric(n)
  for (i in 1:n) FDR[i] <- sum(q0[1:i]) / i 
  
  # the cutoff
  t <- 1
  while (t <= length(q0) & mean(q0[1:t]) <= alpha) { t <- t+1 }
  return (list(FDR=FDR, ND=t))
}
```

####  Only LoF category 

$\widehat{\beta}=0.63$, test statistics is 10.07. 

## RVIS gene 


### RVIS:Estimate $\beta_i$, gene specific $\delta_i$ 

#### Quantile score <50 (8437) genes

Annotation category  | $\widehat{\beta}$ | test.stat
---------------------|---------------|-------------------
LoF,   $0.01 \leq AF < 0.05$  |     0 | 0 
LoF,  $AF < 0.01$ |       0.17 | 6.06  
Damaging, $0.01 \leq AF < 0.05$ |   0| 0 
Damaging,  $0.001 \leq  AF < 0.01$ |  0 | 0 
Damaging,  $AF < 0.001$ | 0.06| 13.55
Non-Damaging, $0.01 \leq  AF < 0.05$ |  0 | 0 
Non-Damaging, $0.001 \leq AF < 0.01$ |  0 | 0 
Non-Damaging,  $AF < 0.001$ | 0.08 | 11.34
Table: Parameter estimates of 8437 ( quantile<50 ) RVIS genes by EM with eight partitions with gene specific  $\delta_i$.



#### with different quantile score 





Replace "Damaging" with "Consensus damaging"

```{r, echo=T}
beta=matrix(nrow=5, ncol=8)
rownames(beta)=c("Quantile score<10", "10-20", "20-30", "30-40", "40-50")
beta[1,]=c(0, 0.5309,  0, 0,  0.0414, 0,  0,  0.0794)
beta[2,]=c(0, 0.1402,  0, 0,   0.1098, 0, 0,  0.0464)
beta[3,]=c(0,  0.0026, 0,   0,   0.0222,0,  0.0197,  0.1779)
beta[4,]=c(0,  0.0016,  0, 0,   0.0770,0,  0,   0.0558)
beta[5,]=c(0,  0.1103,  0, 0,   0.1246,0,   0,  0.0369)
plot(beta[,1], ylim=c(0,0.6), type="o", xaxt="n", xlab="", ylab=expression(paste(hat(beta))), main="Parameter estimate of five non-nested gene sets")
axis(side=1, at=1:5, labels=rownames(beta),cex.axis=0.7)
for (i in 2:8)
 lines(beta[,i], type="o", col=i)
legend(4, 0.5, c(paste("beta", seq(1,8), sep="")), col=seq(1,8), lty=rep(1,8))
```

## Whole genome 

consider all 15624 genes in ASD data. 

### Whole: Estimate $\beta_i$, gene specific $\delta_i$

Annotation category  | $\widehat{\beta}$ | test.stat
---------------------|---------------|-------------------
LoF,   $0.01 \leq AF < 0.05$  |     0 | 0 
LoF,  $AF < 0.01$ |       0.08 | 3.94  
Damaging, $0.01 \leq AF < 0.05$ |   0| 0 
Damaging,  $0.001 \leq  AF < 0.01$ |  0 | 0 
Damaging,  $AF < 0.001$ | 0.06| 23.85
Non-Damaging, $0.01 \leq  AF < 0.05$ |  0 | 0 
Non-Damaging, $0.001 \leq AF < 0.01$ |  0 | 0 
Non-Damaging,  $AF < 0.001$ | 0.06 | 11.42
Table: Parameter estimates of 15624 genes by EM with eight partitions with gene specific  $\delta_i$.


```{r, echo=T}
para.est=c(0, 0.08, 0, 0, 0.06, 0, 0, 0.06)
x=1:8
plot(para.est, type="p", ylim=c(0,0.5), cex.lab=0.7, ylab=expression(paste(hat(beta))), pch=16, xlab="Variant Category", main="Parameter estimate of all genes in the whole genome")
```

## Session information

<!-- Insert the session information into the document -->
```{r session-info}
```
