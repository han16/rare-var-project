---
title: "Simulation study"
author: "Shengtong Han"
output: html_document
---

<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results='asis'}
```
<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
```{r code-version, echo=FALSE, results='asis'}
```

<!-- Add your analysis here -->
## Set up
Defined R function gene.simu is  used to generate case control data. The data generation work flow is as 
![Data generation workflow.](figure/chart.png)


N0, N1 are sample size in case and controls.  m: number of variants per gene. alpha0, beta0, alpha, beta; two scale parameters in beta distriution to generate AF in control and cases. gamma.mean: the mean in gamma distribution to generate RR; sigma: anohter parameter in gamma distribution; pi: probability of a variant being causal.  

```{r data generation, echo=T}
gene.simu=function(N0, N1, m, alpha0, beta0, alpha, beta, gamma.mean, sigma, pi, model, num.group, split.ratio)
{
  pheno=c(rep(0,N0), rep(1,N1))  # filtering step
  q <- rbeta(m, alpha0, beta0)
  x1x0=matrix(nrow=(N0+N1), ncol=m)
  for (i in 1:m)  # generate the data with certain variants full of zeros
    x1x0[,i]=rpois((N0+N1), q[i])
  filter.x1x0=x1x0[,!apply(x1x0==0,2,all)]  # filter variants with 0 counts in both cases and controls since these variants are noninformative
  mm=ncol(filter.x1x0)
  var.index=which(colSums(x1x0!=0)>0) # get the variant index in the original data before filtering
  
  ##################
  #mm=m
  gamma <- rep(1,mm)
  Zij=rep(0,mm)
  qq=rbeta(mm, alpha0, beta0)
  if (model==1)
  {
  #  for (k in 1:num.group)
  #  {
  #    from=split.ratio[k]*mm+1; to=split.ratio[k+1]*mm
  #    Zij[from:to]=rbinom((to-from+1), 1, pi[k])
  #  }
    for (i in 1:mm)
      Zij[i]=rbinom(1,1,pi[var.index[mm]])
    
    qq[Zij==1] <- rbeta(sum(Zij==1), alpha, beta)
    gamma[Zij==1] <- rgamma(sum(Zij==1), gamma.mean*sigma, sigma)
  }
  
  x <- array(0, dim=c(length(pheno), mm))
  for (j in 1:mm)
  {
    x1=rbinom(1, sum(filter.x1x0[,j]), N1*gamma[j]/(gamma[j]*N1+N0))
    #x1=sum(filter.x1x0[,j])-x0
    x0=sum(filter.x1x0[,j])-x1
    x[sample.int(N0,x0),j]=1
    x[N0+sample.int(N1,x1),j]=1
  }
  x=as.matrix(x)
  return (list(geno=x,pheno=pheno,q=q,gamma=gamma, Zij=Zij, var.index=var.index))
  
}
```

```{r calculate BF of single variant by integration, echo=F}
intergrand=function(aa, var.case, var.contr, bar.gamma, sig, N1, N0)
{
  ff=dbinom(var.case, sum(var.case, var.contr), aa*N1/(aa*N1+N0))*dgamma(aa, bar.gamma*sig, sig)
  return(ff)
}
# calculate the bayes factor of a single variant via integration
BF.var.inte=function(var.case, var.contr, bar.gamma, sig, N1, N0)
{
  marglik0.CC <- dbinom(var.case, sum(var.case, var.contr), N1/(N1+N0))    # Under H0: gamma=1
  
  marglik1.CC <- integrate(intergrand, var.case, var.contr, bar.gamma, sig, N1, N0, low=0, upper=100, stop.on.error=F)$value # Under H1: gamma~gamma(gamma.mean*sigma, sigma) 
  BF.var <- marglik1.CC/marglik0.CC
  
  return(BF.var)
}
```

```{r objective functions, echo=F}
objec.func=function(beta.est) # this is the log likelihood function to be maximized
{
  lkhd=0
  for (i in 1:num.var)
    lkhd=lkhd+log(1+BF.var[i]*exp(Ajk.effect[i]*beta.est))-log(1+exp(Ajk.effect[i]*beta.est))
  
  lkhd=lkhd-lambda/2*sum(beta.est^2)
  
  return(lkhd)  
}

objec.func.min=function(beta.est) # this is the log likelihood function to be maximized
{
  lkhd=0
  for (i in 1:num.var)
    lkhd=lkhd-log(1+BF.var[i]*exp(Ajk.effect[i]*beta.est))+log(1+exp(Ajk.effect[i]*beta.est))
  
  lkhd=lkhd+lambda/2*sum(beta.est^2)
  
  return(lkhd)  
}

deriv.objec.func=function(beta.est)
{
  par.beta=numeric(anno.num)
  for (k in 1:anno.num) # k: annotattion index
  {
    par.beta.k=0
    for (j in 1:num.var) # j: variant index
    {
      delta.j=exp(Ajk.effect[j]*beta.est)
      par.beta.k=par.beta.k+Ajk.effect[j]*delta.j*(BF.var[j]/(1+delta.j*BF.var[j])-1/(1+delta.j))
    }  
    par.beta[k]=par.beta.k-lambda*beta.est[k] # k th element of first derivative
  }
  
  return(par.beta)
}
```

```{r parameter settings, echo=T}
num.gene=1000
m=200
N0=5000; N1=5000
delta=1
alpha0 <- 0.1
beta0 <- 1000
alpha <- 0.1
beta <- 2000
gamma.mean <- 10
sigma <- 1
split.ratio=c(0,1)
num.group=length(split.ratio)-1
anno.num=1
```


### case 1: one annotation feature


This is the simplest case in that every variant has one annotation feature if any. Use large $\beta=100$ to make all variant being causal. Set $\bar{\gamma}=10$ to make signal strong with burden close to 10. If the feature has one dimension, the objective likelihood function would be simple to be optimized using common R packages. 


Parameter Settings: N1=N0=5000; $\bar{\gamma}=10$; $\sigma=1$; $\alpha_0=\alpha=0.1$; $\beta_0=1000$; $\beta=2000$. Below is the estimate of $\widehat{\beta}$ with true $\beta=100$ by different optimization methods and tuning parameters $\lambda$. Initial values are randomly generated. 


##############################
Method | MLE ($\lambda=0$) | $\lambda=1e-4$ | $\lambda=1e-3$ | $\lambda=1e-2$ | $\lambda=0.1$ | $\lambda=1$
-------------|---------|--------|-------|--------|-------|--------|
BFGS         | 432.1624|16.2113 |21.2945| 11.9403| 9.8104| 7.7513 |
L-BFGS-B     | 19.2061 |16.1686 |14.0535| 11.9159| 9.8101| 7.7421 |
CG           | 272.6388| 142.0048| 168.9808| 49.8334| 9.8101 |7.7442| 
DEoptim      | 39.1216 |  
##############################


## Session information

<!-- Insert the session information into the document -->
```{r session-info}
```
