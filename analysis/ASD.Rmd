---
title: "ASD WES data"
author: "Shengtong Han"
date: YYYY-MM-DD
#output: html_document
output: workflowr::wflow_html
---


```{r load packages, results='hide', include=FALSE, warning=F}
library(RSQLite)
library(dplyr)
library(knitr)
library(kableExtra)
library(RColorBrewer)
library(gplots)
library(tidyverse)
library(gridExtra)
library(ggpubr)
#source("..\\code\\MIRAGE_burden_only_variant_level.R")
```

```{r, echo=F}
loadRData <- function(fileName){
#loads an RData file, and returns it
    load(fileName)
    get(ls()[ls() != "fileName"])
}
```


```{r defined function, echo=F, results='hide'}

wrap.it <- function(x, len)
{
  sapply(x, function(y) paste(strwrap(y, len),
                              collapse = "\n"),
         USE.NAMES = FALSE)
}


# Call this function with a list or vector
wrap.labels <- function(x, len)
{
  if (is.list(x))
  {
    lapply(x, wrap.it, len)
  } else {
    wrap.it(x, len)
    }
}

test.func=function(evid, Data, N1, N0) # given evid, and sample size, perform the burden analysis
{
evid.data=Data[Data$ID %in% evid,]
count=c(sum(evid.data$No.case), sum(evid.data$No.contr))
Time=c(N1, N0)
pois.test=poisson.test(count, Time, r=1, alternative="greater")
return(result=list(odds.ratio=pois.test$estimate, p.value=pois.test$p.value, rate.case=count[1]/N1, rate.contr=count[2]/N0))
}
```

<!-- Add your analysis here -->
## Quality Control (QC)
N1=N0=4315 trios. 

### Annotated data quality. 

```{r read into data, echo=F, results='hide', cache=T}
All.Anno.Data=as_tibble(read.table("../../AnnotatedTrans.txt", header=T))
#All.Anno.Data=read.table("../../AnnotatedTrans.txt", header=T)
#All.Anno.Data=read.table("C:\\Shengtong\\Research\\rare-var\\AnnotatedTrans.txt", header=T)

```

```{r set paramters and modifying the data, echo=T, results='hide'}
N1=4315; N0=4315
All.Anno.Data[All.Anno.Data =="."] <- NA
All.Anno.Data$ExacAF[is.na(All.Anno.Data$ExacAF)]=0 # set AF of NA to zero 
Anno.Data=All.Anno.Data[which(All.Anno.Data$ExacAF<0.05 & All.Anno.Data$Annotation!="synonymous SNV"),] # use AF cutoff and exclude synonymous SNV
Anno.Data=All.Anno.Data[which(All.Anno.Data$Annotation!="synonymous SNV"),] # use AF cutoff and exclude synonumous SNV

var.data=data.frame(ID=Anno.Data$ID, No.case=Anno.Data$No.case, No.contr=Anno.Data$No.contr)
```

* sample size is of 4315 
* set ExacAF of NA to be 0
* use AF cutoff and exclude synonymous SNV

```{r check missing values for every annotation, echo=F, results='hide'}
nosyn.data=All.Anno.Data[All.Anno.Data$Annotation!="synonymous SNV",]
nonsyn.data=All.Anno.Data[All.Anno.Data$Annotation=="nonsynonymous SNV",]
Anno.fea=paste(rep("ratio_valid_value_", ncol(All.Anno.Data)), colnames(All.Anno.Data), sep=""); Anno.fea[1:4]=c("#{Variants}", "#{Gene}", "rate.ca", "rate.co")
ratio.data=numeric(); ratio.nosyn=numeric(); ratio.nonsyn=numeric()
for (i in 5:length(Anno.fea))
{
  ratio.data[i]=1-sum(is.na(All.Anno.Data[,i]))/nrow(All.Anno.Data)
  ratio.nosyn[i]=1-sum(is.na(nosyn.data[,i]))/nrow(nosyn.data)
  ratio.nonsyn[i]=1-sum(is.na(nonsyn.data[,i]))/nrow(nonsyn.data)
}  
ratio.data[1]=nrow(All.Anno.Data); ratio.data[2]=length(unique(All.Anno.Data$Gene))
ratio.data[3]=sum(All.Anno.Data$No.case)/N1; ratio.data[4]=sum(All.Anno.Data$No.contr)/N0

ratio.nosyn[1]=nrow(nosyn.data); ratio.nosyn[2]=length(unique(nosyn.data$Gene))
ratio.nosyn[3]=sum(nosyn.data$No.case)/N1; ratio.nosyn[4]=sum(nosyn.data$No.contr)/N0

ratio.nonsyn[1]=nrow(nonsyn.data); ratio.nonsyn[2]=length(unique(nonsyn.data$Gene))
ratio.nonsyn[3]=sum(nonsyn.data$No.case)/N1; ratio.nonsyn[4]=sum(nonsyn.data$No.contr)/N0

data.summ=data.frame(item=Anno.fea, value.AllVar=ratio.data, value.withoutsyn=ratio.nosyn, value.nonsyn=ratio.nonsyn)
```

```{r summary of the data, echo=F}
kable(data.summ, caption="Quality of annotated data")
```

The table summaries the ratio of non-missing values in every annotation feature from different types of variants 


* first column: all variants, i.e. everything; second column: all variants excluding synonymous variants; third column: non-synonymous variants only
* "Annotation" row means nonsynonymous SNV, intronic, etc. 


### Variant rate at different AF cutoffs
```{r, echo=F, results='hide'}
ExacAF.cutoff=c(1e-2, 1e-3, 1e-4, 1e-5)
AF.summary=matrix(nrow=length(ExacAF.cutoff)+2, ncol=5)
rownames(AF.summary)=c("NULL", paste("MAF<", ExacAF.cutoff, sep=""), "private"); rownames(AF.summary)[1]=""
colnames(AF.summary)=c("No.rows", "No.var.ca", "No.var.co",  "rate.ca", "rate.co")
AF.summary[1,]=c(nrow(All.Anno.Data),sum(All.Anno.Data$No.case),sum(All.Anno.Data$No.contr), sum(All.Anno.Data$No.case)/N1, sum(All.Anno.Data$No.contr)/N0)

for (i in 1:length(ExacAF.cutoff))
{
#cat(i, "is running", "\n") 
select.data=All.Anno.Data[which(All.Anno.Data$ExacAF<ExacAF.cutoff[i]),]  
AF.summary[i+1,]=c(nrow(select.data),sum(select.data$No.case),sum(select.data$No.contr), sum(select.data$No.case)/N1, sum(select.data$No.contr)/N0)
}
select.data=All.Anno.Data[c(which(is.na(All.Anno.Data$ExacAF)==T), which(All.Anno.Data$ExacAF==0)),]
AF.summary[(length(ExacAF.cutoff)+2),]=c(nrow(select.data),sum(select.data$No.case),sum(select.data$No.contr), sum(select.data$No.case)/N1, sum(select.data$No.contr)/N0)
```
"private" variants is defined as the variants whose ExAC AF is NA or 0. 

```{r summary statistics, echo=F}
kable(AF.summary, caption="Rate of variants in cases and controls at varying AF cutoffs")
```


### Burden of synonymous mutations 
Test: one side ("greater") poisson test to see if the rate in cases is signifcantly greater than that in controls. 

```{r quality control, echo=FALSE, results='hide'}
com.result=matrix(nrow=length(ExacAF.cutoff)+2, ncol=4)
colnames(com.result)=c("OR","p.value", "rate.ca", "rate.co")
rownames(com.result)=c("",paste("MAF<",ExacAF.cutoff, sep=""), "private")
syn.data=All.Anno.Data[which(All.Anno.Data$Annotation=="synonymous SNV"), ]

test=test.func(syn.data$ID, syn.data, N1, N0)
com.result[1,]=c(test$odds.ratio,test$p.value,test$rate.case,test$rate.contr)
for (i in 1:length(ExacAF.cutoff)) {
#  cat(i," is running", "\n")
 cutoff.syn.data=syn.data[which(syn.data$ExacAF<ExacAF.cutoff[i]),]
 test=test.func(cutoff.syn.data$ID, cutoff.syn.data, N1, N0)
 com.result[i+1,]=c(test$odds.ratio,test$p.value,test$rate.case,test$rate.contr)
}  # end of i 
cutoff.syn.data=syn.data[c(which(is.na(syn.data$ExacAF)==T), which(syn.data$ExacAF==0)),]
test=test.func(cutoff.syn.data$ID, cutoff.syn.data, N1, N0)
com.result[length(ExacAF.cutoff)+2,]=c(test$odds.ratio,test$p.value,test$rate.case,test$rate.contr)
```

```{r print the table, echo=F}
kable(com.result, caption = "Burden analysis of synonymous mutations at varying AF cutoffs")
```

## Variant level analysis

### single variant 


```{r define annotations, results='hide', echo=FALSE, include=F, error=F}
var.fea=c("MAF<1e-2", "MAF<1e-3","MAF<1e-4", "Prby Damaging", "Psbl Damaging", "SIFT<0.05", "CADD top10%", "BrainExp top10%", "Consensus", "LoF", "Private"); max.vart=length(var.fea)
var.evid=list()
var.evid[[1]]=as.character(Anno.Data$ID)
var.evid[[2]]=as.character(Anno.Data$ID[which(Anno.Data$ExacAF<1e-3)])
var.evid[[3]]=as.character(Anno.Data$ID[which(Anno.Data$ExacAF<1e-4)])
var.evid[[4]]=as.character(Anno.Data$ID[which(as.numeric(as.character(Anno.Data$Polyphen2.HDIV.score))>=0.957 )]) # probably damaging >=0.957
var.evid[[5]]=as.character(Anno.Data$ID[which(as.numeric(as.character(Anno.Data$Polyphen2.HDIV.score))<=0.956 & as.numeric(as.character(Anno.Data$Polyphen2.HDIV.score))>=0.453)]) # possibly damaging
var.evid[[6]]=as.character(Anno.Data$ID[which(as.numeric(as.character(Anno.Data$SIFT.score))<0.05 )]) # deleterious SIFT<0.05
CADD.cutoff=quantile(as.numeric(as.character(Anno.Data$CADD.raw)), prob=0.9, na.rm=TRUE)
var.evid[[7]]=as.character(Anno.Data$ID[which(as.numeric(as.character(Anno.Data$CADD.raw))>CADD.cutoff)]) # CADD top 10% 
BEE.cutoff=quantile(as.numeric(Anno.Data$Exon.Brain.Exp), prob=0.9, na.rm=TRUE)
var.evid[[8]]=as.character(Anno.Data$ID[which(Anno.Data$Exon.Brain.Exp>BEE.cutoff)]) # Brain expression exon top 10%
var.evid[[9]]=union(union(var.evid[[4]], var.evid[[6]]), var.evid[[7]]) # consensus
LoF.def=c("stopgain", "frameshift substitution", "splicing", "stoploss")
var.evid[[10]]=as.character(Anno.Data$ID[which(Anno.Data$Annotation %in% LoF.def==T)]) 
var.evid[[11]]=union(as.character(All.Anno.Data$ID[which(All.Anno.Data$ExacAF==0)]), as.character(All.Anno.Data$ID[which(is.na(All.Anno.Data$ExacAF)==T)]))  
summy=matrix(nrow=max.vart, ncol=4)
colnames(summy)=c("OR", "p.value", "rate.ca", "rate.co")
rownames(summy)=var.fea
for (vart in 1:max.vart)
{
 # cat(vart, "is running", "\n")
  pois.test=test.func(var.evid[[vart]], var.data, N1, N0)
  summy[vart,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
}
```

```{r, echo=T}
kable(summy, caption="Burden analysis of single variant features")
```

```{r, echo=T,eval=F}
#pdf("D:\\ResearchWork\\StatisticalGenetics\\Latex\\Paper\\PLoS\\Figure\\burdenanalysis.pdf")
#plot(summy[,1], ylim=c(0, 2.3), ylab="", main="Burden analysis for single features", pch=15, col=1, type="p", xaxt='n', xlab="")
barcenters=barplot(summy[,1], xlim=c(0, 2.3), ylab="", main="Burden analysis for single features", pch=15, col="blue", yaxt='n', xlab="", horiz=T, width=0.9)
lines(-log(summy[,2],base=10), barcenters, col=2, pch=16, type="p")
abline(v=1, col="blue", lty=4)
abline(v=-log(0.05, base=10), col="red", lty=4)
legend(1.5, 10, c("OR", "-log(p.val)"), col=c("blue",2), pch=c(15, 16))
axis.labels <-rownames(summy)
axis(2,  las=2, at=seq(1,11), labels=axis.labels, cex.axis=0.5)
#dev.off()
```

Test: use two sample one side poisson test ("greater")

* probably damaging:Polyphen2.HDIV.score >=0.957
* possibly damaging: <0.957 & >=0.453; 
* consensus: "Prby Damaging", or  "SIFT<0.05", or   "CADD top10%" (take union)
* LoF:stopgain+ frameshift substitution+splicing+stoploss (take union)


```{r, echo=T}
Features=rownames(summy)
OR=summy[,1]; pval=summy[,2]
result.summary=data.frame(Features=Features, OR=OR, pval=pval)

#pdf("../../Figure/burden_single_feature.pdf")
ggplot(result.summary, aes(x=Features, y=OR, fill = Features))+
  geom_bar(stat="identity")+
  ylab("")+xlab("Features")+ ggtitle("Burden analysis of single features")+
  geom_point(aes(x=Features, y=-log(pval, base=10),fill=Features, size=-log(pval, base=10)),
           stat="identity")+coord_flip()+geom_hline(yintercept=1,linetype="dashed")+
  guides(fill = FALSE)+
  geom_hline(yintercept=-log(0.05, base=10), linetype="dashed", color = "red")+
   theme(plot.title = element_text(hjust = 0.5, size=10)) #center the title 
#dev.off()
```


### different gene set 


```{r burdern analysis-gene level, results='hide', echo=F}
GeneDB=src_sqlite(path="C:\\Shengtong\\Research\\rare-var\\gene.list.db", create=F)
#GeneDB=src_sqlite(path="../../gene.list.db", create=F)
gene_cate1=data.frame(collect(tbl(GeneDB, "SFARI_HighConf")))
gene_cate2=data.frame(collect(tbl(GeneDB, "SFARI_StrongCand")))
gene_cate3=data.frame(collect(tbl(GeneDB, "SFARI_cate3_gene")))
gene_cate4=data.frame(collect(tbl(GeneDB, "SFARI_cate4_gene")))
gene_cate5=data.frame(collect(tbl(GeneDB, "SFARI_cate5_gene")))
gene_cate6=data.frame(collect(tbl(GeneDB, "SFARI_cate6_gene")))
gene_cateS=data.frame(collect(tbl(GeneDB, "SFARI_cateS_gene")))
IDGene=data.frame(collect(tbl(GeneDB, "Pinto14AJHG_IDgene")))
TADAGene=data.frame(collect(tbl(GeneDB, "TADAGenelist")))
Qlessthan5percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.05]
Qlessthan20percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.2]
Qlessthan30percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.3]
Qlessthan40percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.4]
Qlessthan50percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.5]
Qlargerthan90percentgene=TADAGene$TadaName[TADAGene$qvalue.combined>0.9]
purcell.genelist=data.frame(collect(tbl(GeneDB, "Purcell2014_genelist"))) ## PSD gene, SCZdenovo gene 
ASD.gene=data.frame(collect(tbl(GeneDB, "AutismKB_gene")))
constraint.gene=data.frame(collect(tbl(GeneDB, "Samocha_2014NG_constraintgene")))$gene
RVIS.Allgene=data.frame(collect(tbl(GeneDB, "RVIS_gene")))
RVIS.gene=RVIS.Allgene$GeneID[RVIS.Allgene$RVIS.percentile<5] # top 5% gene 
haploinsuff.gene=data.frame(collect(tbl(GeneDB, "Petrovski_plosgen_haploinsuff_gene")))
gene.set=c("ID gene","High", "Mod", "PSD", "FMRP", "AutismKB", "constraint gene", "RVIS", "Haploinsuff", "SCZ gene", "Olfac.gene")
gene.fea=c("cate1", "cate2", "cate3", "cate4", "cate5", "cate6", "cateS", "TADAq<5%", "TADAq<20%", "TADAq<30%", "TADAq<40%", "TADAq<50%", "TADAq>90%", gene.set); max.gene=length(gene.fea)
LoF.def=c("stopgain", "frameshift substitution", "splicing", "stoploss")
LoF.var=as.character(Anno.Data$ID[which(Anno.Data$Annotation %in% LoF.def==T)])
gene.summy=matrix(nrow=max.gene, ncol=4)
gene.evid=list(); var.index=1
gene.evid[[1]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate1$GeneID )])
gene.evid[[2]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate2$GeneID  )])
gene.evid[[3]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate3$GeneID )])
gene.evid[[4]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate4$GeneID )])
gene.evid[[5]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate5$GeneID )])
gene.evid[[6]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate6$GeneID )])
gene.evid[[7]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cateS$GeneID )])
gene.evid[[8]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan5percentgene)])
gene.evid[[9]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan20percentgene )])
gene.evid[[10]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan30percentgene )])
gene.evid[[11]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan40percentgene )])
gene.evid[[12]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan50percentgene )])
gene.evid[[13]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlargerthan90percentgene  )])
gene.evid[[14]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% IDGene$GeneID )])
high.conf=union(union(gene_cate1$GeneID, gene_cate2$GeneID),Qlessthan5percentgene)
mod.conf=setdiff(union(union(gene_cate3$GeneID, gene_cateS$GeneID), Qlessthan30percentgene),Qlessthan5percentgene)
gene.evid[[15]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% high.conf )])
gene.evid[[16]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% mod.conf )])
psd.gene=purcell.genelist$Gene_symbol[purcell.genelist$PSD=="Y"]
FMRP.gene=purcell.genelist$Gene_symbol[purcell.genelist$FMRP.target=="Y"]
gene.evid[[17]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% psd.gene )])
gene.evid[[18]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% FMRP.gene )])
gene.evid[[19]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% ASD.gene$GeneID )])
gene.evid[[20]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% constraint.gene )])
gene.evid[[21]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% RVIS.gene )])
gene.evid[[22]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% haploinsuff.gene$GeneID )])
gene.evid[[23]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% purcell.genelist$Gene_symbol )])
olfac.gene=data.frame(collect(tbl(GeneDB, "Olfac_gene")))
gene.evid[[24]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% olfac.gene$GeneID )])
#sczgene=as.character(read.table("D:\\ResearchWork\\StatisticalGenetics\\NumericAnalysis\\RealData\\SCZData\\GeneList\\SCZ.67gene.q0.3.txt", header=T)[[1]])
#gene.evid[[25]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% sczgene & Anno.Data$Annotation %in% LoF.def==T)])

colnames(gene.summy)=c("OR", "p.value", "rate.ca", "rate.co")
#rownames(gene.summy)=c(gene.fea, "67SCZriskgene")
rownames(gene.summy)=gene.fea
for (gene in 1:(max.gene))
  if (length(gene.evid[[gene]])>0)
{
 # cat(gene, "is running", "\n")
  pois.test=test.func(gene.evid[[gene]], var.data, N1, N0)
  gene.summy[gene,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
}

```





## Exon level analysis

**All subsequence analsyis foucs on variant with AF < 5% and exluding synonymous mutautions. **

```{r burden analysis-exon level, echo=FALSE, include=F}
exon.cutoff=c(0.9, 0.8, 0.7, 0.6, 0.5)
exon.fea=c(paste("ExonTop", exon.cutoff*100, "%",sep=""), "CriticalExon")
exon.summ=matrix(nrow=(1+length(exon.cutoff)), ncol=4)
evid.exon=list()
colnames(exon.summ)=c("OR", "p.value", "rate.ca", "rate.co")
rownames(exon.summ)=c(paste("Top", exon.cutoff*100, "%", sep=""), "critical exon")
for (i in 1:length(exon.cutoff))
{
  threshold=quantile(Anno.Data$Exon.Exac.Cons, prob=exon.cutoff[i], na.rm=T)
  evid.exon[[i]]=Anno.Data$ID[which(Anno.Data$Exon.Exac.Cons>threshold)]
 # cat(i, "is running", "\n")
  pois.test=test.func(evid.exon[[i]], var.data, N1, N0)
  exon.summ[i,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
}
threshold=quantile(Anno.Data$Exon.Exac.Cons, prob=0.75, na.rm=T)
evid.exon[[1+length(exon.cutoff)]]=Anno.Data$ID[which( Anno.Data$Exon.Exac.Cons>threshold)]
exon.thrshd=quantile(Anno.Data$Exon.Brain.Exp, prob=0.75, na.rm=T)
expre.exon=Anno.Data$ID[which( Anno.Data$Exon.Brain.Exp>exon.thrshd)]
critical.exon=union(evid.exon[[1+length(exon.cutoff)]],expre.exon)
pois.test=test.func(critical.exon, var.data, N1, N0)
exon.summ[(1+length(exon.cutoff)),]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
```
Test:  use two sample one side poisson test

* high values means more constraint
* critical exon=brian expression exon top 25%+exon constraint score top 25%


```{r }
kable(exon.summ, caption="Burden analysis of exons")
```

## Gene level analysis

See [here](GeneSetAnalysis.html)

### seizure-related genes in flies

```{r seizure gene, echo=T, results="hide"}
seizure.gene=c("PNPO", "CPO", "EAS", "EAG", "JUBG", "KCC", "KDN", "LETM1", "PARA", "SEI", "SH", "SHAKB", "SLO", "SESB", "TKO")
seizure.summ=matrix(nrow=length(seizure.gene), ncol=4)

colnames(seizure.summ)=c("OR", "p.value", "rate.ca", "rate.co")
rownames(seizure.summ)=c(seizure.gene)
for (gene in 1:length(seizure.gene))
{
  seizure.evid=as.character(Anno.Data$ID[which(Anno.Data$Gene==seizure.gene[gene])])
  cat(gene, "is running", "\n")
  pois.test=test.func(seizure.evid, var.data, N1, N0)
  seizure.summ[gene,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
}
  
```


```{r, echo=T}
kable(seizure.summ)
```




## Combined feature analysis


###  combination of gene set+AF+exon


```{r burdern analysis for combined set of variants and genes, results='hide', echo=F, eval=F}

comb.exon.cutoff=exon.cutoff;
#sub.com=c(exon.fea, "LoF", "Prby Damaging", "CriticalExon", "Consensus")
sub.com=c(exon.fea, var.fea)
comb.fea=paste(rep(sub.com, each=length(gene.set)), gene.set)
AF.cutoff=c("MAF<1e-2", "MAF<1e-3", "MAF<1e-4", "Private"); colname=c("OR", "p.value", "rate.ca", "rate.co")
comb.summ=matrix(nrow=length(comb.fea), ncol=4*length(AF.cutoff))
rownames(comb.summ)=comb.fea; colnames(comb.summ)=paste(rep(AF.cutoff, each=length(colname)), colname, sep="~")
comb.summ.MIRAGE=comb.summ
#################  record burden and mirage for each cate split from combined feature ###########
Burden.cate=list()
MIRAGE.pvalue=list()
MIRAGE.para.est=list()
MIRAGE.cate.index=list()
nn=0
all.evid=list(); ii=0; all.evid.fea=paste(rep(comb.fea, each=length(AF.cutoff)), AF.cutoff)
signal1.evid=list(); jj1=0
signal2.evid=list(); jj2=0
signal3.evid=list(); jj3=0
signal4.evid=list(); jj4=0
for (i in 14:length(sub.com))
{# i=1 
  cat(i, "th subcom of ", length(sub.com), " is running", "\n")
  
  if (i<=length(comb.exon.cutoff))    # this is for exon 
  for (j in 1:length(gene.set))
  { # j=1
   for (k in 1:(length(AF.cutoff)-1)) 
  { #k=1
    comb.evid=intersect(intersect(evid.exon[[i]], gene.evid[[13+j]]), var.evid[[k]]) 
    pois.test=test.func(comb.evid, var.data, N1, N0)
    comb.summ[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
    ii=ii+1
    all.evid[[ii]]=comb.evid
    ###################### MIRAGE burden
    cand.data=Anno.Data[which(Anno.Data$ID %in% comb.evid),]
    gene.data=eight.partition(cand.data)
    overlap.data=gene.data[gene.data$ID %in% comb.evid,]
    order.overlap.data=overlap.data[order(overlap.data$group.index, decreasing=F),]
    psbl.index=unique(order.overlap.data$group.index); actu.num.group=length(psbl.index)
    delta.init=runif(1); beta.init=runif(actu.num.group)
    order.overlap.data$original.group.index=order.overlap.data$group.index
    
    if (nrow(order.overlap.data)>0)
  {  
    burden.matrix=matrix(nrow=actu.num.group, ncol=4)  # this is burden for every category split from combined feature
    colnames(burden.matrix)=c("OR", "p.value", "rate.case", "rate.contr")
    for (jj in 1:actu.num.group)
    {    
      order.overlap.data$group.index[order.overlap.data$group.index==psbl.index[jj]]=jj # re-index the group labels
      pois.test=test.func(order.overlap.data[order.overlap.data$original.group.index==psbl.index[jj],]$ID, var.data, N1, N0)
      burden.matrix[jj,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
    }
    
   para.est=multi.group.func.for.variant(order.overlap.data, N1, N0, gamma.mean=3, sigma=2, delta=0.2, beta.init, actu.num.group)
   comb.summ.MIRAGE[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=c(pois.test$odds.ratio, para.est$pvalue[length(para.est$pvalue)], pois.test$rate.case, pois.test$rate.contr)
   nn=nn+1
   MIRAGE.pvalue[[nn]]=para.est$cate.pvalue
   MIRAGE.para.est[[nn]]=para.est$beta.est
   MIRAGE.cate.index[[nn]]=psbl.index
   Burden.cate[[nn]]=burden.matrix
   }
  if (nrow(order.overlap.data)==0)  
   comb.summ.MIRAGE[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=NA
    

    ######################
    
    if (pois.test$p.value<0.05)
     {
      if (k==1)
         {
          jj1=jj1+1
          signal1.evid[[jj1]]=comb.evid
         }
         if (k==2)
         {
          jj2=jj2+1
          signal2.evid[[jj2]]=comb.evid
         }
         if (k==3)
         {
          jj3=jj3+1
          signal3.evid[[jj3]]=comb.evid
         }
      }
   }  
    k=length(AF.cutoff)
    comb.evid=intersect(intersect(evid.exon[[i]], gene.evid[[13+j]]), var.evid[[11]]) 
    pois.test=test.func(comb.evid, var.data, N1, N0)
    comb.summ[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
    ii=ii+1
    all.evid[[ii]]=comb.evid 
    
    ###################### MIRAGE burden
    cand.data=Anno.Data[which(Anno.Data$ID %in% comb.evid),]
    gene.data=eight.partition(cand.data)
    overlap.data=gene.data[gene.data$ID %in% comb.evid,]
    order.overlap.data=overlap.data[order(overlap.data$group.index, decreasing=F),]
    psbl.index=unique(order.overlap.data$group.index); actu.num.group=length(psbl.index)
    delta.init=runif(1); beta.init=runif(actu.num.group)
    order.overlap.data$original.group.index=order.overlap.data$group.index
    
    if (nrow(order.overlap.data)>0)
  {  
    burden.matrix=matrix(nrow=actu.num.group, ncol=4)  # this is burden for every category split from combined feature
    colnames(burden.matrix)=c("OR", "p.value", "rate.case", "rate.contr")
    for (jj in 1:actu.num.group)
    {    
      order.overlap.data$group.index[order.overlap.data$group.index==psbl.index[jj]]=jj # re-index the group labels
      pois.test=test.func(order.overlap.data[order.overlap.data$original.group.index==psbl.index[jj],]$ID, var.data, N1, N0)
      burden.matrix[jj,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
    }
    #  delta=runif(1)
   para.est=multi.group.func.for.variant(order.overlap.data, N1, N0, gamma.mean=3, sigma=2, delta=0.2, beta.init, actu.num.group)
   comb.summ.MIRAGE[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=c(pois.test$odds.ratio, para.est$pvalue[length(para.est$pvalue)], pois.test$rate.case, pois.test$rate.contr)
   nn=nn+1
   MIRAGE.pvalue[[nn]]=para.est$cate.pvalue
   MIRAGE.para.est[[nn]]=para.est$beta.est
   MIRAGE.cate.index[[nn]]=psbl.index
   Burden.cate[[nn]]=burden.matrix
   }
  if (nrow(order.overlap.data)==0)  
   comb.summ.MIRAGE[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=NA 
    
    
    
    if (pois.test$p.value<0.05)
    {
      jj4=jj4+1
      signal4.evid[[jj4]]=comb.evid
      }
  }
  
  if (sub.com[i] %in% var.fea==T)   # this is for variant feature 
    for (j in 1:length(gene.set))
    {    
     for (k in 1:(length(AF.cutoff)-1))  
    {
    comb.evid=intersect(intersect(var.evid[[which(sub.com[i]==var.fea)]], gene.evid[[13+j]]), var.evid[[k]]) 
    pois.test=test.func(comb.evid, var.data, N1, N0)
    comb.summ[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
    ii=ii+1
    all.evid[[ii]]=comb.evid
    
    ###################### MIRAGE burden
    cand.data=Anno.Data[which(Anno.Data$ID %in% comb.evid),]
    gene.data=eight.partition(cand.data)
    overlap.data=gene.data[gene.data$ID %in% comb.evid,]
    order.overlap.data=overlap.data[order(overlap.data$group.index, decreasing=F),]
    psbl.index=unique(order.overlap.data$group.index); actu.num.group=length(psbl.index)
    delta.init=runif(1); beta.init=runif(actu.num.group)
    order.overlap.data$original.group.index=order.overlap.data$group.index
   
  if (nrow(order.overlap.data)>0)
  {     
   burden.matrix=matrix(nrow=actu.num.group, ncol=4)  # this is burden for every category split from combined feature
    colnames(burden.matrix)=c("OR", "p.value", "rate.case", "rate.contr")
    for (jj in 1:actu.num.group)
    {    
      order.overlap.data$group.index[order.overlap.data$group.index==psbl.index[jj]]=jj # re-index the group labels
      pois.test=test.func(order.overlap.data[order.overlap.data$original.group.index==psbl.index[jj],]$ID, var.data, N1, N0)
      burden.matrix[jj,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
    }
    #  delta=runif(1)
   para.est=multi.group.func.for.variant(order.overlap.data, N1, N0, gamma.mean=3, sigma=2, delta=0.2, beta.init, actu.num.group)
   comb.summ.MIRAGE[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=c(pois.test$odds.ratio, para.est$pvalue[length(para.est$pvalue)], pois.test$rate.case, pois.test$rate.contr)
   nn=nn+1
   MIRAGE.pvalue[[nn]]=para.est$cate.pvalue
   MIRAGE.para.est[[nn]]=para.est$beta.est
   MIRAGE.cate.index[[nn]]=psbl.index
   Burden.cate[[nn]]=burden.matrix
   }
  if (nrow(order.overlap.data)==0)  
   comb.summ.MIRAGE[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=NA
    
    
    if (pois.test$p.value<0.05)
     {
      if (k==1)
         {
          jj1=jj1+1
          signal1.evid[[jj1]]=comb.evid
         }
         if (k==2)
         {
          jj2=jj2+1
          signal2.evid[[jj2]]=comb.evid
         }
         if (k==3)
         {
          jj3=jj3+1
          signal3.evid[[jj3]]=comb.evid
         }
      }
     } 
     k=length(AF.cutoff)
    comb.evid=intersect(intersect(var.evid[[which(sub.com[i]==var.fea)]], gene.evid[[13+j]]), var.evid[[11]]) 
    pois.test=test.func(comb.evid, var.data, N1, N0)
    comb.summ[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
    ii=ii+1
    all.evid[[ii]]=comb.evid 
    
    ###################### MIRAGE burden
    cand.data=Anno.Data[which(Anno.Data$ID %in% comb.evid),]
    gene.data=eight.partition(cand.data)
    overlap.data=gene.data[gene.data$ID %in% comb.evid,]
    order.overlap.data=overlap.data[order(overlap.data$group.index, decreasing=F),]
    psbl.index=unique(order.overlap.data$group.index); actu.num.group=length(psbl.index)
    delta.init=runif(1); beta.init=runif(actu.num.group)
    order.overlap.data$original.group.index=order.overlap.data$group.index
    
    if (nrow(order.overlap.data)>0)
  {  
    burden.matrix=matrix(nrow=actu.num.group, ncol=4)  # this is burden for every category split from combined feature
    colnames(burden.matrix)=c("OR", "p.value", "rate.case", "rate.contr")
    for (jj in 1:actu.num.group)
    {    
      order.overlap.data$group.index[order.overlap.data$group.index==psbl.index[jj]]=jj # re-index the group labels
      pois.test=test.func(order.overlap.data[order.overlap.data$original.group.index==psbl.index[jj],]$ID, var.data, N1, N0)
      burden.matrix[jj,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
    }
   
   para.est=multi.group.func.for.variant(order.overlap.data, N1, N0, gamma.mean=3, sigma=2, delta=0.2, beta.init, actu.num.group)
   comb.summ.MIRAGE[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=c(pois.test$odds.ratio, para.est$pvalue[length(para.est$pvalue)], pois.test$rate.case, pois.test$rate.contr)
   nn=nn+1
   MIRAGE.pvalue[[nn]]=para.est$cate.pvalue
   MIRAGE.para.est[[nn]]=para.est$beta.est
   MIRAGE.cate.index[[nn]]=psbl.index
   Burden.cate[[nn]]=burden.matrix
   }
  if (nrow(order.overlap.data)==0)  
   comb.summ.MIRAGE[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=NA
    
    
    
    
    if (pois.test$p.value<0.05)
    {
      jj4=jj4+1
      signal4.evid[[jj4]]=comb.evid
      }
    }
  
  if (sub.com[i]=="CriticalExon")  # this is for critical exon
    for (j in 1:length(gene.set))
    {    
     for (k in 1:(length(AF.cutoff)-1))  
    {
    comb.evid=intersect(intersect(critical.exon, gene.evid[[13+j]]), var.evid[[k]]) 
    pois.test=test.func(comb.evid, var.data, N1, N0)
    comb.summ[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
    ii=ii+1
    all.evid[[ii]]=comb.evid
    
    ###################### MIRAGE burden
    cand.data=Anno.Data[which(Anno.Data$ID %in% comb.evid),]
    gene.data=eight.partition(cand.data)
    overlap.data=gene.data[gene.data$ID %in% comb.evid,]
    order.overlap.data=overlap.data[order(overlap.data$group.index, decreasing=F),]
    psbl.index=unique(order.overlap.data$group.index); actu.num.group=length(psbl.index)
    delta.init=runif(1); beta.init=runif(actu.num.group)
    order.overlap.data$original.group.index=order.overlap.data$group.index
    
    if (nrow(order.overlap.data)>0)
  {  
    burden.matrix=matrix(nrow=actu.num.group, ncol=4)  # this is burden for every category split from combined feature
    colnames(burden.matrix)=c("OR", "p.value", "rate.case", "rate.contr")
    for (jj in 1:actu.num.group)
    {    
      order.overlap.data$group.index[order.overlap.data$group.index==psbl.index[jj]]=jj # re-index the group labels
      pois.test=test.func(order.overlap.data[order.overlap.data$original.group.index==psbl.index[jj],]$ID, var.data, N1, N0)
      burden.matrix[jj,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
    }
    #  delta=runif(1)
   para.est=multi.group.func.for.variant(order.overlap.data, N1, N0, gamma.mean=3, sigma=2, delta=0.2, beta.init, actu.num.group)
   comb.summ.MIRAGE[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=c(pois.test$odds.ratio, para.est$pvalue[length(para.est$pvalue)], pois.test$rate.case, pois.test$rate.contr)
   nn=nn+1
   MIRAGE.pvalue[[nn]]=para.est$cate.pvalue
   MIRAGE.para.est[[nn]]=para.est$beta.est
   MIRAGE.cate.index[[nn]]=psbl.index
   Burden.cate[[nn]]=burden.matrix
   }
  if (nrow(order.overlap.data)==0)  
   comb.summ.MIRAGE[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=NA
    
  
    
    
    if (pois.test$p.value<0.05)
     {
      if (k==1)
         {
          jj1=jj1+1
          signal1.evid[[jj1]]=comb.evid
         }
         if (k==2)
         {
          jj2=jj2+1
          signal2.evid[[jj2]]=comb.evid
         }
         if (k==3)
         {
          jj3=jj3+1
          signal3.evid[[jj3]]=comb.evid
         }
      }
     } 
    k=length(AF.cutoff)
    comb.evid=intersect(intersect(critical.exon, gene.evid[[13+j]]), var.evid[[11]]) 
    pois.test=test.func(comb.evid, var.data, N1, N0)
    comb.summ[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
    ii=ii+1
    all.evid[[ii]]=comb.evid 
    
    ###################### MIRAGE burden
    cand.data=Anno.Data[which(Anno.Data$ID %in% comb.evid),]
    gene.data=eight.partition(cand.data)
    overlap.data=gene.data[gene.data$ID %in% comb.evid,]
    order.overlap.data=overlap.data[order(overlap.data$group.index, decreasing=F),]
    psbl.index=unique(order.overlap.data$group.index); actu.num.group=length(psbl.index)
    delta.init=runif(1); beta.init=runif(actu.num.group)
    order.overlap.data$original.group.index=order.overlap.data$group.index
    
     if (nrow(order.overlap.data)>0)
  {     
    burden.matrix=matrix(nrow=actu.num.group, ncol=4)  # this is burden for every category split from combined feature
    colnames(burden.matrix)=c("OR", "p.value", "rate.case", "rate.contr")
    for (jj in 1:actu.num.group)
    {    
      order.overlap.data$group.index[order.overlap.data$group.index==psbl.index[jj]]=jj # re-index the group labels
      pois.test=test.func(order.overlap.data[order.overlap.data$original.group.index==psbl.index[jj],]$ID, var.data, N1, N0)
      burden.matrix[jj,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
    }
    #  delta=runif(1)

   para.est=multi.group.func.for.variant(order.overlap.data, N1, N0, gamma.mean=3, sigma=2, delta=0.2, beta.init, actu.num.group)
   comb.summ.MIRAGE[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=c(pois.test$odds.ratio, para.est$pvalue[length(para.est$pvalue)], pois.test$rate.case, pois.test$rate.contr)
   nn=nn+1
   MIRAGE.pvalue[[nn]]=para.est$cate.pvalue
   MIRAGE.para.est[[nn]]=para.est$beta.est
   MIRAGE.cate.index[[nn]]=psbl.index
   Burden.cate[[nn]]=burden.matrix
   }
  if (nrow(order.overlap.data)==0)  
   comb.summ.MIRAGE[(i-1)*length(gene.set)+j,((k-1)*4+1):(k*4)]=NA 
    
    
    
    if (pois.test$p.value<0.05)
    {
      jj4=jj4+1
      signal4.evid[[jj4]]=comb.evid
      }
    }
   
}  
#save(comb.summ, comb.summ.MIRAGE, MIRAGE.cate.index, MIRAGE.para.est, MIRAGE.pvalue, Burden.cate, file="..\\output\\CombinedFeature\\Burden.MIRAGE.for.Combined.Feature.RData")
```


```{r, echo=F}
load("../output/CombinedFeature/Burden.MIRAGE.for.Combined.Feature.RData")
#Burden.result=tibble(OR=as.numeric(comb.summ[,c(1, 5, 9, 13)]), pvalue=as.numeric(comb.summ[,c(2,6,10,14)]))
#g1=ggplot(Burden.result, aes(x=OR, y=-log(pvalue, base=10)))+
#  geom_point()+
#  geom_hline(yintercept=-log(0.05, base=10), linetype="dashed", color = "red")+
#  xlab("Odds ratio")+ylab(expression(paste("-log" [10], "(p value)")))+
#  ggtitle("Burden test")

#MIRAGE.result=tibble(OR=as.numeric(comb.summ.MIRAGE[,c(1, 5, 9, 13)]), pvalue=as.numeric(comb.summ.MIRAGE[,c(2,6,10,14)]))
#g2=ggplot(MIRAGE.result, aes(x=OR, y=-log(pvalue, base=10)))+
#  geom_point()+
#  geom_hline(yintercept=-log(0.05, base=10), linetype="dashed", color = "red")+
#  xlab("Odds ratio")+ylab(expression(paste("-log" [10], "(p value)")))+
#  ggtitle("MIRAGE")


Burden.OR=numeric(); Burden.pvalue=numeric()
for (ii in 1:length(Burden.cate))
{
  Burden.OR=c(Burden.OR, Burden.cate[[ii]][,1])
  Burden.pvalue=c(Burden.pvalue, Burden.cate[[ii]][,2])
}


Burden.MIRAGE.combine=tibble(Burden.OR=Burden.OR, Burden.pvalue=-log(Burden.pvalue, base=10), MIRAGE.risk.prop=unlist(MIRAGE.para.est), MIRAGE.pvalue=-log(unlist(MIRAGE.pvalue), base=10), cate.index=unlist(MIRAGE.cate.index))
Burden.MIRAGE.combine <- drop_na(Burden.MIRAGE.combine) # remove rows with NA
Burden.MIRAGE.combine.clear <- as_tibble(data.matrix(Burden.MIRAGE.combine)[is.finite(rowSums(data.matrix(Burden.MIRAGE.combine))),])
Burden.MIRAGE.combine.clear$cate.index=Burden.MIRAGE.combine.clear$cate.index %>% recode("1"="LoF; 1%<AF<5%", "2"="LoF; AF<1%", "3" = "Damaging; 1%<AF<5%","4"= "Damaging; 0.1%<FA<1%", "5" ="Damaging; AF<0.1%", "6" ="Non-damaging; 1%<AF<5%", "7" ="Non-damaging; 0.1%<AF<1%", "8" ="Non-damaging; AF<0.1%")

g1=ggplot(as_tibble(Burden.MIRAGE.combine.clear), aes(x=Burden.OR, y=Burden.pvalue, color=as.factor(cate.index), shape=as.factor(cate.index)))+
  scale_shape_manual(values=1:nlevels(as.factor(Burden.MIRAGE.combine.clear$cate.index)))+
  geom_point()+
  xlim(c(0,4))+
  geom_hline(yintercept=-log(0.05, base=10), linetype="dashed", color = "red")+
  xlab("OR")+ylab(expression(paste("-log" [10], "(p value)")))+
  ggtitle("Burden")+
  theme_classic()+
   theme(legend.position = "none")+  # no legend 
theme(plot.title = element_text(hjust = 0.5, size=10)) +# center the title 
theme(legend.title=element_blank())

g2=ggplot(as_tibble(Burden.MIRAGE.combine.clear), aes(x=MIRAGE.risk.prop, y=MIRAGE.pvalue, color=as.factor(cate.index), shape=as.factor(cate.index)))+
  scale_shape_manual(values=1:nlevels(as.factor(Burden.MIRAGE.combine.clear$cate.index)))+  # manually define shapes if more than 6 groups 
  geom_point()+
  xlab(expression(paste(hat(eta))))+
  ylab("")+
  geom_hline(yintercept=-log(0.05, base=10), linetype="dashed", color = "red")+
  ggtitle("MIRAGE-VS")+
  theme_classic()+
  theme(plot.title = element_text(hjust = 0.5, size=10))+  # center the title 
  #labs(color='variant group')+   # define legend title 
  theme(legend.title=element_blank())+
  theme(legend.text=element_text(size=1))
  #theme(legend.position = c(0.8, 4),
  #        legend.direction = "vertical")
#+
  #theme(legend.position="bottom")
#pdf("C:/Users/han24/OneDrive - UWM/rare-var/Figure/Supp/Fig-Burden_MIRAGE-vs_CombinedFeature_Split.pdf")
ggarrange(g1, g2,nrow=1, common.legend = TRUE, legend="bottom")  # multiple panels share one legend 
#dev.off()




```

For more than 700 combined features, each one is split into one or more partition groups by the definition. For every split partition group, perform burden test and MIRAGE-vs test.   

```{r, echo=F}
#Burden_MIRAGE_Summary=loadRData("../output/Burden_MIRAGE_Comparison.RData")
load("../output/CombinedFeature/Burden.MIRAGE.for.Combined.Feature.RData")
Burden_summary=comb.summ
MIRAGE_summary=comb.summ.MIRAGE
pick.feature=1:6
num.feature=length(pick.feature)
burden_mirage_pvalue=tibble(pvalue=c(Burden_summary[pick.feature,2], MIRAGE_summary[pick.feature,2]), cate=c(rownames(Burden_summary)[pick.feature], c(rownames(Burden_summary)[pick.feature])), method=c(rep("Burden", num.feature), rep("MIRAGE", num.feature)))
#pdf("C:/Users/han24/OneDrive - UWM/rare-var/Figure/Supp/Fig-power_comparison_MIRAGE-vs_varyGammabar.pdf")
#pdf("../../Figure/burden_pvalue_comparison.pdf")
#ggplot(burden_mirage_pvalue, aes(x=cate, y=-log(pvalue, base=10), fill=method))+
#  geom_bar(stat="identity", width=.5, position = "dodge")+xlab("Features")+ylab(expression(paste("-log" [10], "(p value)")))+
#  ggtitle(expression(paste("Combined features with AF<", 10^{-2})))+
#  geom_hline(yintercept=-log(0.05, base=10), linetype="dashed", color = "red")+
#  coord_flip()
#dev.off()  
```


Burden test: one sided two sample Poisson test, MIRAGE: estimate parameters, then do likelihood ratio test. 


**Feature combinations: exon/LoF/missense+gene+MAF cutoff**


```{r feature combinations}
kable(comb.summ[,1:4], caption="Combined Annotations", "html")%>%
kable_styling() %>%
scroll_box(height = "200px")

kable(comb.summ[,5:8], caption="Combined Annotations (Cont)", "html")%>%
kable_styling() %>%
scroll_box(height = "200px")

kable(comb.summ[,9:12], caption="Combined Annotations (Cont)", "html")%>%
kable_styling() %>%
scroll_box(height = "200px") 

kable(comb.summ[,13:16], caption="Combined Annotations (Cont)", "html")%>%
kable_styling() %>%
scroll_box(height = "200px")

```


### significant features with p value less than 0.05. 

**Signals with p value<0.05**


```{r extract signal, echo=F}
signal.row=unique(c(which(comb.summ[,2]<0.05), which(comb.summ[,6]<0.05), which(comb.summ[,10]<0.05), which(comb.summ[,14]<0.05)))
poten.signal=comb.summ[signal.row,]
kable(poten.signal[,1:4], caption="Signals with small p values", "html")%>%
kable_styling() %>%
scroll_box(height = "200px")

kable(poten.signal[,5:8], caption="Signals with small p values (Cont)", "html")%>%
kable_styling() %>%
scroll_box(height = "200px")

kable(poten.signal[,9:12], caption="Signals with small p values (Cont)", "html")%>%
kable_styling() %>%
scroll_box(height = "200px")


kable(poten.signal[,13:16], caption="Signals with small p values (Cont)", "html")%>%
kable_styling() %>%
scroll_box(height = "200px")

```


```{r, echo=F, eval=F}
#pdf("D:\\ResearchWork\\StatisticalGenetics\\Latex\\Paper\\PLoS\\Figure\\CombinedFeatureAFMinus2.pdf")
#plot(poten.signal[which(poten.signal[,2]<0.05),1],seq(1, nrow(poten.signal[which(poten.signal[,2]<0.05),])),  pch=15, col=1, xlim=c(0, max(poten.signal[,1])+1), ylab="", xlab="OR", yaxt='n', main=expression(paste("Combined features with AF<", 10^{-2})))
barcenters=barplot(poten.signal[which(poten.signal[,2]<0.05),1],  pch=15, col="blue", xlim=c(0, max(poten.signal[,1])+2), ylab="", xlab="OR", yaxt='n', main=expression(paste("Combined features with AF<", 10^{-2})), horiz=T, width=0.85)
#lines(-log(poten.signal[which(poten.signal[,2]<0.05),2], base=10), seq(1,nrow(poten.signal[which(poten.signal[,2]<0.05),])), pch=16, col=2, type="p")
points(-log(poten.signal[which(poten.signal[,2]<0.05),2], base=10), barcenters, pch=16, col=2, type="p")
#segments(barcenters,poten.signal[which(poten.signal[,2]<0.05),1] , poten.signal[which(poten.signal[,2]<0.05),1],  barcenters, -log(poten.signal[which(poten.signal[,2]<0.05),2],base=10),lwd = 1.5 )
abline(v=1, col="blue", lty=4)
abline(v=-log(0.05, base=10), col=2, lty=4)
axis.labels <-row.names(poten.signal[which(poten.signal[,2]<0.05),])
axis(side=2, las=2, at=seq(1,length(axis.labels)), labels=wrap.it(axis.labels, 15), cex.axis=0.4)
legend(3.5, 21, c("OR", "-log(p.val)"), col=c("blue",2), pch=c(15,16))
#dev.off()
```




```{r, echo=F, eval=F}
Features=row.names(poten.signal[which(poten.signal[,2]<0.05),])
OR=poten.signal[which(poten.signal[,2]<0.05),1]; pval=poten.signal[which(poten.signal[,2]<0.05),2]
result.summary=tibble(Features=Features, OR=OR, pval=pval)
 #pdf("../../Figure/combined_feature_AFlessthan2per.pdf")
  ggplot(result.summary, aes(x=Features, y=OR, fill = Features))+
  geom_bar(stat="identity")+
  ylab("")+xlab("Features")+ ggtitle(expression(paste("Combined features with AF<", 10^{-2})))+
  geom_point(aes(x=Features, y=-log(pval, base=10), size=-log(pval, base=10)),
           stat="identity")+coord_flip()+geom_hline(yintercept=1,linetype="dashed")+
    guides(fill = FALSE)+
  geom_hline(yintercept=-log(0.05, base=10), linetype="dashed", color = "red")#+
    #theme(legend.key.size = unit(0.65,"line"))  # this is to control legend size 
 #dev.off()
```




```{r, echo=F}
par(mfrow=c(2,2))
plot(poten.signal[which(poten.signal[,2]<0.05),1], ylab="OR", pch=19, ylim=c(0, max(poten.signal[,1])+1), xlab="", xaxt='n', main=expression(paste("Combined features with AF<", 10^{-2})))
abline(h=1, col="red", lty=4)
axis.labels <-row.names(poten.signal[which(poten.signal[,2]<0.05),])
axis(1, las=2, at=seq(1,length(axis.labels)), labels=axis.labels, cex.axis=0.45)


plot(poten.signal[which(poten.signal[,6]<0.05),5], ylab="OR", pch=19, ylim=c(0, max(poten.signal[,5])+1), xlab="", xaxt='n', main=expression(paste("Combined features with AF<", 10^{-3})))
abline(h=1, col="red", lty=4)
axis.labels <-row.names(poten.signal[which(poten.signal[,6]<0.05),])
axis(1, las=2, at=seq(1,length(axis.labels)), labels=axis.labels, cex.axis=0.45)


plot(poten.signal[which(poten.signal[,10]<0.05),9], ylab="OR", pch=19, ylim=c(0, max(poten.signal[,9])+1), xlab="", xaxt='n', main=expression(paste("Combined features with AF<", 10^{-4})))
abline(h=1, col="red", lty=4)
axis.labels <-row.names(poten.signal[which(poten.signal[,10]<0.05),])
axis(1, las=2, at=seq(1,length(axis.labels)), labels=axis.labels, cex.axis=0.45)


plot(poten.signal[which(poten.signal[,14]<0.05),13], ylab="OR", pch=19, ylim=c(0, max(poten.signal[,13])+1), xlab="", xaxt='n', main=expression(paste("Combined features with private variants")))
abline(h=1, col="red", lty=4)
axis.labels <-row.names(poten.signal[which(poten.signal[,14]<0.05),])
axis(1, las=2, at=seq(1,length(axis.labels)), labels=axis.labels, cex.axis=0.45)
```


```{r, echo=F, eval=F}
#barplot(-log(poten.signal[which(poten.signal[,2]<0.05),2]), horiz=T)
pval=read.table("D:\\ResearchWork\\StatisticalGenetics\\Rare-variant-project\\rare-var-project\\output\\signal1.para.deltaof1.txt", header=T)
plot(-log(poten.signal[which(poten.signal[,2]<0.05),2], base=10), seq(1,20), pch=16, xlim=c(0, 6), col=1, ylab="", xlab="-log(p.value)", yaxt='n')
lines(-log(pval[,3], base=10), seq(1,20), pch=16, col=2, type="p")
axis.labels <-row.names(poten.signal[which(poten.signal[,6]<0.05),])
axis(2, las=2, at=seq(1,length(axis.labels)), labels=axis.labels, cex.axis=0.45)
```




## Session information

<!-- Insert the session information into the document -->
```{r session-info}
```
