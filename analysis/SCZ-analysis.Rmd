---
title: "SCZ analysis"
author: "Shengtong Han"
date: YYYY-MM-DD
output: html_document
---

<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```


<!-- Add your analysis here -->


```{r load packages, results='hide', include=FALSE}
rm(list=ls())
library(RSQLite)
library(dplyr)
library(knitr)
set.seed(123)
```

```{r defined function, echo=F, results='hide'}
test.func=function(evid, Data, N1, N0) # given evid, and sample size, perform the burden analysis
{
evid.data=Data[Data$ID %in% evid,]
count=c(sum(evid.data$No.case), sum(evid.data$No.contr))
Time=c(N1, N0)
pois.test=poisson.test(count, Time, r=1, alternative="greater")
return(result=list(odds.ratio=pois.test$estimate, p.value=pois.test$p.value, rate.case=count[1]/N1, rate.contr=count[2]/N0))
}
```


```{r, echo=F}
eight.partition=function(cand.data) # given gene data and annotations, do variant partitions
{
  par.evid=list()
  LoF.def=c("stopgain", "frameshift substitution", "splicing", "stoploss")
  par.evid[[1]]=which(cand.data$Annotation %in% LoF.def==T & cand.data$ExacAF<0.05 & cand.data$ExacAF>=0.01 )
  par.evid[[2]]=which(cand.data$Annotation %in% LoF.def==T &  cand.data$ExacAF<0.01)

  par.evid[[3]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))>=0.957 & cand.data$ExacAF>=0.01 & cand.data$ExacAF<0.05)
  par.evid[[4]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))>=0.957 & cand.data$ExacAF>=0.001 & cand.data$ExacAF<0.01)
  par.evid[[5]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))>=0.957 &  cand.data$ExacAF<0.001)

  par.evid[[6]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))<0.957 & cand.data$ExacAF>=0.01 & cand.data$ExacAF<0.05)
  par.evid[[7]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))<0.957 & cand.data$ExacAF>=0.001 & cand.data$ExacAF<0.01)
  par.evid[[8]]=which(cand.data$Annotation %in% LoF.def==F & as.numeric(as.character(cand.data$Polyphen2.HDIV.score))<0.957 & cand.data$ExacAF<0.001)

  group.index=rep(NA, nrow(cand.data))
  for (i in 1:length(par.evid))
    group.index[par.evid[[i]]]=i
  gene.data=data.frame(ID=cand.data$ID, Gene=cand.data$Gene, No.case=cand.data$No.case, No.contr=cand.data$No.contr, group.index=group.index)
  gene.data=gene.data[complete.cases(gene.data),]
  return(gene.data)
}
```

<!-- Add your analysis here -->
The data is from this [paper][paper].


[paper]: http://www.nature.com/nature/journal/v506/n7487/full/nature12975.html?foxtrotcallback=true


## Quality Control (QC)

### Annotated data quality. 

```{r read into data, echo=F, results='hide'}
# working directory: "C:/Shengtong/Research/rare-var/rare-var-project/analysis"
All.Anno.Data=read.table("../../AnnotatedSCZ.txt", header=T)
colnames(All.Anno.Data)[10]="Exon.Exac.Cons"
```

```{r set paramters and modifying the data, echo=T, results='hide'}
N1=2536; N0=2543
All.Anno.Data[All.Anno.Data =="."] <- NA
All.Anno.Data$ExacAF[is.na(All.Anno.Data$ExacAF)]=0 # set AF of NA to zero 
Anno.Data=All.Anno.Data[which(All.Anno.Data$ExacAF<0.05 & All.Anno.Data$Annotation!="synonymous SNV"),] # use AF cutoff and exclude synonumous SNV
var.data=data.frame(ID=Anno.Data$ID, No.case=Anno.Data$No.case, No.contr=Anno.Data$No.contr)
```

* sample size is N1=2536; N0=2543 
* set ExacAF of NA to be 0
* use AF cutoff and exclude synonymous SNV




```{r check missing values for every annotation, echo=F, results='hide'}
nosyn.data=All.Anno.Data[All.Anno.Data$Annotation!="synonymous SNV",]
nonsyn.data=All.Anno.Data[All.Anno.Data$Annotation=="nonsynonymous SNV",]
Anno.fea=paste(rep("ratio_valid_value_", ncol(All.Anno.Data)), colnames(All.Anno.Data), sep=""); Anno.fea[1:4]=c("#{Variants}", "#{Gene}", "rate.ca", "rate.co")
ratio.data=numeric(); ratio.nosyn=numeric(); ratio.nonsyn=numeric()
for (i in 5:length(Anno.fea))
{
  ratio.data[i]=1-sum(is.na(All.Anno.Data[,i]))/nrow(All.Anno.Data)
  ratio.nosyn[i]=1-sum(is.na(nosyn.data[,i]))/nrow(nosyn.data)
  ratio.nonsyn[i]=1-sum(is.na(nonsyn.data[,i]))/nrow(nonsyn.data)
}  
ratio.data[1]=nrow(All.Anno.Data); ratio.data[2]=length(unique(All.Anno.Data$Gene))
ratio.data[3]=sum(All.Anno.Data$No.case)/N1; ratio.data[4]=sum(All.Anno.Data$No.contr)/N0

ratio.nosyn[1]=nrow(nosyn.data); ratio.nosyn[2]=length(unique(nosyn.data$Gene))
ratio.nosyn[3]=sum(nosyn.data$No.case)/N1; ratio.nosyn[4]=sum(nosyn.data$No.contr)/N0

ratio.nonsyn[1]=nrow(nonsyn.data); ratio.nonsyn[2]=length(unique(nonsyn.data$Gene))
ratio.nonsyn[3]=sum(nonsyn.data$No.case)/N1; ratio.nonsyn[4]=sum(nonsyn.data$No.contr)/N0

data.summ=data.frame(item=Anno.fea, value.AllVar=ratio.data, value.withoutsyn=ratio.nosyn, value.nonsyn=ratio.nonsyn)
```
```{r summary of the data, echo=F}
kable(data.summ, caption="Quality of annotated data")
```


The table summaries the ratio of non-missing values in every annotation feature from different types of variants 


* first column: all variants, i.e. everything; second column: all variants excluding synonymous variants; third column: non-synonymous variants only
* "Annotation" row means nonsynonymous SNV, intronic, etc. 


### Variant rate at different AF cutoffs
```{r, echo=F, results='hide'}
ExacAF.cutoff=c(1e-2, 1e-3, 1e-4, 1e-5)
AF.summary=matrix(nrow=length(ExacAF.cutoff)+2, ncol=5)
rownames(AF.summary)=c("NULL", paste("MAF<", ExacAF.cutoff, sep=""), "private"); rownames(AF.summary)[1]=""
colnames(AF.summary)=c("No.rows", "No.var.ca", "No.var.co",  "rate.ca", "rate.co")
AF.summary[1,]=c(nrow(All.Anno.Data),sum(All.Anno.Data$No.case),sum(All.Anno.Data$No.contr), sum(All.Anno.Data$No.case)/N1, sum(All.Anno.Data$No.contr)/N0)

for (i in 1:length(ExacAF.cutoff))
{
cat(i, "is running", "\n") 
select.data=All.Anno.Data[which(All.Anno.Data$ExacAF<ExacAF.cutoff[i]),]  
AF.summary[i+1,]=c(nrow(select.data),sum(select.data$No.case),sum(select.data$No.contr), sum(select.data$No.case)/N1, sum(select.data$No.contr)/N0)
}
select.data=All.Anno.Data[c(which(is.na(All.Anno.Data$ExacAF)==T), which(All.Anno.Data$ExacAF==0)),]
AF.summary[(length(ExacAF.cutoff)+2),]=c(nrow(select.data),sum(select.data$No.case),sum(select.data$No.contr), sum(select.data$No.case)/N1, sum(select.data$No.contr)/N0)
```
"private" variants is defined as the variants whose ExAC AF is NA or 0. 

```{r summary statistics, echo=F}
kable(AF.summary, caption="Rate of variants in cases and controls at varying AF cutoffs")
```


### Burden of synonymous mutations 
Test: one side ("greater") poisson test to see if the rate in cases is signifcantly greater than that in controls. 

```{r quality control, echo=FALSE, results='hide'}
com.result=matrix(nrow=length(ExacAF.cutoff)+2, ncol=4)
colnames(com.result)=c("OR","p.value", "rate.ca", "rate.co")
rownames(com.result)=c("",paste("MAF<",ExacAF.cutoff, sep=""), "private")
syn.data=All.Anno.Data[which(All.Anno.Data$Annotation=="synonymous SNV"), ]

test=test.func(syn.data$ID, syn.data, N1, N0)
com.result[1,]=c(test$odds.ratio,test$p.value,test$rate.case,test$rate.contr)
for (i in 1:length(ExacAF.cutoff)) {
  cat(i," is running", "\n")
 cutoff.syn.data=syn.data[which(syn.data$ExacAF<ExacAF.cutoff[i]),]
 test=test.func(cutoff.syn.data$ID, cutoff.syn.data, N1, N0)
 com.result[i+1,]=c(test$odds.ratio,test$p.value,test$rate.case,test$rate.contr)
}  # end of i 
cutoff.syn.data=syn.data[c(which(is.na(syn.data$ExacAF)==T), which(syn.data$ExacAF==0)),]
test=test.func(cutoff.syn.data$ID, cutoff.syn.data, N1, N0)
com.result[length(ExacAF.cutoff)+2,]=c(test$odds.ratio,test$p.value,test$rate.case,test$rate.contr)
```

```{r print the table, echo=F}
kable(com.result, caption = "Burden analysis of synonymous mutations at verying AF cutoffs")
```

## Variant level analysis

### single variant 


```{r define annotations, results='hide', echo=FALSE, include=F, error=F}
var.fea=c("MAF<1e-2", "MAF<1e-3","MAF<1e-4", "Prby Damaging", "Psbl Damaging", "SIFT<0.05", "CADD top10%", "BrainExp top10%", "Consensus", "LoF", "Private"); max.vart=length(var.fea)
var.evid=list()
var.evid[[1]]=as.character(Anno.Data$ID)
var.evid[[2]]=as.character(Anno.Data$ID[which(Anno.Data$ExacAF<1e-3)])
var.evid[[3]]=as.character(Anno.Data$ID[which(Anno.Data$ExacAF<1e-4)])
var.evid[[4]]=as.character(Anno.Data$ID[which(as.numeric(as.character(Anno.Data$Polyphen2.HDIV.score))>=0.957 )]) # probably damaging >=0.957
var.evid[[5]]=as.character(Anno.Data$ID[which(as.numeric(as.character(Anno.Data$Polyphen2.HDIV.score))<=0.956 & as.numeric(as.character(Anno.Data$Polyphen2.HDIV.score))>=0.453)]) # possibly damaging
var.evid[[6]]=as.character(Anno.Data$ID[which(as.numeric(as.character(Anno.Data$SIFT.score))<0.05 )]) # deleterious SIFT<0.05
CADD.cutoff=quantile(as.numeric(as.character(Anno.Data$CADD.raw)), prob=0.9, na.rm=TRUE)
var.evid[[7]]=as.character(Anno.Data$ID[which(as.numeric(as.character(Anno.Data$CADD.raw))>CADD.cutoff)]) # CADD top 10% 
BEE.cutoff=quantile(as.numeric(Anno.Data$Exon.Brain.Exp), prob=0.9, na.rm=TRUE)
var.evid[[8]]=as.character(Anno.Data$ID[which(Anno.Data$Exon.Brain.Exp>BEE.cutoff)]) # Brain expression exon top 10%
var.evid[[9]]=union(union(var.evid[[4]], var.evid[[6]]), var.evid[[7]]) # consensus
LoF.def=c("stopgain", "frameshift substitution", "splicing", "stoploss")
var.evid[[10]]=as.character(Anno.Data$ID[which(Anno.Data$Annotation %in% LoF.def==T)]) 
var.evid[[11]]=union(as.character(All.Anno.Data$ID[which(All.Anno.Data$ExacAF==0)]), as.character(All.Anno.Data$ID[which(is.na(All.Anno.Data$ExacAF)==T)]))  
summy=matrix(nrow=max.vart, ncol=4)
colnames(summy)=c("OR", "p.value", "rate.ca", "rate.co")
rownames(summy)=var.fea
for (vart in 1:max.vart)
{
  cat(vart, "is running", "\n")
  pois.test=test.func(var.evid[[vart]], var.data, N1, N0)
  summy[vart,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
}
```

```{r, echo=T}
kable(summy, caption="Burden analysis of single variant features")
```

Test: use two sample one side poisson test ("greater")

* probably damaging:Polyphen2.HDIV.score >=0.957
* possibly damaging: <0.957 & >=0.453; 
* consensus: "Prby Damaging", or  "SIFT<0.05", or   "CADD top10%" (take union)
* LoF:stopgain+ frameshift substitution+splicing+stoploss (take union)

### LoF in different gene set 


```{r burdern analysis-gene level, results='hide', echo=F}
GeneDB=src_sqlite(path="../../gene.list.db", create=F)
gene_cate1=data.frame(collect(tbl(GeneDB, "SFARI_HighConf")))
gene_cate2=data.frame(collect(tbl(GeneDB, "SFARI_StrongCand")))
gene_cate3=data.frame(collect(tbl(GeneDB, "SFARI_cate3_gene")))
gene_cate4=data.frame(collect(tbl(GeneDB, "SFARI_cate4_gene")))
gene_cate5=data.frame(collect(tbl(GeneDB, "SFARI_cate5_gene")))
gene_cate6=data.frame(collect(tbl(GeneDB, "SFARI_cate6_gene")))
gene_cateS=data.frame(collect(tbl(GeneDB, "SFARI_cateS_gene")))
IDGene=data.frame(collect(tbl(GeneDB, "Pinto14AJHG_IDgene")))
TADAGene=data.frame(collect(tbl(GeneDB, "TADAGenelist")))
Qlessthan5percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.05]
Qlessthan20percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.2]
Qlessthan30percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.3]
Qlessthan40percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.4]
Qlessthan50percentgene=TADAGene$TadaName[TADAGene$qvalue.combined<0.5]
Qlargerthan90percentgene=TADAGene$TadaName[TADAGene$qvalue.combined>0.9]
purcell.genelist=data.frame(collect(tbl(GeneDB, "Purcell2014_genelist"))) ## PSD gene, SCZdenovo gene 
ASD.gene=data.frame(collect(tbl(GeneDB, "AutismKB_gene")))
constraint.gene=data.frame(collect(tbl(GeneDB, "Samocha_2014NG_constraintgene")))$gene
RVIS.Allgene=data.frame(collect(tbl(GeneDB, "RVIS_gene")))
RVIS.gene=RVIS.Allgene$GeneID[RVIS.Allgene$RVIS.percentile<5] # top 5% gene 
haploinsuff.gene=data.frame(collect(tbl(GeneDB, "Petrovski_plosgen_haploinsuff_gene")))
gene.set=c("ID gene","High", "Mod", "PSD", "FMRP", "AutismKB", "constraint gene", "RVIS", "Haploinsuff gene", "SCZ gene", "Olfac.gene")
gene.fea=c("cate1", "cate2", "cate3", "cate4", "cate5", "cate6", "cateS", "TADAq<5%", "TADAq<20%", "TADAq<30%", "TADAq<40%", "TADAq<50%", "TADAq>90%", gene.set); max.gene=length(gene.fea)
LoF.def=c("stopgain", "frameshift substitution", "splicing", "stoploss")
gene.summy=matrix(nrow=max.gene+1, ncol=4)
gene.evid=list(); var.index=1
gene.evid[[1]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate1$GeneID & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[2]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate2$GeneID  & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[3]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate3$GeneID & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[4]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate4$GeneID & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[5]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate5$GeneID & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[6]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cate6$GeneID & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[7]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% gene_cateS$GeneID & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[8]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan5percentgene & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[9]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan20percentgene & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[10]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan30percentgene & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[11]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan40percentgene & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[12]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlessthan50percentgene & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[13]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% Qlargerthan90percentgene & Anno.Data$Annotation %in% LoF.def==T )])
gene.evid[[14]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% IDGene$GeneID & Anno.Data$Annotation %in% LoF.def==T)])
high.conf=union(union(gene_cate1$GeneID, gene_cate2$GeneID),Qlessthan5percentgene)
mod.conf=setdiff(union(union(gene_cate3$GeneID, gene_cateS$GeneID), Qlessthan30percentgene),Qlessthan5percentgene)
gene.evid[[15]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% high.conf & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[16]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% mod.conf & Anno.Data$Annotation %in% LoF.def==T )])
psd.gene=purcell.genelist$Gene_symbol[purcell.genelist$PSD=="Y"]
FMRP.gene=purcell.genelist$Gene_symbol[purcell.genelist$FMRP.target=="Y"]
gene.evid[[17]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% psd.gene & Anno.Data$Annotation %in% LoF.def==T )])
gene.evid[[18]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% FMRP.gene & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[19]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% ASD.gene$GeneID & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[20]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% constraint.gene & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[21]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% RVIS.gene & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[22]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% haploinsuff.gene$GeneID & Anno.Data$Annotation %in% LoF.def==T)])
gene.evid[[23]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% purcell.genelist$Gene_symbol & Anno.Data$Annotation %in% LoF.def==T)])
olfac.gene=data.frame(collect(tbl(GeneDB, "Olfac_gene")))
gene.evid[[24]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% olfac.gene$GeneID & Anno.Data$Annotation %in% LoF.def==T )])
sczgene=as.character(read.table("../../SCZ.67gene.q0.3.txt", header=T)[[1]])
gene.evid[[25]]=as.character(Anno.Data$ID[which(Anno.Data$Gene %in% sczgene & Anno.Data$Annotation %in% LoF.def==T)])

colnames(gene.summy)=c("OR", "p.value", "rate.ca", "rate.co")
rownames(gene.summy)=c(gene.fea, "67SCZriskgene")
for (gene in 1:(max.gene+1))
  if (length(gene.evid[[gene]])>0)
{
  cat(gene, "is running", "\n")
  pois.test=test.func(gene.evid[[gene]], var.data, N1, N0)
  gene.summy[gene,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
}

```

## Exon level analysis

**All subsequence analsyis foucs on variant with AF < 5% and exluding synonymous mutautions. **

```{r burden analysis-exon level, echo=FALSE, include=F}
exon.cutoff=c(0.9, 0.8, 0.7, 0.6, 0.5)
exon.fea=c(paste("ExonTop%", exon.cutoff*100, sep=""), "CriticalExon")
exon.summ=matrix(nrow=(1+length(exon.cutoff)), ncol=4)
evid.exon=list()
colnames(exon.summ)=c("OR", "p.value", "rate.ca", "rate.co")
rownames(exon.summ)=c(paste("Top%", exon.cutoff*100, sep=""), "critical exon")
for (i in 1:length(exon.cutoff))
{
  threshold=quantile(Anno.Data$Exon.Exac.Cons, prob=exon.cutoff[i], na.rm=T)
  evid.exon[[i]]=Anno.Data$ID[which(Anno.Data$Exon.Exac.Cons>threshold)]
  cat(i, "is running", "\n")
  pois.test=test.func(evid.exon[[i]], var.data, N1, N0)
  exon.summ[i,]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
}
threshold=quantile(Anno.Data$Exon.Exac.Cons, prob=0.75, na.rm=T)
evid.exon[[1+length(exon.cutoff)]]=Anno.Data$ID[which( Anno.Data$Exon.Exac.Cons>threshold)]
exon.thrshd=quantile(Anno.Data$Exon.Brain.Exp, prob=0.75, na.rm=T)
expre.exon=Anno.Data$ID[which( Anno.Data$Exon.Brain.Exp>exon.thrshd)]
critical.exon=union(evid.exon[[1+length(exon.cutoff)]],expre.exon)
pois.test=test.func(critical.exon, var.data, N1, N0)
exon.summ[(1+length(exon.cutoff)),]=c(pois.test$odds.ratio, pois.test$p.value, pois.test$rate.case, pois.test$rate.contr)
```
Test:  use two sample one side poisson test

* high values means more constraint
* critical exon=brian expression exon top 25%+exon constraint score top 25%


```{r }
kable(exon.summ, caption="Burden analysis of exons")
```

## Gene level analysis

See [here](Geneset-SCZ.html)


## Combined feature analysis



###  combination of gene set+AF+exon

```{r, echo=F, eval=F}
# run code burden.and.mirage-vs.for.cvombined.feature.R at C:\Shengtong\Research\rare-var\rare-var-project\code
```


```{r, echo=F}
rm("Burden.cate", "MIRAGE.cate.index", "MIRAGE.para.est", "MIRAGE.pvalue")
load("../output/CombinedFeature/Burden.MIRAGE.for.Combined.exon.geneset.partition.SCZ.RData")
#Burden.result=tibble(OR=as.numeric(comb.summ[,c(1, 5, 9, 13)]), pvalue=as.numeric(comb.summ[,c(2,6,10,14)]))
#g1=ggplot(Burden.result, aes(x=OR, y=-log(pvalue, base=10)))+
#  geom_point()+
#  geom_hline(yintercept=-log(0.05, base=10), linetype="dashed", color = "red")+
#  xlab("Odds ratio")+ylab(expression(paste("-log" [10], "(p value)")))+
#  ggtitle("Burden test")

#MIRAGE.result=tibble(OR=as.numeric(comb.summ.MIRAGE[,c(1, 5, 9, 13)]), pvalue=as.numeric(comb.summ.MIRAGE[,c(2,6,10,14)]))
#g2=ggplot(MIRAGE.result, aes(x=OR, y=-log(pvalue, base=10)))+
#  geom_point()+
#  geom_hline(yintercept=-log(0.05, base=10), linetype="dashed", color = "red")+
#  xlab("Odds ratio")+ylab(expression(paste("-log" [10], "(p value)")))+
#  ggtitle("MIRAGE")
N1=2536; N0=2543

Burden.OR=numeric(); Burden.pvalue=numeric(); No.var.case=numeric(); No.var.control=numeric()
feature.name=numeric(); cate.index=numeric()
for (ii in 1:length(Burden.cate))
{
  Burden.OR=c(Burden.OR, Burden.cate[[ii]][,1])
  Burden.pvalue=c(Burden.pvalue, Burden.cate[[ii]][,2])
  No.var.case=c(No.var.case, Burden.cate[[ii]][,3]*N1)
  No.var.control=c(No.var.control, Burden.cate[[ii]][,4]*N0)
  feature.name=c(feature.name, rownames(Burden.cate[[ii]]))
  cate.index=c(cate.index, MIRAGE.cate.index[[ii]])
}     

############### multiple correction for p values
MIRAGE.pvalue=unlist(MIRAGE.pvalue)
Burden.MIRAGE.pvalue=cbind(Burden.pvalue, MIRAGE.pvalue)
Burden.pvalue.adjust=p.adjust(Burden.pvalue, method="BH", n=length(Burden.pvalue))
MIRAGE.pvalue.adjust=p.adjust(MIRAGE.pvalue, method="BH", n=length(MIRAGE.pvalue))
Burden.MIRAGE.pvalue.adjust.pvalue=tibble(Burden.pvalue=Burden.pvalue, MIRAGE.pvalue=MIRAGE.pvalue, Burden.adjust.pvalue=Burden.pvalue.adjust, MIRAGE.adjust.pvalue=MIRAGE.pvalue.adjust)
burden.pvalue.fdr.0.05.cutoff=Burden.MIRAGE.pvalue.adjust.pvalue%>% filter(Burden.adjust.pvalue<0.05) %>% summarize(max.burden.pvalue=max(Burden.pvalue)) %>% pull()
mirage.pvalue.fdr.0.05.cutoff=Burden.MIRAGE.pvalue.adjust.pvalue%>% filter(MIRAGE.adjust.pvalue<0.05) %>% summarize(max.mirage.pvalue=max(MIRAGE.pvalue)) %>% pull()
 
##############

Burden.MIRAGE.combine=tibble(Burden.OR=Burden.OR, Burden.pvalue=Burden.pvalue, MIRAGE.risk.prop=unlist(MIRAGE.para.est), MIRAGE.pvalue=unlist(MIRAGE.pvalue), cate.index=unlist(MIRAGE.cate.index), No.var.case=No.var.case, No.var.control=No.var.control, combine.feature=feature.name)
Burden.MIRAGE.combine <- drop_na(Burden.MIRAGE.combine) # remove rows with NA
#Burden.MIRAGE.combine.clear <- as_tibble(data.matrix(Burden.MIRAGE.combine)[is.finite(rowSums(data.matrix(Burden.MIRAGE.combine))),])
Burden.MIRAGE.combine.clear=Burden.MIRAGE.combine
Burden.MIRAGE.combine.clear$cate.index=Burden.MIRAGE.combine.clear$cate.index %>% recode("1"="LoF; 1%<AF<5%", "2"="LoF; AF<1%", "3" = "Damaging; 1%<AF<5%","4"= "Damaging; 0.1%<AF<1%", "5" ="Damaging; AF<0.1%", "6" ="Non-damaging; 1%<AF<5%", "7" ="Non-damaging; 0.1%<AF<1%", "8" ="Non-damaging; AF<0.1%")


################### save significant combined features with p values less than 0.05
significant.combined.features=Burden.MIRAGE.combine.clear %>% filter(Burden.pvalue<0.05 | MIRAGE.pvalue<0.05)
#write.csv(significant.combined.features, file="../output/CombinedFeature/significant.combined.features.pvalue.lessthan.0.05.csv")
###################

g1=ggplot(as_tibble(Burden.MIRAGE.combine.clear), aes(x=Burden.OR, y=-log(Burden.pvalue, base=10), color=as.factor(cate.index), shape=as.factor(cate.index)))+
  scale_shape_manual(values=1:nlevels(as.factor(Burden.MIRAGE.combine.clear$cate.index)))+
  geom_point()+
  xlim(c(0,4))+ylim(c(0,5.5))+
  geom_hline(yintercept=-log(0.05, base=10), linetype="dashed", color = "red")+
  geom_hline(yintercept=-log(burden.pvalue.fdr.0.05.cutoff, base=10), linetype="solid", color = "blue")+
  xlab("OR")+ylab(expression(paste("-log" [10], "(p value)")))+
  ggtitle("Burden")+
  theme_classic()+
   theme(legend.position = "none")+  # no legend 
theme(plot.title = element_text(hjust = 0.5, size=10)) +# center the title 
theme(legend.title=element_blank())

g2=ggplot(as_tibble(Burden.MIRAGE.combine.clear), aes(x=MIRAGE.risk.prop, y=-log(MIRAGE.pvalue, base=10), color=as.factor(cate.index), shape=as.factor(cate.index)))+
  scale_shape_manual(values=1:nlevels(as.factor(Burden.MIRAGE.combine.clear$cate.index)))+  # manually define shapes if more than 6 groups 
  geom_point()+
  xlab(expression(paste(hat(eta))))+
  ylab("")+
  ylim(c(0,5.5))+
  geom_hline(yintercept=-log(0.05, base=10), linetype="dashed", color = "red")+
  geom_hline(yintercept=-log(mirage.pvalue.fdr.0.05.cutoff, base=10), linetype="solid", color = "blue")+
  ggtitle("MIRAGE-VS")+
  theme_classic()+
  theme(plot.title = element_text(hjust = 0.5, size=10))+  # center the title 
  #labs(color='variant group')+   # define legend title 
  theme(legend.title=element_blank())+
  theme(legend.text=element_text(size=1))
  #theme(legend.position = c(0.8, 4),
  #        legend.direction = "vertical")
#+
  #theme(legend.position="bottom")
#pdf("C:/Users/han24/OneDrive - UWM/rare-var/Figure/Supp/Fig-Burden_MIRAGE-vs_CombinedFeature_Split.pdf")
ggarrange(g1, g2,nrow=1, common.legend = TRUE, legend="bottom")  # multiple panels share one legend 
#dev.off()




```


## Session information

<!-- Insert the session information into the document -->
```{r session-info}
```
